{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201c76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 5.2 kB/s              |███████████▌                    | 315.6 MB 66.6 MB/s eta 0:00:09\n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed torch-1.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af04fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc55fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe64f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f832a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999eb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d30238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2923ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddc490d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8351ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8121380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f9ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c98b9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d614a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc896c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred = df_pred[df_pred[\"source\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74a31ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949c810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92d46f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  time_spent  isco_functie_niveau  education  company_name  \\\n",
       "0         84556   -0.210459                  2.0        0.0        324258   \n",
       "1         84556   -0.252626                  1.0        0.0        324258   \n",
       "2         84556   -0.085012                  2.0        0.0        329244   \n",
       "3         84556   -0.370694                  1.0        0.0        368140   \n",
       "4         84556   -0.363314                  1.0        0.0        419826   \n",
       "\n",
       "   function_id  isco_code4  \n",
       "0          936         208  \n",
       "1          809         348  \n",
       "2          936         208  \n",
       "3         1519         344  \n",
       "4         1519         344  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d74cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id           8.909607e+06\n",
       "time_spent             3.389322e+01\n",
       "isco_functie_niveau    4.000000e+00\n",
       "education              5.000000e+00\n",
       "company_name           4.411520e+05\n",
       "function_id            2.988000e+03\n",
       "isco_code4             3.540000e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e89eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2989, 267934)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pred[\"function_id\"].unique()), len(df_pred[\"company_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bbc3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df_pred[\"isco_code4\"].mode().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a598d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(2 / (0.5 * np.sqrt(df_pred[\"isco_code4\"].value_counts().sort_values().reset_index().drop(\"index\", axis=1)))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8590181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdd52ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5211a40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = df_pred[\"isco_code4\"].unique().max() + 1\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7692f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c075439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:47<00:00, 9787.30it/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "402cd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95b98f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661101fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[-0.21045870102048395, 2.0, 0.0, 324258.0, 93...\n",
       "84612    [[-0.3685852264755267, 1.0, 0.0, 201740.0, 151...\n",
       "84731    [[-0.35066422025728855, 1.0, 0.0, 353745.0, 15...\n",
       "85437    [[0.3313881928721292, 1.0, 2.0, 5500.0, 1519.0...\n",
       "85888    [[-0.2895219637480053, 2.0, 3.0, 423330.0, 795...\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ad290ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12e97e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a22ebd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "577b8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cadae677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtered: (113428, 113428)\n",
    "# Grouped: (176485, 176485)\n",
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a265a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:50000]\n",
    "# y = y[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fe7869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "    test, validation = test[:(len(test) // 2)], test[(len(test) // 2):]\n",
    "\n",
    "    train_indices, val_indices, test_indices = idxs[training], idxs[validation], idxs[test]\n",
    "    X_train, X_val, X_test = to_fill[training], to_fill[validation], to_fill[test]\n",
    "    y_train, y_val, y_test = y[training].astype(int), y[validation].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_data = TensorDataset(torch.Tensor(test_indices),\n",
    "                             torch.Tensor(X_test),\n",
    "                             torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "023dd07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super(attention, self).__init__()\n",
    "\n",
    "        # Attention layer\n",
    "        self.att_fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, outputs, h_n):\n",
    "        \n",
    "        # Deal with batches \n",
    "        outputs = outputs.transpose(0, 1)\n",
    "        att_weight = []\n",
    "        \n",
    "        # Determine weight of each timestep\n",
    "        for timestep in outputs:\n",
    "            x = self.att_fc(timestep)\n",
    "            att_weight.append(x)\n",
    "                        \n",
    "        # Normalize            \n",
    "        normalized_weights = nn.functional.softmax(torch.cat(att_weight, 1), 1)\n",
    "                \n",
    "        # Transpose to match normalized_weights\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        \n",
    "        # Multiply each timestep by its weight\n",
    "        attn_applied = (outputs * normalized_weights.unsqueeze(1)).permute(0, 2, 1)\n",
    "                       \n",
    "        attn_applied *= h_n.unsqueeze(1)\n",
    "        attn_applied = nn.functional.relu(attn_applied)\n",
    "                \n",
    "        # Weighted sum over time steps\n",
    "        attn_applied = attn_applied.sum(dim=1)\n",
    "                \n",
    "        return attn_applied, normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5fe34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers,\n",
    "                 skills, certs, licenses, languages, addresses, \n",
    "                 w2v, candidate_lengths, max_len, dropout_prob=0.3,\n",
    "                 skill_embedding_size=50, certs_embedding_size=20,\n",
    "                 license_embedding_size=3, language_embedding_size=10,\n",
    "                 address_embedding_size=25, function_embedding_size=50, \n",
    "                 isco4_embedding_size=25, education_embedding_size=3, \n",
    "                 isco_level_embedding_size=3, company_embedding_size=50):\n",
    "        \n",
    "        super(eLSTM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size + 300\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        \n",
    "        # Categorical feature embeddings isco_functie_niveau\tsource\teducation\tcompany_name\tfunction_id\tisco_code4\n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "        \n",
    "        # -6 --> embedded features get replaced\n",
    "        N = self.input_size - 5 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=1,\n",
    "                                kernel_size=(max_len, 1),\n",
    "                                padding=(max_len // 2, 0))\n",
    "        \n",
    "        self.convrelu = nn.ReLU()\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size=N * 2,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout_prob)\n",
    "            \n",
    "        # Attention layer\n",
    "        self.attention = attention(hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # Final fully-connected layer takes the LSTM output, as well as the static embeddings\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])\n",
    "                \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:\n",
    "                    # 0, 10, 20, 30, 40, 50\n",
    "                    # duration = 50\n",
    "                    # ---> 0, 5, 15, 25\n",
    "                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * 300).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    " \n",
    "    def forward(self, candidate, x):               \n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * 500).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "        \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "                        \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "            \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                   \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "                \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)\n",
    "\n",
    "        # CNN\n",
    "        x2 = self.conv2d(x.unsqueeze(1))\n",
    "        x2 = self.convrelu(x2)\n",
    "        x2 = x2.squeeze(1)\n",
    "        \n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        # TODO: Look into how to concatenate these two?\n",
    "        x = torch.cat([x, x2], dim=2)\n",
    "                \n",
    "        # LSTM\n",
    "        x, (h_n, c_n) = self.LSTM(x)\n",
    "        \n",
    "        # In case of multiple LSTMs, take the last h_n\n",
    "        if h_n.size(0) > 1:\n",
    "            h_n = h_n[-1]\n",
    "        \n",
    "        h_n = h_n.squeeze(0)\n",
    "                \n",
    "        # Apply attention\n",
    "        context, weight = self.attention(x, h_n)\n",
    "        \n",
    "        # Combine the context and the lstm output\n",
    "        x = torch.cat([h_n, context], dim=1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "                \n",
    "        # Fully-connected\n",
    "        out = self.fc(x)\n",
    "\n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out, weight, career_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9de1e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "        \n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, weight, _ = model(candidate, career)\n",
    "                        \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "                    \n",
    "        training_loss /= len(trainloader)\n",
    "               \n",
    "        stats = test_loop(valloader, testloader, model, criterion)\n",
    "        \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int((done) // 60)}:{int((done) % 60):02d}\")\n",
    "\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"Acc@20\"].append(stats[3])\n",
    "        results[\"test_loss\"].append(stats[4])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        results[\"duration\"].append(done)\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/optimal_eCNN-LSTM.pt\")\n",
    "            highest_performance = stats[0]\n",
    "        \n",
    "        scheduler.step()\n",
    "                \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "        plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "        plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Average loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(passed, accuracy)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, testloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred, weight, _ = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    print(f\"\\nVal Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    size_2 = len(testloader.dataset)\n",
    "    num_batches_2 = len(testloader)\n",
    "    test_loss_2, acc1_2, acc5_2, acc10_2 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in testloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred, weight, _ = model(candidate, career)\n",
    "            \n",
    "            test_loss_2 += criterion(pred, job).mean().item()\n",
    "            acc1_2 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5_2 = []\n",
    "            at10_2 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5_2.append(answer.item() in predictions[:5])\n",
    "                at10_2.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5_2 += np.sum(at5_2)\n",
    "            acc10_2 += np.sum(at10_2)\n",
    "            \n",
    "    test_loss_2 /= num_batches_2\n",
    "    acc1_2 /= size_2\n",
    "    acc5_2 /= size_2\n",
    "    acc10_2 /= size_2\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1_2):>0.2f}%, Acc@5: {100*acc5_2:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10_2:>0.2f}%, Avg loss: {test_loss_2:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53eaab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Initial learning rate: 0.001\n",
      "- Batch size: 2048\n",
      "- Model: \n",
      "\n",
      " eLSTM(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=50, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=10, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=15, bias=False)\n",
      "  (address_embedding): Embedding(4768, 25)\n",
      "  (function_embedding): Embedding(2992, 250)\n",
      "  (isco_code_embedding): Embedding(355, 150)\n",
      "  (company_embedding): Embedding(441153, 300)\n",
      "  (education_embedding): Embedding(6, 10)\n",
      "  (isco_level_embedding): Embedding(5, 10)\n",
      "  (conv2d): Conv2d(1, 1, kernel_size=(25, 1), stride=(1, 1), padding=(12, 0))\n",
      "  (convrelu): ReLU()\n",
      "  (LSTM): LSTM(2442, 1000, batch_first=True)\n",
      "  (attention): attention(\n",
      "    (att_fc): Linear(in_features=1000, out_features=1, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc): Linear(in_features=2000, out_features=355, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ") \n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 17:39:54\n",
      "Epoch: 1, batch: 22/45, loss: 4.57923\r"
     ]
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 30\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-3]\n",
    "hidden_sizes = [1000]\n",
    "num_layerss = [1]\n",
    "batch_sizes = [2048]\n",
    "dropout_probs = [0, 0.5]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=300\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:        \n",
    "    for learning_rate in learning_rates:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for num_layers in num_layerss:\n",
    "                for dropout in dropout_probs:\n",
    "                    for batch_size in batch_sizes:\n",
    "\n",
    "                        lstm = eLSTM(num_classes=num_classes,\n",
    "                                     input_size=num_features,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=num_layers,\n",
    "                                     dropout_prob=dropout,\n",
    "                                     skills=skills, \n",
    "                                     certs=certs,\n",
    "                                     licenses=licenses,\n",
    "                                     languages=languages,\n",
    "                                     addresses=addresses,\n",
    "                                     w2v=w2v,\n",
    "                                     skill_embedding_size=skill_embedding_size,\n",
    "                                     certs_embedding_size=certs_embedding_size,\n",
    "                                     license_embedding_size=license_embedding_size,\n",
    "                                     language_embedding_size=language_embedding_size,\n",
    "                                     address_embedding_size=address_embedding_size,\n",
    "                                     function_embedding_size=function_embedding_size,\n",
    "                                     isco4_embedding_size=isco4_embedding_size,\n",
    "                                     education_embedding_size=education_embedding_size,\n",
    "                                     isco_level_embedding_size=isco_level_embedding_size,\n",
    "                                     company_embedding_size=company_embedding_size,\n",
    "                                     candidate_lengths=candidate_lens,\n",
    "                                     max_len=max_len)\n",
    "\n",
    "                        lstm = lstm.to(device)\n",
    "\n",
    "                        optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "                        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "                        if current >= 1:\n",
    "                            print(\"\\n\\n\\n\")\n",
    "\n",
    "                        print(f\"- Initial learning rate: {learning_rate}\\n- Batch size: {batch_size}\\n- Model: \\n\\n\", lstm, \"\\n\")\n",
    "\n",
    "                        trainloader, valloader, testloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                                            weight_type=3, batch_size=batch_size)\n",
    "                        \n",
    "                        # Store results of current configuration\n",
    "                        outcome = train_loop(lstm, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                        outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                        outcome[\"Nodes per layer\"] = [hidden_size] * num_epochs\n",
    "                        outcome[\"Number of layers\"] = [num_layers] * num_epochs\n",
    "                        outcome[\"Dropout\"] = [dropout] * num_epochs\n",
    "                        outcome[\"Batch size\"] = [batch_size] * num_epochs\n",
    "\n",
    "                        full_results.append(outcome)\n",
    "                        \n",
    "                        current += 1\n",
    "\n",
    "            break\n",
    "        break\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b504538",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Nodes per layer\", \"Number of layers\", \"Dropout\", \"Batch size\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "951b734c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>Acc@20</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"60\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"60\" valign=\"top\">1000</th>\n",
       "      <th rowspan=\"60\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.00</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">2048</th>\n",
       "      <th>1</th>\n",
       "      <td>0.242471</td>\n",
       "      <td>0.526797</td>\n",
       "      <td>0.648011</td>\n",
       "      <td>0.764783</td>\n",
       "      <td>3.581701</td>\n",
       "      <td>4.646030</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244142</td>\n",
       "      <td>0.528863</td>\n",
       "      <td>0.649813</td>\n",
       "      <td>0.771378</td>\n",
       "      <td>3.410987</td>\n",
       "      <td>3.394140</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226116</td>\n",
       "      <td>0.511629</td>\n",
       "      <td>0.638910</td>\n",
       "      <td>0.764783</td>\n",
       "      <td>3.464014</td>\n",
       "      <td>2.564378</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227479</td>\n",
       "      <td>0.509431</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.765355</td>\n",
       "      <td>3.473832</td>\n",
       "      <td>1.998128</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226775</td>\n",
       "      <td>0.510662</td>\n",
       "      <td>0.638470</td>\n",
       "      <td>0.769620</td>\n",
       "      <td>3.502456</td>\n",
       "      <td>1.583063</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232359</td>\n",
       "      <td>0.514135</td>\n",
       "      <td>0.648626</td>\n",
       "      <td>0.774236</td>\n",
       "      <td>3.536835</td>\n",
       "      <td>1.295728</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.235304</td>\n",
       "      <td>0.520246</td>\n",
       "      <td>0.650912</td>\n",
       "      <td>0.775907</td>\n",
       "      <td>3.594574</td>\n",
       "      <td>1.056718</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.234073</td>\n",
       "      <td>0.517388</td>\n",
       "      <td>0.651967</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>3.614389</td>\n",
       "      <td>0.895034</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.231479</td>\n",
       "      <td>0.523544</td>\n",
       "      <td>0.655705</td>\n",
       "      <td>0.778193</td>\n",
       "      <td>3.708885</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233018</td>\n",
       "      <td>0.522225</td>\n",
       "      <td>0.653023</td>\n",
       "      <td>0.774544</td>\n",
       "      <td>3.766299</td>\n",
       "      <td>0.645076</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.233018</td>\n",
       "      <td>0.530226</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.775863</td>\n",
       "      <td>3.830939</td>\n",
       "      <td>0.556088</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.234557</td>\n",
       "      <td>0.532820</td>\n",
       "      <td>0.662431</td>\n",
       "      <td>0.777358</td>\n",
       "      <td>3.880208</td>\n",
       "      <td>0.478786</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.232491</td>\n",
       "      <td>0.530226</td>\n",
       "      <td>0.659046</td>\n",
       "      <td>0.775467</td>\n",
       "      <td>3.941080</td>\n",
       "      <td>0.414042</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.232183</td>\n",
       "      <td>0.524247</td>\n",
       "      <td>0.657727</td>\n",
       "      <td>0.772565</td>\n",
       "      <td>4.023437</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.238206</td>\n",
       "      <td>0.528907</td>\n",
       "      <td>0.657419</td>\n",
       "      <td>0.773269</td>\n",
       "      <td>4.088887</td>\n",
       "      <td>0.334967</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.240141</td>\n",
       "      <td>0.531589</td>\n",
       "      <td>0.661332</td>\n",
       "      <td>0.773840</td>\n",
       "      <td>4.149440</td>\n",
       "      <td>0.297436</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.236755</td>\n",
       "      <td>0.524863</td>\n",
       "      <td>0.654913</td>\n",
       "      <td>0.768389</td>\n",
       "      <td>4.205299</td>\n",
       "      <td>0.267564</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.241108</td>\n",
       "      <td>0.529127</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.764344</td>\n",
       "      <td>4.263642</td>\n",
       "      <td>0.239369</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.235744</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>0.653374</td>\n",
       "      <td>0.765839</td>\n",
       "      <td>4.270088</td>\n",
       "      <td>0.219582</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.241987</td>\n",
       "      <td>0.527281</td>\n",
       "      <td>0.651484</td>\n",
       "      <td>0.762893</td>\n",
       "      <td>4.308475</td>\n",
       "      <td>0.200148</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.529963</td>\n",
       "      <td>0.655705</td>\n",
       "      <td>0.766542</td>\n",
       "      <td>4.413041</td>\n",
       "      <td>0.176215</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.237195</td>\n",
       "      <td>0.525170</td>\n",
       "      <td>0.648934</td>\n",
       "      <td>0.762233</td>\n",
       "      <td>4.419962</td>\n",
       "      <td>0.165004</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.234249</td>\n",
       "      <td>0.527545</td>\n",
       "      <td>0.650297</td>\n",
       "      <td>0.763640</td>\n",
       "      <td>4.453727</td>\n",
       "      <td>0.148447</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.233370</td>\n",
       "      <td>0.520422</td>\n",
       "      <td>0.647131</td>\n",
       "      <td>0.759244</td>\n",
       "      <td>4.515778</td>\n",
       "      <td>0.138806</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.240624</td>\n",
       "      <td>0.527457</td>\n",
       "      <td>0.650868</td>\n",
       "      <td>0.760607</td>\n",
       "      <td>4.569533</td>\n",
       "      <td>0.126969</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.228534</td>\n",
       "      <td>0.521082</td>\n",
       "      <td>0.646472</td>\n",
       "      <td>0.759903</td>\n",
       "      <td>4.575587</td>\n",
       "      <td>0.120334</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.235524</td>\n",
       "      <td>0.524599</td>\n",
       "      <td>0.649461</td>\n",
       "      <td>0.759683</td>\n",
       "      <td>4.613018</td>\n",
       "      <td>0.111578</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.234425</td>\n",
       "      <td>0.514838</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.753836</td>\n",
       "      <td>4.605562</td>\n",
       "      <td>0.104124</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.236404</td>\n",
       "      <td>0.521873</td>\n",
       "      <td>0.647571</td>\n",
       "      <td>0.756342</td>\n",
       "      <td>4.674026</td>\n",
       "      <td>0.098561</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.243218</td>\n",
       "      <td>0.523236</td>\n",
       "      <td>0.646516</td>\n",
       "      <td>0.756826</td>\n",
       "      <td>4.728583</td>\n",
       "      <td>0.091350</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.25</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">2048</th>\n",
       "      <th>1</th>\n",
       "      <td>0.233150</td>\n",
       "      <td>0.510969</td>\n",
       "      <td>0.634381</td>\n",
       "      <td>0.753572</td>\n",
       "      <td>3.637204</td>\n",
       "      <td>4.731715</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222554</td>\n",
       "      <td>0.505034</td>\n",
       "      <td>0.631304</td>\n",
       "      <td>0.757617</td>\n",
       "      <td>3.525288</td>\n",
       "      <td>3.486802</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228050</td>\n",
       "      <td>0.509958</td>\n",
       "      <td>0.638382</td>\n",
       "      <td>0.760387</td>\n",
       "      <td>3.450307</td>\n",
       "      <td>2.644501</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206595</td>\n",
       "      <td>0.496812</td>\n",
       "      <td>0.631128</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>3.541522</td>\n",
       "      <td>2.075440</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226379</td>\n",
       "      <td>0.508507</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.767641</td>\n",
       "      <td>3.548276</td>\n",
       "      <td>1.662400</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.213322</td>\n",
       "      <td>0.501121</td>\n",
       "      <td>0.639481</td>\n",
       "      <td>0.770675</td>\n",
       "      <td>3.640209</td>\n",
       "      <td>1.364773</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.225104</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.650912</td>\n",
       "      <td>0.770983</td>\n",
       "      <td>3.611803</td>\n",
       "      <td>1.136035</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.220004</td>\n",
       "      <td>0.509607</td>\n",
       "      <td>0.645065</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>3.711885</td>\n",
       "      <td>0.977622</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.217454</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.652627</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>3.784262</td>\n",
       "      <td>0.837562</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.224885</td>\n",
       "      <td>0.512904</td>\n",
       "      <td>0.649330</td>\n",
       "      <td>0.768740</td>\n",
       "      <td>3.848463</td>\n",
       "      <td>0.732793</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.220972</td>\n",
       "      <td>0.517169</td>\n",
       "      <td>0.652715</td>\n",
       "      <td>0.771158</td>\n",
       "      <td>3.940530</td>\n",
       "      <td>0.640299</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.217762</td>\n",
       "      <td>0.515498</td>\n",
       "      <td>0.652803</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>4.019189</td>\n",
       "      <td>0.568246</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.223522</td>\n",
       "      <td>0.514399</td>\n",
       "      <td>0.647967</td>\n",
       "      <td>0.767905</td>\n",
       "      <td>4.086190</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.222774</td>\n",
       "      <td>0.522532</td>\n",
       "      <td>0.652275</td>\n",
       "      <td>0.770983</td>\n",
       "      <td>4.137924</td>\n",
       "      <td>0.461093</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.227479</td>\n",
       "      <td>0.516641</td>\n",
       "      <td>0.647747</td>\n",
       "      <td>0.766366</td>\n",
       "      <td>4.157132</td>\n",
       "      <td>0.422716</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.231611</td>\n",
       "      <td>0.519279</td>\n",
       "      <td>0.649989</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>4.244360</td>\n",
       "      <td>0.383820</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.647835</td>\n",
       "      <td>0.762453</td>\n",
       "      <td>4.309830</td>\n",
       "      <td>0.352039</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.231699</td>\n",
       "      <td>0.518356</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.761442</td>\n",
       "      <td>4.396050</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.222510</td>\n",
       "      <td>0.517740</td>\n",
       "      <td>0.651176</td>\n",
       "      <td>0.762717</td>\n",
       "      <td>4.426726</td>\n",
       "      <td>0.308146</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.223566</td>\n",
       "      <td>0.508947</td>\n",
       "      <td>0.641899</td>\n",
       "      <td>0.759683</td>\n",
       "      <td>4.444165</td>\n",
       "      <td>0.286340</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.230732</td>\n",
       "      <td>0.520774</td>\n",
       "      <td>0.649945</td>\n",
       "      <td>0.760783</td>\n",
       "      <td>4.534028</td>\n",
       "      <td>0.259671</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.225676</td>\n",
       "      <td>0.514707</td>\n",
       "      <td>0.648494</td>\n",
       "      <td>0.759508</td>\n",
       "      <td>4.552880</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.232359</td>\n",
       "      <td>0.515894</td>\n",
       "      <td>0.641504</td>\n",
       "      <td>0.756210</td>\n",
       "      <td>4.643656</td>\n",
       "      <td>0.220385</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.228622</td>\n",
       "      <td>0.516157</td>\n",
       "      <td>0.646120</td>\n",
       "      <td>0.756650</td>\n",
       "      <td>4.678653</td>\n",
       "      <td>0.212844</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.227830</td>\n",
       "      <td>0.514267</td>\n",
       "      <td>0.642207</td>\n",
       "      <td>0.753704</td>\n",
       "      <td>4.704782</td>\n",
       "      <td>0.196488</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.222291</td>\n",
       "      <td>0.513783</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.751902</td>\n",
       "      <td>4.720306</td>\n",
       "      <td>0.187556</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.226731</td>\n",
       "      <td>0.509782</td>\n",
       "      <td>0.640229</td>\n",
       "      <td>0.755287</td>\n",
       "      <td>4.818793</td>\n",
       "      <td>0.181075</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.223346</td>\n",
       "      <td>0.509519</td>\n",
       "      <td>0.639701</td>\n",
       "      <td>0.751198</td>\n",
       "      <td>4.854109</td>\n",
       "      <td>0.172204</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.225456</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.637591</td>\n",
       "      <td>0.751638</td>\n",
       "      <td>4.856996</td>\n",
       "      <td>0.163482</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.508947</td>\n",
       "      <td>0.635964</td>\n",
       "      <td>0.748912</td>\n",
       "      <td>4.919608</td>\n",
       "      <td>0.154945</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Acc@1  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch             \n",
       "0.001 1000            1                0.00    2048       1      0.242471   \n",
       "                                                          2      0.244142   \n",
       "                                                          3      0.226116   \n",
       "                                                          4      0.227479   \n",
       "                                                          5      0.226775   \n",
       "                                                          6      0.232359   \n",
       "                                                          7      0.235304   \n",
       "                                                          8      0.234073   \n",
       "                                                          9      0.231479   \n",
       "                                                          10     0.233018   \n",
       "                                                          11     0.233018   \n",
       "                                                          12     0.234557   \n",
       "                                                          13     0.232491   \n",
       "                                                          14     0.232183   \n",
       "                                                          15     0.238206   \n",
       "                                                          16     0.240141   \n",
       "                                                          17     0.236755   \n",
       "                                                          18     0.241108   \n",
       "                                                          19     0.235744   \n",
       "                                                          20     0.241987   \n",
       "                                                          21     0.237327   \n",
       "                                                          22     0.237195   \n",
       "                                                          23     0.234249   \n",
       "                                                          24     0.233370   \n",
       "                                                          25     0.240624   \n",
       "                                                          26     0.228534   \n",
       "                                                          27     0.235524   \n",
       "                                                          28     0.234425   \n",
       "                                                          29     0.236404   \n",
       "                                                          30     0.243218   \n",
       "                                       0.25    2048       1      0.233150   \n",
       "                                                          2      0.222554   \n",
       "                                                          3      0.228050   \n",
       "                                                          4      0.206595   \n",
       "                                                          5      0.226379   \n",
       "                                                          6      0.213322   \n",
       "                                                          7      0.225104   \n",
       "                                                          8      0.220004   \n",
       "                                                          9      0.217454   \n",
       "                                                          10     0.224885   \n",
       "                                                          11     0.220972   \n",
       "                                                          12     0.217762   \n",
       "                                                          13     0.223522   \n",
       "                                                          14     0.222774   \n",
       "                                                          15     0.227479   \n",
       "                                                          16     0.231611   \n",
       "                                                          17     0.230600   \n",
       "                                                          18     0.231699   \n",
       "                                                          19     0.222510   \n",
       "                                                          20     0.223566   \n",
       "                                                          21     0.230732   \n",
       "                                                          22     0.225676   \n",
       "                                                          23     0.232359   \n",
       "                                                          24     0.228622   \n",
       "                                                          25     0.227830   \n",
       "                                                          26     0.222291   \n",
       "                                                          27     0.226731   \n",
       "                                                          28     0.223346   \n",
       "                                                          29     0.225456   \n",
       "                                                          30     0.228314   \n",
       "\n",
       "                                                                    Acc@5  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch             \n",
       "0.001 1000            1                0.00    2048       1      0.526797   \n",
       "                                                          2      0.528863   \n",
       "                                                          3      0.511629   \n",
       "                                                          4      0.509431   \n",
       "                                                          5      0.510662   \n",
       "                                                          6      0.514135   \n",
       "                                                          7      0.520246   \n",
       "                                                          8      0.517388   \n",
       "                                                          9      0.523544   \n",
       "                                                          10     0.522225   \n",
       "                                                          11     0.530226   \n",
       "                                                          12     0.532820   \n",
       "                                                          13     0.530226   \n",
       "                                                          14     0.524247   \n",
       "                                                          15     0.528907   \n",
       "                                                          16     0.531589   \n",
       "                                                          17     0.524863   \n",
       "                                                          18     0.529127   \n",
       "                                                          19     0.527193   \n",
       "                                                          20     0.527281   \n",
       "                                                          21     0.529963   \n",
       "                                                          22     0.525170   \n",
       "                                                          23     0.527545   \n",
       "                                                          24     0.520422   \n",
       "                                                          25     0.527457   \n",
       "                                                          26     0.521082   \n",
       "                                                          27     0.524599   \n",
       "                                                          28     0.514838   \n",
       "                                                          29     0.521873   \n",
       "                                                          30     0.523236   \n",
       "                                       0.25    2048       1      0.510969   \n",
       "                                                          2      0.505034   \n",
       "                                                          3      0.509958   \n",
       "                                                          4      0.496812   \n",
       "                                                          5      0.508507   \n",
       "                                                          6      0.501121   \n",
       "                                                          7      0.511805   \n",
       "                                                          8      0.509607   \n",
       "                                                          9      0.511805   \n",
       "                                                          10     0.512904   \n",
       "                                                          11     0.517169   \n",
       "                                                          12     0.515498   \n",
       "                                                          13     0.514399   \n",
       "                                                          14     0.522532   \n",
       "                                                          15     0.516641   \n",
       "                                                          16     0.519279   \n",
       "                                                          17     0.514970   \n",
       "                                                          18     0.518356   \n",
       "                                                          19     0.517740   \n",
       "                                                          20     0.508947   \n",
       "                                                          21     0.520774   \n",
       "                                                          22     0.514707   \n",
       "                                                          23     0.515894   \n",
       "                                                          24     0.516157   \n",
       "                                                          25     0.514267   \n",
       "                                                          26     0.513783   \n",
       "                                                          27     0.509782   \n",
       "                                                          28     0.509519   \n",
       "                                                          29     0.508200   \n",
       "                                                          30     0.508947   \n",
       "\n",
       "                                                                   Acc@10  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch             \n",
       "0.001 1000            1                0.00    2048       1      0.648011   \n",
       "                                                          2      0.649813   \n",
       "                                                          3      0.638910   \n",
       "                                                          4      0.636711   \n",
       "                                                          5      0.638470   \n",
       "                                                          6      0.648626   \n",
       "                                                          7      0.650912   \n",
       "                                                          8      0.651967   \n",
       "                                                          9      0.655705   \n",
       "                                                          10     0.653023   \n",
       "                                                          11     0.657639   \n",
       "                                                          12     0.662431   \n",
       "                                                          13     0.659046   \n",
       "                                                          14     0.657727   \n",
       "                                                          15     0.657419   \n",
       "                                                          16     0.661332   \n",
       "                                                          17     0.654913   \n",
       "                                                          18     0.654517   \n",
       "                                                          19     0.653374   \n",
       "                                                          20     0.651484   \n",
       "                                                          21     0.655705   \n",
       "                                                          22     0.648934   \n",
       "                                                          23     0.650297   \n",
       "                                                          24     0.647131   \n",
       "                                                          25     0.650868   \n",
       "                                                          26     0.646472   \n",
       "                                                          27     0.649461   \n",
       "                                                          28     0.640800   \n",
       "                                                          29     0.647571   \n",
       "                                                          30     0.646516   \n",
       "                                       0.25    2048       1      0.634381   \n",
       "                                                          2      0.631304   \n",
       "                                                          3      0.638382   \n",
       "                                                          4      0.631128   \n",
       "                                                          5      0.643658   \n",
       "                                                          6      0.639481   \n",
       "                                                          7      0.650912   \n",
       "                                                          8      0.645065   \n",
       "                                                          9      0.652627   \n",
       "                                                          10     0.649330   \n",
       "                                                          11     0.652715   \n",
       "                                                          12     0.652803   \n",
       "                                                          13     0.647967   \n",
       "                                                          14     0.652275   \n",
       "                                                          15     0.647747   \n",
       "                                                          16     0.649989   \n",
       "                                                          17     0.647835   \n",
       "                                                          18     0.646604   \n",
       "                                                          19     0.651176   \n",
       "                                                          20     0.641899   \n",
       "                                                          21     0.649945   \n",
       "                                                          22     0.648494   \n",
       "                                                          23     0.641504   \n",
       "                                                          24     0.646120   \n",
       "                                                          25     0.642207   \n",
       "                                                          26     0.640800   \n",
       "                                                          27     0.640229   \n",
       "                                                          28     0.639701   \n",
       "                                                          29     0.637591   \n",
       "                                                          30     0.635964   \n",
       "\n",
       "                                                                   Acc@20  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch             \n",
       "0.001 1000            1                0.00    2048       1      0.764783   \n",
       "                                                          2      0.771378   \n",
       "                                                          3      0.764783   \n",
       "                                                          4      0.765355   \n",
       "                                                          5      0.769620   \n",
       "                                                          6      0.774236   \n",
       "                                                          7      0.775907   \n",
       "                                                          8      0.776742   \n",
       "                                                          9      0.778193   \n",
       "                                                          10     0.774544   \n",
       "                                                          11     0.775863   \n",
       "                                                          12     0.777358   \n",
       "                                                          13     0.775467   \n",
       "                                                          14     0.772565   \n",
       "                                                          15     0.773269   \n",
       "                                                          16     0.773840   \n",
       "                                                          17     0.768389   \n",
       "                                                          18     0.764344   \n",
       "                                                          19     0.765839   \n",
       "                                                          20     0.762893   \n",
       "                                                          21     0.766542   \n",
       "                                                          22     0.762233   \n",
       "                                                          23     0.763640   \n",
       "                                                          24     0.759244   \n",
       "                                                          25     0.760607   \n",
       "                                                          26     0.759903   \n",
       "                                                          27     0.759683   \n",
       "                                                          28     0.753836   \n",
       "                                                          29     0.756342   \n",
       "                                                          30     0.756826   \n",
       "                                       0.25    2048       1      0.753572   \n",
       "                                                          2      0.757617   \n",
       "                                                          3      0.760387   \n",
       "                                                          4      0.760079   \n",
       "                                                          5      0.767641   \n",
       "                                                          6      0.770675   \n",
       "                                                          7      0.770983   \n",
       "                                                          8      0.768477   \n",
       "                                                          9      0.774104   \n",
       "                                                          10     0.768740   \n",
       "                                                          11     0.771158   \n",
       "                                                          12     0.772917   \n",
       "                                                          13     0.767905   \n",
       "                                                          14     0.770983   \n",
       "                                                          15     0.766366   \n",
       "                                                          16     0.765047   \n",
       "                                                          17     0.762453   \n",
       "                                                          18     0.761442   \n",
       "                                                          19     0.762717   \n",
       "                                                          20     0.759683   \n",
       "                                                          21     0.760783   \n",
       "                                                          22     0.759508   \n",
       "                                                          23     0.756210   \n",
       "                                                          24     0.756650   \n",
       "                                                          25     0.753704   \n",
       "                                                          26     0.751902   \n",
       "                                                          27     0.755287   \n",
       "                                                          28     0.751198   \n",
       "                                                          29     0.751638   \n",
       "                                                          30     0.748912   \n",
       "\n",
       "                                                                 test_loss  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch              \n",
       "0.001 1000            1                0.00    2048       1       3.581701   \n",
       "                                                          2       3.410987   \n",
       "                                                          3       3.464014   \n",
       "                                                          4       3.473832   \n",
       "                                                          5       3.502456   \n",
       "                                                          6       3.536835   \n",
       "                                                          7       3.594574   \n",
       "                                                          8       3.614389   \n",
       "                                                          9       3.708885   \n",
       "                                                          10      3.766299   \n",
       "                                                          11      3.830939   \n",
       "                                                          12      3.880208   \n",
       "                                                          13      3.941080   \n",
       "                                                          14      4.023437   \n",
       "                                                          15      4.088887   \n",
       "                                                          16      4.149440   \n",
       "                                                          17      4.205299   \n",
       "                                                          18      4.263642   \n",
       "                                                          19      4.270088   \n",
       "                                                          20      4.308475   \n",
       "                                                          21      4.413041   \n",
       "                                                          22      4.419962   \n",
       "                                                          23      4.453727   \n",
       "                                                          24      4.515778   \n",
       "                                                          25      4.569533   \n",
       "                                                          26      4.575587   \n",
       "                                                          27      4.613018   \n",
       "                                                          28      4.605562   \n",
       "                                                          29      4.674026   \n",
       "                                                          30      4.728583   \n",
       "                                       0.25    2048       1       3.637204   \n",
       "                                                          2       3.525288   \n",
       "                                                          3       3.450307   \n",
       "                                                          4       3.541522   \n",
       "                                                          5       3.548276   \n",
       "                                                          6       3.640209   \n",
       "                                                          7       3.611803   \n",
       "                                                          8       3.711885   \n",
       "                                                          9       3.784262   \n",
       "                                                          10      3.848463   \n",
       "                                                          11      3.940530   \n",
       "                                                          12      4.019189   \n",
       "                                                          13      4.086190   \n",
       "                                                          14      4.137924   \n",
       "                                                          15      4.157132   \n",
       "                                                          16      4.244360   \n",
       "                                                          17      4.309830   \n",
       "                                                          18      4.396050   \n",
       "                                                          19      4.426726   \n",
       "                                                          20      4.444165   \n",
       "                                                          21      4.534028   \n",
       "                                                          22      4.552880   \n",
       "                                                          23      4.643656   \n",
       "                                                          24      4.678653   \n",
       "                                                          25      4.704782   \n",
       "                                                          26      4.720306   \n",
       "                                                          27      4.818793   \n",
       "                                                          28      4.854109   \n",
       "                                                          29      4.856996   \n",
       "                                                          30      4.919608   \n",
       "\n",
       "                                                                 training_loss  \\\n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch                  \n",
       "0.001 1000            1                0.00    2048       1           4.646030   \n",
       "                                                          2           3.394140   \n",
       "                                                          3           2.564378   \n",
       "                                                          4           1.998128   \n",
       "                                                          5           1.583063   \n",
       "                                                          6           1.295728   \n",
       "                                                          7           1.056718   \n",
       "                                                          8           0.895034   \n",
       "                                                          9           0.745645   \n",
       "                                                          10          0.645076   \n",
       "                                                          11          0.556088   \n",
       "                                                          12          0.478786   \n",
       "                                                          13          0.414042   \n",
       "                                                          14          0.377419   \n",
       "                                                          15          0.334967   \n",
       "                                                          16          0.297436   \n",
       "                                                          17          0.267564   \n",
       "                                                          18          0.239369   \n",
       "                                                          19          0.219582   \n",
       "                                                          20          0.200148   \n",
       "                                                          21          0.176215   \n",
       "                                                          22          0.165004   \n",
       "                                                          23          0.148447   \n",
       "                                                          24          0.138806   \n",
       "                                                          25          0.126969   \n",
       "                                                          26          0.120334   \n",
       "                                                          27          0.111578   \n",
       "                                                          28          0.104124   \n",
       "                                                          29          0.098561   \n",
       "                                                          30          0.091350   \n",
       "                                       0.25    2048       1           4.731715   \n",
       "                                                          2           3.486802   \n",
       "                                                          3           2.644501   \n",
       "                                                          4           2.075440   \n",
       "                                                          5           1.662400   \n",
       "                                                          6           1.364773   \n",
       "                                                          7           1.136035   \n",
       "                                                          8           0.977622   \n",
       "                                                          9           0.837562   \n",
       "                                                          10          0.732793   \n",
       "                                                          11          0.640299   \n",
       "                                                          12          0.568246   \n",
       "                                                          13          0.506427   \n",
       "                                                          14          0.461093   \n",
       "                                                          15          0.422716   \n",
       "                                                          16          0.383820   \n",
       "                                                          17          0.352039   \n",
       "                                                          18          0.322917   \n",
       "                                                          19          0.308146   \n",
       "                                                          20          0.286340   \n",
       "                                                          21          0.259671   \n",
       "                                                          22          0.241406   \n",
       "                                                          23          0.220385   \n",
       "                                                          24          0.212844   \n",
       "                                                          25          0.196488   \n",
       "                                                          26          0.187556   \n",
       "                                                          27          0.181075   \n",
       "                                                          28          0.172204   \n",
       "                                                          29          0.163482   \n",
       "                                                          30          0.154945   \n",
       "\n",
       "                                                                 duration  \n",
       "lr    Nodes per layer Number of layers Dropout Batch size Epoch            \n",
       "0.001 1000            1                0.00    2048       1           196  \n",
       "                                                          2           195  \n",
       "                                                          3           195  \n",
       "                                                          4           196  \n",
       "                                                          5           195  \n",
       "                                                          6           195  \n",
       "                                                          7           195  \n",
       "                                                          8           197  \n",
       "                                                          9           195  \n",
       "                                                          10          196  \n",
       "                                                          11          196  \n",
       "                                                          12          195  \n",
       "                                                          13          196  \n",
       "                                                          14          196  \n",
       "                                                          15          196  \n",
       "                                                          16          196  \n",
       "                                                          17          195  \n",
       "                                                          18          195  \n",
       "                                                          19          196  \n",
       "                                                          20          195  \n",
       "                                                          21          195  \n",
       "                                                          22          195  \n",
       "                                                          23          195  \n",
       "                                                          24          194  \n",
       "                                                          25          194  \n",
       "                                                          26          194  \n",
       "                                                          27          195  \n",
       "                                                          28          195  \n",
       "                                                          29          194  \n",
       "                                                          30          195  \n",
       "                                       0.25    2048       1           194  \n",
       "                                                          2           194  \n",
       "                                                          3           194  \n",
       "                                                          4           194  \n",
       "                                                          5           194  \n",
       "                                                          6           194  \n",
       "                                                          7           195  \n",
       "                                                          8           194  \n",
       "                                                          9           194  \n",
       "                                                          10          194  \n",
       "                                                          11          194  \n",
       "                                                          12          194  \n",
       "                                                          13          194  \n",
       "                                                          14          195  \n",
       "                                                          15          194  \n",
       "                                                          16          194  \n",
       "                                                          17          194  \n",
       "                                                          18          194  \n",
       "                                                          19          194  \n",
       "                                                          20          194  \n",
       "                                                          21          194  \n",
       "                                                          22          195  \n",
       "                                                          23          194  \n",
       "                                                          24          197  \n",
       "                                                          25          194  \n",
       "                                                          26          194  \n",
       "                                                          27          194  \n",
       "                                                          28          194  \n",
       "                                                          29          194  \n",
       "                                                          30          194  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81533f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=300\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "lstm = eLSTM(num_classes=num_classes,\n",
    "             input_size=num_features,\n",
    "             hidden_size=1000,\n",
    "             num_layers=1,\n",
    "             dropout_prob=0,\n",
    "             skills=skills, \n",
    "             certs=certs,\n",
    "             licenses=licenses,\n",
    "             languages=languages,\n",
    "             addresses=addresses,\n",
    "             w2v=w2v,\n",
    "             skill_embedding_size=skill_embedding_size,\n",
    "             certs_embedding_size=certs_embedding_size,\n",
    "             license_embedding_size=license_embedding_size,\n",
    "             language_embedding_size=language_embedding_size,\n",
    "             address_embedding_size=address_embedding_size,\n",
    "             function_embedding_size=function_embedding_size,\n",
    "             isco4_embedding_size=isco4_embedding_size,\n",
    "             education_embedding_size=education_embedding_size,\n",
    "             isco_level_embedding_size=isco_level_embedding_size,\n",
    "             company_embedding_size=company_embedding_size,\n",
    "             candidate_lengths=candidate_lens,\n",
    "             max_len=max_len)\n",
    "\n",
    "lstm.load_state_dict(torch.load(\"../models/optimal_eCNN-LSTM.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a54f60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eLSTM(\n",
       "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
       "  (certs_embedding): Linear(in_features=98, out_features=50, bias=False)\n",
       "  (license_embedding): Linear(in_features=8, out_features=10, bias=False)\n",
       "  (language_embedding): Linear(in_features=23, out_features=15, bias=False)\n",
       "  (address_embedding): Embedding(4768, 25)\n",
       "  (function_embedding): Embedding(2992, 250)\n",
       "  (isco_code_embedding): Embedding(355, 150)\n",
       "  (company_embedding): Embedding(441153, 300)\n",
       "  (education_embedding): Embedding(6, 10)\n",
       "  (isco_level_embedding): Embedding(5, 10)\n",
       "  (conv2d): Conv2d(1, 1, kernel_size=(25, 1), stride=(1, 1), padding=(12, 0))\n",
       "  (convrelu): ReLU()\n",
       "  (LSTM): LSTM(2442, 1000, batch_first=True)\n",
       "  (attention): attention(\n",
       "    (att_fc): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (fc): Linear(in_features=2000, out_features=355, bias=True)\n",
       "  (softmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a0b3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader, test_loader = create_loaders(to_fill, idxs, y, split_size=0.99, \n",
    "                                                     weight_type=3, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfd9aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total.to_csv(\"../results/eCNN-LSTM-results_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36d89137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.7188048958778381\n",
      "\n",
      "Previous-job baseline accuracy: 0.0\n",
      "Majority class accuracy: 0.1195079086115993\n",
      "\n",
      "Fraction of previous job predictions: 0.0\n",
      "Majority class predictions: 0.11072056239015818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        career, job = career.to(device), job.to(device)\n",
    "        pred, weight, _ = lstm(candidate, career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())        \n",
    "        print()\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        previous_job = torch.Tensor(career_paths.loc[candidate.cpu()].apply(lambda x: x[-2][-1]).values).to(device)\n",
    "        print(\"Previous-job baseline accuracy:\", (job == previous_job).cpu().numpy().mean())\n",
    "        print(\"Majority class accuracy:\", (job == majority_class).cpu().numpy().mean())\n",
    "        print()\n",
    "        \n",
    "        print(\"Fraction of previous job predictions:\", (pred.argmax(1) == previous_job).cpu().numpy().mean())\n",
    "        print(\"Majority class predictions:\", (pred.argmax(1) == majority_class).cpu().numpy().mean())\n",
    " \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "                \n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # TODO: this now includes the last CNN layer\n",
    "        a = weight.cpu().detach().numpy().mean(axis=0)            \n",
    "        plt.plot(a, label=\"average\")\n",
    "        # plt.plot(weights[0][np.random.choice(range(len(weights[0])))].cpu().detach().numpy(), label=\"random example\")\n",
    "        plt.xlabel(\"Career step\")\n",
    "        plt.ylabel(\"Attention weight\")\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79d64fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = weight.cpu().detach().numpy()\n",
    "\n",
    "for _ in range(20):\n",
    "    c = np.random.randint(0, len(b))\n",
    "    plt.plot(b[c])\n",
    "    plt.xlabel(\"Career step\")\n",
    "    plt.ylabel(\"Attention weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d34b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guided_backprop():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None # store R0\n",
    "        self.activation_maps = []  # store f1, f2, ... \n",
    "        self.model.eval()\n",
    "        \n",
    "        self.update_relus()\n",
    "        \n",
    "    def update_relus(self):\n",
    "        \n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0] \n",
    "            \n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.named_children())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "        def forward_hook_fn(module, input, output):\n",
    "            self.activation_maps.append(output)\n",
    "\n",
    "        def backward_hook_fn(module, grad_in, grad_out):\n",
    "            grad = self.activation_maps.pop() \n",
    "            # for the forward pass, after the ReLU operation, \n",
    "            # if the output value is positive, we set the value to 1,\n",
    "            # and if the output value is negative, we set it to 0.\n",
    "            grad[grad > 0] = 1 \n",
    "            \n",
    "            # grad_out[0] stores the gradients for each feature map,\n",
    "            # and we only retain the positive gradients\n",
    "            positive_grad_out = torch.clamp(grad_out[0], min=0.0)\n",
    "            new_grad_in = positive_grad_out * grad\n",
    "\n",
    "            return (new_grad_in,)\n",
    "        \n",
    "        modules = list(self.model.named_children())\n",
    "                        \n",
    "        # travese the modules，register forward hook & backward hook\n",
    "        # for the ReLU\n",
    "        for name, module in modules:\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                module.register_forward_hook(forward_hook_fn)\n",
    "                module.register_backward_hook(backward_hook_fn)\n",
    "                                \n",
    "        # register backward hook for the first conv relu layer\n",
    "        name, first_layer = modules[-6]\n",
    "        \n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def generate_gradients(self, candidate, career, target_class):        \n",
    "        model_output, weight, career_duration = self.model(candidate, career)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred_class = model_output.argmax().item()\n",
    "                            \n",
    "        grad_target_map = torch.zeros(model_output.shape,\n",
    "                                      dtype=torch.float).to(device)\n",
    "        if target_class is not None:\n",
    "            grad_target_map[0][target_class] = 1\n",
    "        else:\n",
    "            grad_target_map[0][pred_class] = 1\n",
    "        \n",
    "        model_output.backward(grad_target_map)\n",
    "        \n",
    "        result = self.gradients.data[0].numpy()[0]\n",
    "        return result, weight, pred_class, career_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37eeee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e4263a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result / result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9eeb5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, isco_level, source, education, company_name, function_id, isco_code, w2v_list, skill_list, certs_list, license_list, langs_list, address_emb\n",
    "feature_names = [\"Time spent\", \"isco level\", \"education\", \"company name\", \"function\", \"isco code\",\n",
    "                 \"cv\", \"skills\", \"certificates\", \"licenses\", \"languages\", \"location\"]\n",
    "\n",
    "# skill_embedding_size=50\n",
    "# certs_embedding_size=20\n",
    "# license_embedding_size=3\n",
    "# language_embedding_size=10\n",
    "# address_embedding_size=25\n",
    "# function_embedding_size=50 \n",
    "# isco4_embedding_size=25\n",
    "# education_embedding_size=3\n",
    "# isco_level_embedding_size=3\n",
    "# company_embedding_size=50\n",
    "# w2v_embedding_size = 300\n",
    "\n",
    "embedding_sizes= [0, 1, isco_level_embedding_size, education_embedding_size, company_embedding_size, function_embedding_size, \n",
    "                  isco4_embedding_size, w2v_embedding_size, skill_embedding_size, certs_embedding_size, \n",
    "                  license_embedding_size, language_embedding_size, address_embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20ac8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(model, dataloader, candidate_id=8443697):\n",
    "    guided_bp = Guided_backprop(model.to(device))\n",
    "\n",
    "    candidate, career, job = next(iter(dataloader))\n",
    "    i = 0\n",
    "    \n",
    "    while candidate_id not in candidate:\n",
    "        print(f\"{i}/{len(dataloader)}\", end=\"\\r\")\n",
    "        candidate, career, job = next(iter(dataloader))\n",
    "        i += 1\n",
    "        \n",
    "    candidate_loc = (candidate == candidate_id).type(torch.LongTensor).argmax()\n",
    "\n",
    "    candidate, career = candidate[candidate_loc].unsqueeze(0), career[candidate_loc].unsqueeze(0).to(device)\n",
    "    correct = job[candidate_loc].item()\n",
    "          \n",
    "    result, weight, pred_class, career_duration = guided_bp.generate_gradients(candidate, career, None)\n",
    "    \n",
    "    return result, weight, pred_class, correct, career, candidate, career_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02f4d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_layers(output, embedding_sizes):\n",
    "    \"\"\"order: start=0, reg_features, isco_level_embedding_size, source_embedding_size, \n",
    "              education_embedding_size, company_embedding_size, function_embedding_size, \n",
    "              isco4_embedding_size, w2v_embedding_size, skill_embedding_size, \n",
    "              certs_embedding_size, license_embedding_size, language_embedding_size, \n",
    "              address_embedding_size\"\"\"\n",
    "    \n",
    "    idxs = np.cumsum(embedding_sizes)\n",
    "        \n",
    "    result = np.stack([output[idxs[i]:idxs[i+1]].mean(axis=0) for i in range(len(idxs) - 1)])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed9fecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_explanation(model, dataloader, embedding_sizes, feature_names, candidate_id=8443697, lang=\"en\"):\n",
    "    \n",
    "    if lang != \"en\":        \n",
    "        feature_names = [\"Dagen gewerkt\", \"Werkniveau\", \"Opleidingsniveau\", \"Bedrijf\", \"Functie\", \"Isco code\",\n",
    "                         \"CV\", \"Vaardigheden\", \"Certificaten\", \"Rijbewijzen\", \"Talen\", \"Postcode\"]\n",
    "        \n",
    "\n",
    "    # Find gradients, attention weights, prediction, and ground truth\n",
    "    result, weight, pred_class, correct, career, candidate, career_duration = calculate_gradients(model, dataloader, candidate_id=candidate_id)\n",
    "\n",
    "    result = result[-career_duration:]\n",
    "    weight = weight.detach().cpu().numpy()[0][-career_duration:]\n",
    "\n",
    "    # Convert embedded features to regular features by taking the mean per embedding dimension\n",
    "    to_plot = merge_layers(result.T, embedding_sizes)\n",
    "    to_plot[to_plot < 0] = 0\n",
    "    \n",
    "    # Sum each feature over the time dimension and normalize    \n",
    "    feature_weight = to_plot.T.sum(axis=0)\n",
    "    feature_weight /= feature_weight.sum()\n",
    "\n",
    "    print(f\"Current candidate id: {int(candidate.item())}\")\n",
    "    print(f\"Predicted class: {pred_class + 1}\\nActual class: {correct + 1}\")\n",
    "\n",
    "    # Sum each feature over the time dimension and normalize    \n",
    "    feature_weight = to_plot.T.sum(axis=0)    \n",
    "    # feature_weight *= (values.T.sum(axis=0) != 0)\n",
    "    feature_weight /= feature_weight.sum()\n",
    "\n",
    "    # Normalized feature attention \n",
    "    series = pd.Series(feature_weight, index=feature_names).sort_values(ascending=False) \n",
    "    \n",
    "    series.to_csv(f\"values_{candidate_id}\")\n",
    "\n",
    "    # Create grid\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    grid = plt.GridSpec(2, 2, wspace=0.35, hspace=0.5)\n",
    "    grid.update(top=0.9)\n",
    "\n",
    "    ax1 = plt.subplot(grid[0, 0])\n",
    "    ax2 = plt.subplot(grid[0, 1])\n",
    "    ax3 = plt.subplot(grid[1, :])\n",
    "    # ax4 = plt.subplot(grid[2, :2])\n",
    "\n",
    "    fig.suptitle(\"Attention types\")\n",
    "\n",
    "    # Plot total attention for each feature\n",
    "    sns.barplot(x=series.values, y=series.index, ax=ax1)\n",
    "    # ax1.set_xticklabels(labels=series.values, rotation=90)\n",
    "    ax1.set_ylabel(\"Gradient\")\n",
    "    ax1.set_title(\"Attention per feature\")\n",
    "    \n",
    "    series2 = pd.Series(dict(zip(range(1, career_duration + 1), weight)))\n",
    "\n",
    "    sns.barplot(x=series2.index, y=series2.values, ax=ax2)\n",
    "\n",
    "    ax2.set_title(\"Attention per time step\")\n",
    "    ax2.set_ylabel(\"Attention score\")\n",
    "    ax2.set_xlabel(\"Time step\")\n",
    "\n",
    "\n",
    "    cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n",
    "\n",
    "    # Normalize gradients\n",
    "    # to_plot *= (values.sum(axis=0) != 0)\n",
    "    to_plot /= to_plot.max() \n",
    "    to_plot = scipy.special.softmax(to_plot, axis=0) * 100\n",
    "    to_plot = pd.DataFrame(to_plot)\n",
    "\n",
    "    to_plot.index = feature_names\n",
    "    to_plot.columns = range(1, career_duration + 1)\n",
    "\n",
    "    to_plot = to_plot.loc[series.index]\n",
    "\n",
    "\n",
    "    sns.heatmap(to_plot, cmap=cmap, xticklabels=to_plot.columns, yticklabels=to_plot.index, \n",
    "                cbar_kws={'label': 'Gradient'}, linewidths=0.1, ax=ax3)\n",
    "\n",
    "    ax3.set_title(\"Spatiotemporal attention\")\n",
    "    ax3.set_xlabel(\"Time step\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f\"examples/eCNN-LSTM_example.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f33fe7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a50e6126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current candidate id: 7112518\n",
      "Predicted class: 235\n",
      "Actual class: 235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_explanation(lstm, trainloader, embedding_sizes, feature_names, candidate_id=7112518)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f679504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
