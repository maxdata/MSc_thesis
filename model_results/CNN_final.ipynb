{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d6f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07aedc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7205c568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770d9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71031d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0762ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2584ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d14f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e4cc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dece6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d441860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85bdd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2081a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b96f9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fa5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd38ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848df268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  time_spent  isco_functie_niveau  education  company_name  \\\n",
       "0         84556   -0.210459                  2.0        0.0        324258   \n",
       "1         84556   -0.252626                  1.0        0.0        324258   \n",
       "2         84556   -0.085012                  2.0        0.0        329244   \n",
       "3         84556   -0.370694                  1.0        0.0        368140   \n",
       "4         84556   -0.363314                  1.0        0.0        419826   \n",
       "\n",
       "   function_id  isco_code4  \n",
       "0          936         208  \n",
       "1          809         348  \n",
       "2          936         208  \n",
       "3         1519         344  \n",
       "4         1519         344  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf57e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8aa88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c17c21c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404db13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61860616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:47<00:00, 9862.28it/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6d4ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "605c3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3537929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[-0.21045870102048395, 2.0, 0.0, 324258.0, 93...\n",
       "84612    [[-0.3685852264755267, 1.0, 0.0, 201740.0, 151...\n",
       "84731    [[-0.35066422025728855, 1.0, 0.0, 353745.0, 15...\n",
       "85437    [[0.3313881928721292, 1.0, 2.0, 5500.0, 1519.0...\n",
       "85888    [[-0.2895219637480053, 2.0, 3.0, 423330.0, 795...\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1135d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78a2f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4ed3080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8ad0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180e998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83dd22e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9f39f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:50000]\n",
    "# y = y[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "135092c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "    test, validation = test[:(len(test) // 2)], test[(len(test) // 2):]\n",
    "\n",
    "    train_indices, val_indices, test_indices = idxs[training], idxs[validation], idxs[test]\n",
    "    X_train, X_val, X_test = to_fill[training], to_fill[validation], to_fill[test]\n",
    "    y_train, y_val, y_test = y[training].astype(int), y[validation].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_data = TensorDataset(torch.Tensor(test_indices),\n",
    "                             torch.Tensor(X_test),\n",
    "                             torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb8adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, f_out,\n",
    "                 kernel_size, pooling_size, dropout,                \n",
    "                 skills, certs, licenses, languages, \n",
    "                 addresses, w2v, candidate_lengths, max_len, \n",
    "                 skill_embedding_size=50, certs_embedding_size=20,\n",
    "                 license_embedding_size=3, language_embedding_size=10,\n",
    "                 address_embedding_size=25, function_embedding_size=50, \n",
    "                 isco4_embedding_size=25, education_embedding_size=3, \n",
    "                 isco_level_embedding_size=3, company_embedding_size=50):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size + 300\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        \n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.source_embedding = nn.Embedding(2, 1)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(6, isco_level_embedding_size)\n",
    "        \n",
    "        # -6 --> embedded features get replaced\n",
    "        N = self.input_size - 5 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "        \n",
    "        # Actual model\n",
    "        self.conv2d = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=f_out, \n",
    "                                kernel_size=(kernel_size, kernel_size), \n",
    "                                stride=1, \n",
    "                                padding=(kernel_size // 2))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpooling = nn.MaxPool3d(kernel_size=(f_out, pooling_size, pooling_size))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear((N // pooling_size) * (max_len // pooling_size), num_classes)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        \n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len        \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])\n",
    "    \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "                        \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:\n",
    "                    # 0, 10, 20, 30, 40, 50\n",
    "                    # duration = 50\n",
    "                    # ---> 0, 5, 15, 25\n",
    "                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * 300).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    " \n",
    "    def forward(self, candidate, x):               \n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * 500).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "        \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "                        \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "            \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                   \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "                \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "                \n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc(x)\n",
    "               \n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33beff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "        \n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            \n",
    "            career, job = career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(candidate, career)\n",
    "                        \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "               \n",
    "        training_loss /= len(trainloader)\n",
    "                \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int((done) // 60)}:{int((done) % 60):02d}\")\n",
    "            \n",
    "        stats = test_loop(valloader, testloader, model, criterion)\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"test_loss\"].append(stats[3])\n",
    "        results[\"Acc@1 (test)\"].append(stats[4])\n",
    "        results[\"Acc@5 (test)\"].append(stats[5])\n",
    "        results[\"Acc@10 (test)\"].append(stats[6])\n",
    "        results[\"test_loss (test)\"].append(stats[7])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        results[\"duration\"].append(done)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/CNN_optimal.pt\")\n",
    "            highest_performance = stats[0]\n",
    "                    \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, testloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    print(f\"\\nVal Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    size_2 = len(testloader.dataset)\n",
    "    num_batches_2 = len(testloader)\n",
    "    test_loss_2, acc1_2, acc5_2, acc10_2 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in testloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred = model(candidate, career)\n",
    "            \n",
    "            test_loss_2 += criterion(pred, job).mean().item()\n",
    "            acc1_2 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5_2 = []\n",
    "            at10_2 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5_2.append(answer.item() in predictions[:5])\n",
    "                at10_2.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5_2 += np.sum(at5_2)\n",
    "            acc10_2 += np.sum(at10_2)\n",
    "            \n",
    "    test_loss_2 /= num_batches_2\n",
    "    acc1_2 /= size_2\n",
    "    acc5_2 /= size_2\n",
    "    acc10_2 /= size_2\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1_2):>0.2f}%, Acc@5: {100*acc5_2:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10_2:>0.2f}%, Avg loss: {test_loss_2:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, test_loss, acc1_2, acc5_2, acc10_2, test_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5d26ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Initial learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " CNN(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=50, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=10, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=15, bias=False)\n",
      "  (address_embedding): Embedding(4768, 25)\n",
      "  (function_embedding): Embedding(2992, 250)\n",
      "  (isco_code_embedding): Embedding(355, 150)\n",
      "  (company_embedding): Embedding(441153, 300)\n",
      "  (source_embedding): Embedding(2, 1)\n",
      "  (education_embedding): Embedding(6, 10)\n",
      "  (isco_level_embedding): Embedding(6, 10)\n",
      "  (conv2d): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu): ReLU()\n",
      "  (maxpooling): MaxPool3d(kernel_size=(64, 1, 1), stride=(64, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (fc): Linear(in_features=30525, out_features=355, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ") \n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:18:31\n",
      "Epoch duration: 4:32/711, loss: 2.53185\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.36%, Acc@5: 46.63%, Acc@10: 60.22% Avg loss: 3.719886\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 19.13%, Acc@5: 45.79%, Acc@10: 58.67%, Avg loss: 4.143151\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:23:36\n",
      "Epoch duration: 4:32/711, loss: 1.90977\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 17.01%, Acc@5: 44.68%, Acc@10: 58.14% Avg loss: 3.891287\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 16.64%, Acc@5: 43.76%, Acc@10: 57.70%, Avg loss: 4.837991\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:28:40\n",
      "Epoch duration: 4:32/711, loss: 1.40632\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 18.41%, Acc@5: 43.71%, Acc@10: 58.54% Avg loss: 4.105157\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 18.91%, Acc@5: 44.87%, Acc@10: 58.97%, Avg loss: 5.319616\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:33:44\n",
      "Epoch duration: 4:32/711, loss: 0.98425\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 17.99%, Acc@5: 43.36%, Acc@10: 56.85% Avg loss: 4.349128\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 18.04%, Acc@5: 43.98%, Acc@10: 57.81%, Avg loss: 5.980409\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:38:48\n",
      "Epoch duration: 4:32/711, loss: 1.26504\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 18.44%, Acc@5: 45.48%, Acc@10: 60.00% Avg loss: 4.520390\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 18.07%, Acc@5: 46.20%, Acc@10: 60.17%, Avg loss: 6.243482\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:43:54\n",
      "Epoch duration: 4:32/711, loss: 0.46686\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.38%, Acc@5: 46.92%, Acc@10: 61.02% Avg loss: 4.495691\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 19.86%, Acc@5: 49.38%, Acc@10: 62.68%, Avg loss: 6.038042\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:49:08\n",
      "Epoch duration: 4:32/711, loss: 0.59440\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 18.90%, Acc@5: 46.85%, Acc@10: 61.20% Avg loss: 4.612164\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.18%, Acc@5: 49.82%, Acc@10: 63.06%, Avg loss: 6.278029\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:54:13\n",
      "Epoch duration: 4:32/711, loss: 0.61011\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.59%, Acc@5: 47.32%, Acc@10: 61.53% Avg loss: 4.681600\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.32%, Acc@5: 50.16%, Acc@10: 63.48%, Avg loss: 6.420602\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 22:59:28\n",
      "Epoch duration: 4:32/711, loss: 0.65609\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.26%, Acc@5: 47.38%, Acc@10: 61.44% Avg loss: 4.779632\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.41%, Acc@5: 49.96%, Acc@10: 63.55%, Avg loss: 6.591115\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:04:33\n",
      "Epoch duration: 4:321/711, loss: 0.67467\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.83%, Acc@5: 47.79%, Acc@10: 61.83% Avg loss: 4.881277\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.65%, Acc@5: 50.39%, Acc@10: 63.44%, Avg loss: 6.765184\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:09:48\n",
      "Epoch duration: 4:321/711, loss: 0.52751\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.85%, Acc@5: 47.93%, Acc@10: 62.24% Avg loss: 4.885925\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.83%, Acc@5: 50.53%, Acc@10: 63.59%, Avg loss: 6.787966\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:15:04\n",
      "Epoch duration: 4:321/711, loss: 0.61880\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.77%, Acc@5: 47.87%, Acc@10: 62.03% Avg loss: 4.898150\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.69%, Acc@5: 50.73%, Acc@10: 63.60%, Avg loss: 6.808068\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:20:08\n",
      "Epoch duration: 4:321/711, loss: 0.59788\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.77%, Acc@5: 47.81%, Acc@10: 62.03% Avg loss: 4.905997\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.71%, Acc@5: 50.55%, Acc@10: 63.66%, Avg loss: 6.811875\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:25:11\n",
      "Epoch duration: 4:321/711, loss: 0.44739\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.70%, Acc@5: 47.88%, Acc@10: 62.08% Avg loss: 4.920237\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.75%, Acc@5: 50.84%, Acc@10: 63.65%, Avg loss: 6.842018\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:30:16\n",
      "Epoch duration: 4:321/711, loss: 0.52783\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.56%, Acc@5: 47.73%, Acc@10: 62.12% Avg loss: 4.928779\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.49%, Acc@5: 50.65%, Acc@10: 63.65%, Avg loss: 6.845501\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:35:20\n",
      "Epoch duration: 4:321/711, loss: 0.55091\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.73%, Acc@5: 47.85%, Acc@10: 62.18% Avg loss: 4.928499\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.53%, Acc@5: 50.73%, Acc@10: 63.62%, Avg loss: 6.847522\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:40:24\n",
      "Epoch duration: 4:321/711, loss: 0.57745\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.75%, Acc@5: 47.89%, Acc@10: 62.18% Avg loss: 4.929075\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.66%, Acc@5: 50.83%, Acc@10: 63.63%, Avg loss: 6.853330\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:45:28\n",
      "Epoch duration: 4:321/711, loss: 0.48272\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.71%, Acc@5: 47.90%, Acc@10: 62.16% Avg loss: 4.930210\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.72%, Acc@5: 50.81%, Acc@10: 63.64%, Avg loss: 6.856946\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:50:32\n",
      "Epoch duration: 4:321/711, loss: 0.54554\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.75%, Acc@5: 47.90%, Acc@10: 62.19% Avg loss: 4.933382\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.80%, Acc@5: 50.85%, Acc@10: 63.72%, Avg loss: 6.859578\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 23:55:37\n",
      "Epoch duration: 4:321/711, loss: 0.58138\n",
      "\n",
      "Val Error:\n",
      "Acc@1: 19.77%, Acc@5: 47.85%, Acc@10: 62.20% Avg loss: 4.933428\n",
      "\n",
      "Test Error:\n",
      "Acc@1: 20.78%, Acc@5: 50.82%, Acc@10: 63.74%, Avg loss: 6.862931\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 20\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-3]\n",
    "f_outs = [64]\n",
    "kernel_sizes = [5]\n",
    "pooling_sizes = [1]\n",
    "batch_sizes = [128]\n",
    "dropout_probs = [0.0]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=300\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            for f_out in f_outs:\n",
    "                for kernel_size in kernel_sizes:\n",
    "                    for pooling_size in pooling_sizes:\n",
    "                        for dropout in dropout_probs:\n",
    "\n",
    "                            cnn = CNN(num_classes=num_classes,\n",
    "                                      input_size=num_features,\n",
    "                                      f_out=f_out,\n",
    "                                      pooling_size=pooling_size,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      dropout=dropout,\n",
    "                                      skills=skills, \n",
    "                                      certs=certs,\n",
    "                                      licenses=licenses,\n",
    "                                      languages=languages,\n",
    "                                      addresses=addresses,\n",
    "                                      w2v=w2v,\n",
    "                                      skill_embedding_size=skill_embedding_size,\n",
    "                                      certs_embedding_size=certs_embedding_size,\n",
    "                                      license_embedding_size=license_embedding_size,\n",
    "                                      language_embedding_size=language_embedding_size,\n",
    "                                      address_embedding_size=address_embedding_size,\n",
    "                                      function_embedding_size=function_embedding_size,\n",
    "                                      isco4_embedding_size=isco4_embedding_size,\n",
    "                                      education_embedding_size=education_embedding_size,\n",
    "                                      isco_level_embedding_size=isco_level_embedding_size,\n",
    "                                      company_embedding_size=company_embedding_size,\n",
    "                                      candidate_lengths=candidate_lens,\n",
    "                                      max_len=max_len)\n",
    "\n",
    "                            cnn = cnn.to(device)\n",
    "\n",
    "                            optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "                            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "                            print(f\"- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", cnn, \"\\n\")\n",
    "\n",
    "                            trainloader, valloader, testloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                                                weight_type=3, batch_size=batch_size)\n",
    "\n",
    "                            # Store results of current configuration\n",
    "                            outcome = train_loop(cnn, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                            outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                            outcome[\"Batch size\"] = [batch_size] * num_epochs\n",
    "                            outcome[\"Number of filters\"] = [f_out] * num_epochs\n",
    "                            outcome[\"Kernel size\"] = [kernel_size] * num_epochs\n",
    "                            outcome[\"Pooling size\"] = [pooling_size] * num_epochs\n",
    "                            outcome[\"Dropout\"] = [dropout] * num_epochs\n",
    "\n",
    "                            full_results.append(outcome)\n",
    "                            current += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b42ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Batch size\", \"Number of filters\", \"Kernel size\", \"Pooling size\", \"Dropout\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82fd7008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>Acc@1 (test)</th>\n",
       "      <th>Acc@5 (test)</th>\n",
       "      <th>Acc@10 (test)</th>\n",
       "      <th>test_loss (test)</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Number of filters</th>\n",
       "      <th>Kernel size</th>\n",
       "      <th>Pooling size</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">64</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">0.0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.193616</td>\n",
       "      <td>0.466280</td>\n",
       "      <td>0.602216</td>\n",
       "      <td>3.719886</td>\n",
       "      <td>0.191347</td>\n",
       "      <td>0.457879</td>\n",
       "      <td>0.586704</td>\n",
       "      <td>4.143151</td>\n",
       "      <td>5.299506</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170052</td>\n",
       "      <td>0.446848</td>\n",
       "      <td>0.581377</td>\n",
       "      <td>3.891287</td>\n",
       "      <td>0.166374</td>\n",
       "      <td>0.437566</td>\n",
       "      <td>0.577031</td>\n",
       "      <td>4.837991</td>\n",
       "      <td>2.308818</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.184120</td>\n",
       "      <td>0.437088</td>\n",
       "      <td>0.585422</td>\n",
       "      <td>4.105157</td>\n",
       "      <td>0.189149</td>\n",
       "      <td>0.448734</td>\n",
       "      <td>0.589694</td>\n",
       "      <td>5.319616</td>\n",
       "      <td>1.567526</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.433571</td>\n",
       "      <td>0.568452</td>\n",
       "      <td>4.349128</td>\n",
       "      <td>0.180355</td>\n",
       "      <td>0.439764</td>\n",
       "      <td>0.578087</td>\n",
       "      <td>5.980409</td>\n",
       "      <td>1.190234</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.184384</td>\n",
       "      <td>0.454761</td>\n",
       "      <td>0.600018</td>\n",
       "      <td>4.520390</td>\n",
       "      <td>0.180707</td>\n",
       "      <td>0.462012</td>\n",
       "      <td>0.601741</td>\n",
       "      <td>6.243482</td>\n",
       "      <td>0.953074</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.193792</td>\n",
       "      <td>0.469181</td>\n",
       "      <td>0.610217</td>\n",
       "      <td>4.495691</td>\n",
       "      <td>0.198646</td>\n",
       "      <td>0.493757</td>\n",
       "      <td>0.626803</td>\n",
       "      <td>6.038042</td>\n",
       "      <td>0.754955</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.188956</td>\n",
       "      <td>0.468478</td>\n",
       "      <td>0.611976</td>\n",
       "      <td>4.612164</td>\n",
       "      <td>0.201811</td>\n",
       "      <td>0.498241</td>\n",
       "      <td>0.630584</td>\n",
       "      <td>6.278029</td>\n",
       "      <td>0.695770</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.195903</td>\n",
       "      <td>0.473226</td>\n",
       "      <td>0.615317</td>\n",
       "      <td>4.681600</td>\n",
       "      <td>0.203218</td>\n",
       "      <td>0.501583</td>\n",
       "      <td>0.634805</td>\n",
       "      <td>6.420602</td>\n",
       "      <td>0.638940</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.192649</td>\n",
       "      <td>0.473754</td>\n",
       "      <td>0.614438</td>\n",
       "      <td>4.779632</td>\n",
       "      <td>0.204098</td>\n",
       "      <td>0.499560</td>\n",
       "      <td>0.635508</td>\n",
       "      <td>6.591115</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.198277</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>0.618307</td>\n",
       "      <td>4.881277</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.503869</td>\n",
       "      <td>0.634365</td>\n",
       "      <td>6.765184</td>\n",
       "      <td>0.566617</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.198540</td>\n",
       "      <td>0.479293</td>\n",
       "      <td>0.622351</td>\n",
       "      <td>4.885925</td>\n",
       "      <td>0.208319</td>\n",
       "      <td>0.505276</td>\n",
       "      <td>0.635948</td>\n",
       "      <td>6.787966</td>\n",
       "      <td>0.536378</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.197661</td>\n",
       "      <td>0.478678</td>\n",
       "      <td>0.620329</td>\n",
       "      <td>4.898150</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>0.507299</td>\n",
       "      <td>0.636036</td>\n",
       "      <td>6.808068</td>\n",
       "      <td>0.542972</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.197661</td>\n",
       "      <td>0.478062</td>\n",
       "      <td>0.620329</td>\n",
       "      <td>4.905997</td>\n",
       "      <td>0.207088</td>\n",
       "      <td>0.505540</td>\n",
       "      <td>0.636563</td>\n",
       "      <td>6.811875</td>\n",
       "      <td>0.540399</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.197046</td>\n",
       "      <td>0.478765</td>\n",
       "      <td>0.620768</td>\n",
       "      <td>4.920237</td>\n",
       "      <td>0.207527</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.636476</td>\n",
       "      <td>6.842018</td>\n",
       "      <td>0.540239</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.195639</td>\n",
       "      <td>0.477271</td>\n",
       "      <td>0.621208</td>\n",
       "      <td>4.928779</td>\n",
       "      <td>0.204889</td>\n",
       "      <td>0.506507</td>\n",
       "      <td>0.636476</td>\n",
       "      <td>6.845501</td>\n",
       "      <td>0.529268</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.197309</td>\n",
       "      <td>0.478502</td>\n",
       "      <td>0.621824</td>\n",
       "      <td>4.928499</td>\n",
       "      <td>0.205329</td>\n",
       "      <td>0.507299</td>\n",
       "      <td>0.636212</td>\n",
       "      <td>6.847522</td>\n",
       "      <td>0.527188</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.197485</td>\n",
       "      <td>0.478941</td>\n",
       "      <td>0.621824</td>\n",
       "      <td>4.929075</td>\n",
       "      <td>0.206560</td>\n",
       "      <td>0.508266</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>6.853330</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.197134</td>\n",
       "      <td>0.479029</td>\n",
       "      <td>0.621560</td>\n",
       "      <td>4.930210</td>\n",
       "      <td>0.207176</td>\n",
       "      <td>0.508090</td>\n",
       "      <td>0.636388</td>\n",
       "      <td>6.856946</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.197485</td>\n",
       "      <td>0.479029</td>\n",
       "      <td>0.621912</td>\n",
       "      <td>4.933382</td>\n",
       "      <td>0.207967</td>\n",
       "      <td>0.508530</td>\n",
       "      <td>0.637179</td>\n",
       "      <td>6.859578</td>\n",
       "      <td>0.524891</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.478502</td>\n",
       "      <td>0.621999</td>\n",
       "      <td>4.933428</td>\n",
       "      <td>0.207791</td>\n",
       "      <td>0.508178</td>\n",
       "      <td>0.637355</td>\n",
       "      <td>6.862931</td>\n",
       "      <td>0.524130</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Acc@1  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch             \n",
       "0.001 128        64                5           1            0.0     1      0.193616   \n",
       "                                                                    2      0.170052   \n",
       "                                                                    3      0.184120   \n",
       "                                                                    4      0.179900   \n",
       "                                                                    5      0.184384   \n",
       "                                                                    6      0.193792   \n",
       "                                                                    7      0.188956   \n",
       "                                                                    8      0.195903   \n",
       "                                                                    9      0.192649   \n",
       "                                                                    10     0.198277   \n",
       "                                                                    11     0.198540   \n",
       "                                                                    12     0.197661   \n",
       "                                                                    13     0.197661   \n",
       "                                                                    14     0.197046   \n",
       "                                                                    15     0.195639   \n",
       "                                                                    16     0.197309   \n",
       "                                                                    17     0.197485   \n",
       "                                                                    18     0.197134   \n",
       "                                                                    19     0.197485   \n",
       "                                                                    20     0.197749   \n",
       "\n",
       "                                                                              Acc@5  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch             \n",
       "0.001 128        64                5           1            0.0     1      0.466280   \n",
       "                                                                    2      0.446848   \n",
       "                                                                    3      0.437088   \n",
       "                                                                    4      0.433571   \n",
       "                                                                    5      0.454761   \n",
       "                                                                    6      0.469181   \n",
       "                                                                    7      0.468478   \n",
       "                                                                    8      0.473226   \n",
       "                                                                    9      0.473754   \n",
       "                                                                    10     0.477886   \n",
       "                                                                    11     0.479293   \n",
       "                                                                    12     0.478678   \n",
       "                                                                    13     0.478062   \n",
       "                                                                    14     0.478765   \n",
       "                                                                    15     0.477271   \n",
       "                                                                    16     0.478502   \n",
       "                                                                    17     0.478941   \n",
       "                                                                    18     0.479029   \n",
       "                                                                    19     0.479029   \n",
       "                                                                    20     0.478502   \n",
       "\n",
       "                                                                             Acc@10  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch             \n",
       "0.001 128        64                5           1            0.0     1      0.602216   \n",
       "                                                                    2      0.581377   \n",
       "                                                                    3      0.585422   \n",
       "                                                                    4      0.568452   \n",
       "                                                                    5      0.600018   \n",
       "                                                                    6      0.610217   \n",
       "                                                                    7      0.611976   \n",
       "                                                                    8      0.615317   \n",
       "                                                                    9      0.614438   \n",
       "                                                                    10     0.618307   \n",
       "                                                                    11     0.622351   \n",
       "                                                                    12     0.620329   \n",
       "                                                                    13     0.620329   \n",
       "                                                                    14     0.620768   \n",
       "                                                                    15     0.621208   \n",
       "                                                                    16     0.621824   \n",
       "                                                                    17     0.621824   \n",
       "                                                                    18     0.621560   \n",
       "                                                                    19     0.621912   \n",
       "                                                                    20     0.621999   \n",
       "\n",
       "                                                                           test_loss  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch              \n",
       "0.001 128        64                5           1            0.0     1       3.719886   \n",
       "                                                                    2       3.891287   \n",
       "                                                                    3       4.105157   \n",
       "                                                                    4       4.349128   \n",
       "                                                                    5       4.520390   \n",
       "                                                                    6       4.495691   \n",
       "                                                                    7       4.612164   \n",
       "                                                                    8       4.681600   \n",
       "                                                                    9       4.779632   \n",
       "                                                                    10      4.881277   \n",
       "                                                                    11      4.885925   \n",
       "                                                                    12      4.898150   \n",
       "                                                                    13      4.905997   \n",
       "                                                                    14      4.920237   \n",
       "                                                                    15      4.928779   \n",
       "                                                                    16      4.928499   \n",
       "                                                                    17      4.929075   \n",
       "                                                                    18      4.930210   \n",
       "                                                                    19      4.933382   \n",
       "                                                                    20      4.933428   \n",
       "\n",
       "                                                                           Acc@1 (test)  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch                 \n",
       "0.001 128        64                5           1            0.0     1          0.191347   \n",
       "                                                                    2          0.166374   \n",
       "                                                                    3          0.189149   \n",
       "                                                                    4          0.180355   \n",
       "                                                                    5          0.180707   \n",
       "                                                                    6          0.198646   \n",
       "                                                                    7          0.201811   \n",
       "                                                                    8          0.203218   \n",
       "                                                                    9          0.204098   \n",
       "                                                                    10         0.206472   \n",
       "                                                                    11         0.208319   \n",
       "                                                                    12         0.206912   \n",
       "                                                                    13         0.207088   \n",
       "                                                                    14         0.207527   \n",
       "                                                                    15         0.204889   \n",
       "                                                                    16         0.205329   \n",
       "                                                                    17         0.206560   \n",
       "                                                                    18         0.207176   \n",
       "                                                                    19         0.207967   \n",
       "                                                                    20         0.207791   \n",
       "\n",
       "                                                                           Acc@5 (test)  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch                 \n",
       "0.001 128        64                5           1            0.0     1          0.457879   \n",
       "                                                                    2          0.437566   \n",
       "                                                                    3          0.448734   \n",
       "                                                                    4          0.439764   \n",
       "                                                                    5          0.462012   \n",
       "                                                                    6          0.493757   \n",
       "                                                                    7          0.498241   \n",
       "                                                                    8          0.501583   \n",
       "                                                                    9          0.499560   \n",
       "                                                                    10         0.503869   \n",
       "                                                                    11         0.505276   \n",
       "                                                                    12         0.507299   \n",
       "                                                                    13         0.505540   \n",
       "                                                                    14         0.508442   \n",
       "                                                                    15         0.506507   \n",
       "                                                                    16         0.507299   \n",
       "                                                                    17         0.508266   \n",
       "                                                                    18         0.508090   \n",
       "                                                                    19         0.508530   \n",
       "                                                                    20         0.508178   \n",
       "\n",
       "                                                                           Acc@10 (test)  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch                  \n",
       "0.001 128        64                5           1            0.0     1           0.586704   \n",
       "                                                                    2           0.577031   \n",
       "                                                                    3           0.589694   \n",
       "                                                                    4           0.578087   \n",
       "                                                                    5           0.601741   \n",
       "                                                                    6           0.626803   \n",
       "                                                                    7           0.630584   \n",
       "                                                                    8           0.634805   \n",
       "                                                                    9           0.635508   \n",
       "                                                                    10          0.634365   \n",
       "                                                                    11          0.635948   \n",
       "                                                                    12          0.636036   \n",
       "                                                                    13          0.636563   \n",
       "                                                                    14          0.636476   \n",
       "                                                                    15          0.636476   \n",
       "                                                                    16          0.636212   \n",
       "                                                                    17          0.636300   \n",
       "                                                                    18          0.636388   \n",
       "                                                                    19          0.637179   \n",
       "                                                                    20          0.637355   \n",
       "\n",
       "                                                                           test_loss (test)  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch                     \n",
       "0.001 128        64                5           1            0.0     1              4.143151   \n",
       "                                                                    2              4.837991   \n",
       "                                                                    3              5.319616   \n",
       "                                                                    4              5.980409   \n",
       "                                                                    5              6.243482   \n",
       "                                                                    6              6.038042   \n",
       "                                                                    7              6.278029   \n",
       "                                                                    8              6.420602   \n",
       "                                                                    9              6.591115   \n",
       "                                                                    10             6.765184   \n",
       "                                                                    11             6.787966   \n",
       "                                                                    12             6.808068   \n",
       "                                                                    13             6.811875   \n",
       "                                                                    14             6.842018   \n",
       "                                                                    15             6.845501   \n",
       "                                                                    16             6.847522   \n",
       "                                                                    17             6.853330   \n",
       "                                                                    18             6.856946   \n",
       "                                                                    19             6.859578   \n",
       "                                                                    20             6.862931   \n",
       "\n",
       "                                                                           training_loss  \\\n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch                  \n",
       "0.001 128        64                5           1            0.0     1           5.299506   \n",
       "                                                                    2           2.308818   \n",
       "                                                                    3           1.567526   \n",
       "                                                                    4           1.190234   \n",
       "                                                                    5           0.953074   \n",
       "                                                                    6           0.754955   \n",
       "                                                                    7           0.695770   \n",
       "                                                                    8           0.638940   \n",
       "                                                                    9           0.600703   \n",
       "                                                                    10          0.566617   \n",
       "                                                                    11          0.536378   \n",
       "                                                                    12          0.542972   \n",
       "                                                                    13          0.540399   \n",
       "                                                                    14          0.540239   \n",
       "                                                                    15          0.529268   \n",
       "                                                                    16          0.527188   \n",
       "                                                                    17          0.525120   \n",
       "                                                                    18          0.523793   \n",
       "                                                                    19          0.524891   \n",
       "                                                                    20          0.524130   \n",
       "\n",
       "                                                                           duration  \n",
       "lr    Batch size Number of filters Kernel size Pooling size Dropout Epoch            \n",
       "0.001 128        64                5           1            0.0     1           272  \n",
       "                                                                    2           272  \n",
       "                                                                    3           272  \n",
       "                                                                    4           272  \n",
       "                                                                    5           272  \n",
       "                                                                    6           272  \n",
       "                                                                    7           272  \n",
       "                                                                    8           272  \n",
       "                                                                    9           272  \n",
       "                                                                    10          272  \n",
       "                                                                    11          272  \n",
       "                                                                    12          272  \n",
       "                                                                    13          272  \n",
       "                                                                    14          272  \n",
       "                                                                    15          272  \n",
       "                                                                    16          272  \n",
       "                                                                    17          272  \n",
       "                                                                    18          272  \n",
       "                                                                    19          272  \n",
       "                                                                    20          272  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "022077c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00883588586472029"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0.637355\n",
    "n = 11373\n",
    "\n",
    "1.96 * np.sqrt( ((1 - acc) * (acc)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a29c3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv(\"../results/CNN-results_optimal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcd5391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.2265625\n",
      "Previous-job baseline accuracy: 0.0\n",
      "Fraction of previous job predictions: 0.015625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        career, job = career.to(device), job.to(device)\n",
    "        pred = cnn(candidate, career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())        \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        previous_job = torch.Tensor(career_paths.loc[candidate.cpu()].apply(lambda x: x[-2][-1]).values).to(device)\n",
    "        print(\"Previous-job baseline accuracy:\", (job == previous_job).cpu().numpy().mean())\n",
    "        print(\"Fraction of previous job predictions:\", (pred.argmax(1) == previous_job).cpu().numpy().mean())\n",
    "        \n",
    "        plt.show()        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42630a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c90a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
