{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be38665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 5.5 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed torch-1.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875fbc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "from heapq import nlargest\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef92866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48341cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1bd76a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa697124",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca5829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571a71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afdff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6a560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9b8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0228fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf4f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c18aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a35a8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f25e6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969d019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  time_spent  isco_functie_niveau  education  company_name  \\\n",
       "0         84556   -0.210459                  2.0        0.0        324258   \n",
       "1         84556   -0.252626                  1.0        0.0        324258   \n",
       "2         84556   -0.085012                  2.0        0.0        329244   \n",
       "3         84556   -0.370694                  1.0        0.0        368140   \n",
       "4         84556   -0.363314                  1.0        0.0        419826   \n",
       "\n",
       "   function_id  isco_code4  \n",
       "0          936         208  \n",
       "1          809         348  \n",
       "2          936         208  \n",
       "3         1519         344  \n",
       "4         1519         344  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8fe4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df_pred[\"isco_code4\"].mode().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e46f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(2 / (0.5 * np.sqrt(df_pred[\"isco_code4\"].value_counts().sort_values().reset_index().drop(\"index\", axis=1)))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf564de",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac28c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0837c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70230556",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c16d1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:48<00:00, 9701.25it/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8baa7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a6b59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b89a9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[-0.21045870102048395, 2.0, 0.0, 324258.0, 93...\n",
       "84612    [[-0.3685852264755267, 1.0, 0.0, 201740.0, 151...\n",
       "84731    [[-0.35066422025728855, 1.0, 0.0, 353745.0, 15...\n",
       "85437    [[0.3313881928721292, 1.0, 2.0, 5500.0, 1519.0...\n",
       "85888    [[-0.2895219637480053, 2.0, 3.0, 423330.0, 795...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a88da38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19a48439",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f32bb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8323b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff567a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43ec5506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtered: (113428, 113428)\n",
    "# Grouped: (176485, 176485)\n",
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de0fa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:50000]\n",
    "# y = y[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d94fd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "    test, validation = test[:(len(test) // 2)], test[(len(test) // 2):]\n",
    "\n",
    "    train_indices, val_indices, test_indices = idxs[training], idxs[validation], idxs[test]\n",
    "    X_train, X_val, X_test = to_fill[training], to_fill[validation], to_fill[test]\n",
    "    y_train, y_val, y_test = y[training].astype(int), y[validation].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_data = TensorDataset(torch.Tensor(test_indices),\n",
    "                             torch.Tensor(X_test),\n",
    "                             torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4f224e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super(attention, self).__init__()\n",
    "\n",
    "        # Attention layer\n",
    "        self.att_fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, outputs):\n",
    "        \n",
    "        # Deal with batches \n",
    "        outputs = outputs.transpose(0, 1)\n",
    "        att_weight = []\n",
    "        \n",
    "        # Determine weight of each timestep\n",
    "        for timestep in outputs:\n",
    "            x = self.att_fc(timestep)\n",
    "            x = torch.tanh(x)\n",
    "            att_weight.append(x)\n",
    "                        \n",
    "        # Normalize            \n",
    "        normalized_weights = nn.functional.softmax(torch.cat(att_weight, 1), 1)\n",
    "        \n",
    "        # Transpose to match normalized_weights\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        \n",
    "        # Multiply each timestep by its weight\n",
    "        attn_applied = outputs * normalized_weights.unsqueeze(1)\n",
    "        \n",
    "        # Weighted sum over time steps\n",
    "        attn_applied = attn_applied.sum(dim=2)\n",
    "        \n",
    "        return attn_applied, normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1808b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCPNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, \n",
    "                 num_layers, skills, certs, licenses, languages, \n",
    "                 addresses, w2v, candidate_lengths, max_len, dropout_prob=0.3,\n",
    "                 skill_embedding_size=50, certs_embedding_size=20,\n",
    "                 license_embedding_size=3, language_embedding_size=10,\n",
    "                 address_embedding_size=25, function_embedding_size=50, \n",
    "                 isco4_embedding_size=25, education_embedding_size=3, \n",
    "                 isco_level_embedding_size=3, company_embedding_size=50):\n",
    "        \n",
    "        super(HCPNN, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size + 300\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        \n",
    "        # Categorical feature embeddings isco_functie_niveau\tsource\teducation\tcompany_name\tfunction_id\tisco_code4\n",
    "        self.function_embedding = nn.Embedding(2993, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.source_embedding = nn.Embedding(2, 1)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "        \n",
    "        self.LSTMs = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            # input size + embedding\n",
    "            input_size = self.input_size + (function_embedding_size + isco4_embedding_size + company_embedding_size + 1 +\n",
    "                                            education_embedding_size + isco_level_embedding_size - 6) if i == 0 else hidden_size\n",
    "                                                  \n",
    "            self.LSTMs.append(nn.LSTM(input_size=input_size,\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      num_layers=1,\n",
    "                                      batch_first=True))\n",
    "            \n",
    "        self.attention = attention(hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        # Final fully-connected layer takes the LSTM output, as well as the static embeddings\n",
    "        self.fc = nn.Linear(hidden_size + skill_embedding_size + certs_embedding_size + license_embedding_size + \n",
    "                            language_embedding_size + address_embedding_size, num_classes)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])\n",
    "                \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:\n",
    "                    # 0, 10, 20, 30, 40, 50\n",
    "                    # duration = 50\n",
    "                    # ---> 0, 5, 15, 25\n",
    "                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * 300).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    "    \n",
    "\n",
    " \n",
    "    def forward(self, candidate, x):               \n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * 300).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "        \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "                        \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "            \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, w2v_list], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "                \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        # Forward pass\n",
    "        for i in range(self.num_layers):\n",
    "            # All hidden state, last hidden state, last cell state\n",
    "            output, (_, _) = self.LSTMs[i](self.dropout(x))\n",
    "            outputs.append(output)\n",
    "            x = output # self.dropout(output)\n",
    "            \n",
    "        # Apply attention\n",
    "        output, weight = self.attention(x)\n",
    "        \n",
    "        # Combine attention output with static features\n",
    "        x = torch.cat([output, batch_features, batch_addresses], dim=1)\n",
    "                        \n",
    "        # Fully-connected\n",
    "        out = self.fc(x)\n",
    "\n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "146de65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "        \n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, weight = model(candidate, career)\n",
    "                        \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "                                \n",
    "        training_loss /= len(trainloader)\n",
    "               \n",
    "        stats = test_loop(valloader, testloader, model, criterion)\n",
    "        \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int((done) // 60)}:{int((done) % 60):02d}\")\n",
    "\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"test_loss\"].append(stats[3])\n",
    "        results[\"Acc@1 (test)\"].append(stats[4])\n",
    "        results[\"Acc@5 (test)\"].append(stats[5])\n",
    "        results[\"Acc@10 (test)\"].append(stats[6])\n",
    "        results[\"test_loss (test)\"].append(stats[7])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        results[\"duration\"].append(done)\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/LSTM_optimal.pt\")\n",
    "            highest_performance = stats[0]\n",
    "            \n",
    "        scheduler.step()\n",
    "                \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "#         plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "#         plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "#         plt.xlabel(\"Epoch\")\n",
    "#         plt.ylabel(\"Average loss\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, testloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred, _ = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    print(f\"\\nVal Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    size_2 = len(testloader.dataset)\n",
    "    num_batches_2 = len(testloader)\n",
    "    test_loss_2, acc1_2, acc5_2, acc10_2 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in testloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred, _ = model(candidate, career)\n",
    "            \n",
    "            test_loss_2 += criterion(pred, job).mean().item()\n",
    "            acc1_2 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5_2 = []\n",
    "            at10_2 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5_2.append(answer.item() in predictions[:5])\n",
    "                at10_2.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5_2 += np.sum(at5_2)\n",
    "            acc10_2 += np.sum(at10_2)\n",
    "            \n",
    "    test_loss_2 /= num_batches_2\n",
    "    acc1_2 /= size_2\n",
    "    acc5_2 /= size_2\n",
    "    acc10_2 /= size_2\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1_2):>0.2f}%, Acc@5: {100*acc5_2:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10_2:>0.2f}%, Avg loss: {test_loss_2:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, test_loss, acc1_2, acc5_2, acc10_2, test_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-3]\n",
    "num_layers_values = [1]\n",
    "hidden_sizes = [1000]\n",
    "dropout_probs = [0]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=300\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for num_layers in num_layers_values:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                for dropout_prob in dropout_probs:\n",
    "\n",
    "                    lstm = HCPNN(num_classes=num_classes,\n",
    "                                 input_size=num_features,\n",
    "                                 num_layers=num_layers,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 dropout_prob=dropout_prob,\n",
    "                                 skills=skills, \n",
    "                                 certs=certs,\n",
    "                                 licenses=licenses,\n",
    "                                 languages=languages,\n",
    "                                 addresses=addresses,\n",
    "                                 w2v=w2v,\n",
    "                                 skill_embedding_size=skill_embedding_size,\n",
    "                                 certs_embedding_size=certs_embedding_size,\n",
    "                                 license_embedding_size=license_embedding_size,\n",
    "                                 language_embedding_size=language_embedding_size,\n",
    "                                 address_embedding_size=address_embedding_size,\n",
    "                                 function_embedding_size=function_embedding_size,\n",
    "                                 isco4_embedding_size=isco4_embedding_size,\n",
    "                                 education_embedding_size=education_embedding_size,\n",
    "                                 isco_level_embedding_size=isco_level_embedding_size,\n",
    "                                 company_embedding_size=company_embedding_size,\n",
    "                                 candidate_lengths=candidate_lens,\n",
    "                                 max_len=max_len)\n",
    "\n",
    "                    lstm = lstm.to(device)\n",
    "\n",
    "                    optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "                    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "                    if current >= 1:\n",
    "                        print(\"\\n\\n\\n\")\n",
    "\n",
    "                    print(f\"- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", lstm, \"\\n\")\n",
    "\n",
    "                    trainloader, testloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                                        weight_type=3, batch_size=512)\n",
    "\n",
    "                    # Store results of current configuration\n",
    "                    outcome = train_loop(lstm, trainloader, valloader, testloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                    outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                    outcome[\"Number of layers\"] = [num_layers] * num_epochs\n",
    "                    outcome[\"Nodes per layer\"] = [hidden_size] * num_epochs\n",
    "                    outcome[\"Dropout\"] = [dropout_prob] * num_epochs\n",
    "\n",
    "                    full_results.append(outcome)\n",
    "\n",
    "                    current += 1\n",
    "                    \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd53b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Number of layers\", \"Nodes per layer\", \"Dropout\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dea72117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>Acc@1 (test)</th>\n",
       "      <th>Acc@5 (test)</th>\n",
       "      <th>Acc@10 (test)</th>\n",
       "      <th>test_loss (test)</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">1000</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.527348</td>\n",
       "      <td>0.655909</td>\n",
       "      <td>3.547212</td>\n",
       "      <td>0.201266</td>\n",
       "      <td>0.499780</td>\n",
       "      <td>0.644509</td>\n",
       "      <td>3.665821</td>\n",
       "      <td>4.603593</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193458</td>\n",
       "      <td>0.515477</td>\n",
       "      <td>0.654326</td>\n",
       "      <td>3.575456</td>\n",
       "      <td>0.198013</td>\n",
       "      <td>0.491955</td>\n",
       "      <td>0.640640</td>\n",
       "      <td>3.653566</td>\n",
       "      <td>3.419888</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197854</td>\n",
       "      <td>0.505452</td>\n",
       "      <td>0.648874</td>\n",
       "      <td>3.627782</td>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.491075</td>\n",
       "      <td>0.630616</td>\n",
       "      <td>3.591741</td>\n",
       "      <td>2.659173</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195832</td>\n",
       "      <td>0.519961</td>\n",
       "      <td>0.656789</td>\n",
       "      <td>3.678284</td>\n",
       "      <td>0.209883</td>\n",
       "      <td>0.495736</td>\n",
       "      <td>0.635452</td>\n",
       "      <td>3.545383</td>\n",
       "      <td>2.129618</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.192754</td>\n",
       "      <td>0.503078</td>\n",
       "      <td>0.641136</td>\n",
       "      <td>3.827811</td>\n",
       "      <td>0.205663</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>0.622703</td>\n",
       "      <td>3.596726</td>\n",
       "      <td>1.722824</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.187214</td>\n",
       "      <td>0.497626</td>\n",
       "      <td>0.645093</td>\n",
       "      <td>3.992448</td>\n",
       "      <td>0.199420</td>\n",
       "      <td>0.475688</td>\n",
       "      <td>0.619625</td>\n",
       "      <td>3.643404</td>\n",
       "      <td>1.418396</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.195304</td>\n",
       "      <td>0.511959</td>\n",
       "      <td>0.652568</td>\n",
       "      <td>4.124724</td>\n",
       "      <td>0.205575</td>\n",
       "      <td>0.486855</td>\n",
       "      <td>0.628066</td>\n",
       "      <td>3.660862</td>\n",
       "      <td>1.181855</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.201372</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>4.262439</td>\n",
       "      <td>0.205311</td>\n",
       "      <td>0.484305</td>\n",
       "      <td>0.625253</td>\n",
       "      <td>3.738043</td>\n",
       "      <td>1.000694</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>0.650281</td>\n",
       "      <td>4.406540</td>\n",
       "      <td>0.210499</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.625605</td>\n",
       "      <td>3.781991</td>\n",
       "      <td>0.853623</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.196272</td>\n",
       "      <td>0.505540</td>\n",
       "      <td>0.643598</td>\n",
       "      <td>4.606770</td>\n",
       "      <td>0.209443</td>\n",
       "      <td>0.479909</td>\n",
       "      <td>0.621472</td>\n",
       "      <td>3.904510</td>\n",
       "      <td>0.743285</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.193721</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.645005</td>\n",
       "      <td>4.732886</td>\n",
       "      <td>0.209443</td>\n",
       "      <td>0.486327</td>\n",
       "      <td>0.628682</td>\n",
       "      <td>3.934208</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.195128</td>\n",
       "      <td>0.507474</td>\n",
       "      <td>0.647731</td>\n",
       "      <td>4.929768</td>\n",
       "      <td>0.213752</td>\n",
       "      <td>0.492658</td>\n",
       "      <td>0.628594</td>\n",
       "      <td>4.031569</td>\n",
       "      <td>0.571090</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.197151</td>\n",
       "      <td>0.508794</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>4.966176</td>\n",
       "      <td>0.200914</td>\n",
       "      <td>0.482458</td>\n",
       "      <td>0.620329</td>\n",
       "      <td>4.088117</td>\n",
       "      <td>0.504048</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.202691</td>\n",
       "      <td>0.514333</td>\n",
       "      <td>0.651425</td>\n",
       "      <td>5.134888</td>\n",
       "      <td>0.210411</td>\n",
       "      <td>0.493977</td>\n",
       "      <td>0.631847</td>\n",
       "      <td>4.137114</td>\n",
       "      <td>0.443666</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.198734</td>\n",
       "      <td>0.505540</td>\n",
       "      <td>0.646148</td>\n",
       "      <td>5.257959</td>\n",
       "      <td>0.209795</td>\n",
       "      <td>0.489229</td>\n",
       "      <td>0.624461</td>\n",
       "      <td>4.204283</td>\n",
       "      <td>0.395206</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.203306</td>\n",
       "      <td>0.511256</td>\n",
       "      <td>0.648083</td>\n",
       "      <td>5.414461</td>\n",
       "      <td>0.213224</td>\n",
       "      <td>0.496966</td>\n",
       "      <td>0.629122</td>\n",
       "      <td>4.339396</td>\n",
       "      <td>0.360476</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.198734</td>\n",
       "      <td>0.510376</td>\n",
       "      <td>0.642455</td>\n",
       "      <td>5.657576</td>\n",
       "      <td>0.207333</td>\n",
       "      <td>0.494680</td>\n",
       "      <td>0.628770</td>\n",
       "      <td>4.494002</td>\n",
       "      <td>0.330983</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.203394</td>\n",
       "      <td>0.511871</td>\n",
       "      <td>0.649226</td>\n",
       "      <td>5.645266</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.493361</td>\n",
       "      <td>0.629122</td>\n",
       "      <td>4.458937</td>\n",
       "      <td>0.308775</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.183609</td>\n",
       "      <td>0.494460</td>\n",
       "      <td>0.634541</td>\n",
       "      <td>5.678792</td>\n",
       "      <td>0.198540</td>\n",
       "      <td>0.484481</td>\n",
       "      <td>0.620856</td>\n",
       "      <td>4.505385</td>\n",
       "      <td>0.275873</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.505540</td>\n",
       "      <td>0.638058</td>\n",
       "      <td>5.766778</td>\n",
       "      <td>0.214807</td>\n",
       "      <td>0.494856</td>\n",
       "      <td>0.625780</td>\n",
       "      <td>4.564402</td>\n",
       "      <td>0.257876</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Acc@1     Acc@5  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                       \n",
       "0.001 1                1000            0       1      0.203922  0.527348   \n",
       "                                               2      0.193458  0.515477   \n",
       "                                               3      0.197854  0.505452   \n",
       "                                               4      0.195832  0.519961   \n",
       "                                               5      0.192754  0.503078   \n",
       "                                               6      0.187214  0.497626   \n",
       "                                               7      0.195304  0.511959   \n",
       "                                               8      0.201372  0.514773   \n",
       "                                               9      0.201899  0.513102   \n",
       "                                               10     0.196272  0.505540   \n",
       "                                               11     0.193721  0.502990   \n",
       "                                               12     0.195128  0.507474   \n",
       "                                               13     0.197151  0.508794   \n",
       "                                               14     0.202691  0.514333   \n",
       "                                               15     0.198734  0.505540   \n",
       "                                               16     0.203306  0.511256   \n",
       "                                               17     0.198734  0.510376   \n",
       "                                               18     0.203394  0.511871   \n",
       "                                               19     0.183609  0.494460   \n",
       "                                               20     0.206472  0.505540   \n",
       "\n",
       "                                                        Acc@10  test_loss  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                        \n",
       "0.001 1                1000            0       1      0.655909   3.547212   \n",
       "                                               2      0.654326   3.575456   \n",
       "                                               3      0.648874   3.627782   \n",
       "                                               4      0.656789   3.678284   \n",
       "                                               5      0.641136   3.827811   \n",
       "                                               6      0.645093   3.992448   \n",
       "                                               7      0.652568   4.124724   \n",
       "                                               8      0.651600   4.262439   \n",
       "                                               9      0.650281   4.406540   \n",
       "                                               10     0.643598   4.606770   \n",
       "                                               11     0.645005   4.732886   \n",
       "                                               12     0.647731   4.929768   \n",
       "                                               13     0.649402   4.966176   \n",
       "                                               14     0.651425   5.134888   \n",
       "                                               15     0.646148   5.257959   \n",
       "                                               16     0.648083   5.414461   \n",
       "                                               17     0.642455   5.657576   \n",
       "                                               18     0.649226   5.645266   \n",
       "                                               19     0.634541   5.678792   \n",
       "                                               20     0.638058   5.766778   \n",
       "\n",
       "                                                      Acc@1 (test)  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                 \n",
       "0.001 1                1000            0       1          0.201266   \n",
       "                                               2          0.198013   \n",
       "                                               3          0.208125   \n",
       "                                               4          0.209883   \n",
       "                                               5          0.205663   \n",
       "                                               6          0.199420   \n",
       "                                               7          0.205575   \n",
       "                                               8          0.205311   \n",
       "                                               9          0.210499   \n",
       "                                               10         0.209443   \n",
       "                                               11         0.209443   \n",
       "                                               12         0.213752   \n",
       "                                               13         0.200914   \n",
       "                                               14         0.210411   \n",
       "                                               15         0.209795   \n",
       "                                               16         0.213224   \n",
       "                                               17         0.207333   \n",
       "                                               18         0.218500   \n",
       "                                               19         0.198540   \n",
       "                                               20         0.214807   \n",
       "\n",
       "                                                      Acc@5 (test)  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                 \n",
       "0.001 1                1000            0       1          0.499780   \n",
       "                                               2          0.491955   \n",
       "                                               3          0.491075   \n",
       "                                               4          0.495736   \n",
       "                                               5          0.477886   \n",
       "                                               6          0.475688   \n",
       "                                               7          0.486855   \n",
       "                                               8          0.484305   \n",
       "                                               9          0.486943   \n",
       "                                               10         0.479909   \n",
       "                                               11         0.486327   \n",
       "                                               12         0.492658   \n",
       "                                               13         0.482458   \n",
       "                                               14         0.493977   \n",
       "                                               15         0.489229   \n",
       "                                               16         0.496966   \n",
       "                                               17         0.494680   \n",
       "                                               18         0.493361   \n",
       "                                               19         0.484481   \n",
       "                                               20         0.494856   \n",
       "\n",
       "                                                      Acc@10 (test)  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                  \n",
       "0.001 1                1000            0       1           0.644509   \n",
       "                                               2           0.640640   \n",
       "                                               3           0.630616   \n",
       "                                               4           0.635452   \n",
       "                                               5           0.622703   \n",
       "                                               6           0.619625   \n",
       "                                               7           0.628066   \n",
       "                                               8           0.625253   \n",
       "                                               9           0.625605   \n",
       "                                               10          0.621472   \n",
       "                                               11          0.628682   \n",
       "                                               12          0.628594   \n",
       "                                               13          0.620329   \n",
       "                                               14          0.631847   \n",
       "                                               15          0.624461   \n",
       "                                               16          0.629122   \n",
       "                                               17          0.628770   \n",
       "                                               18          0.629122   \n",
       "                                               19          0.620856   \n",
       "                                               20          0.625780   \n",
       "\n",
       "                                                      test_loss (test)  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                     \n",
       "0.001 1                1000            0       1              3.665821   \n",
       "                                               2              3.653566   \n",
       "                                               3              3.591741   \n",
       "                                               4              3.545383   \n",
       "                                               5              3.596726   \n",
       "                                               6              3.643404   \n",
       "                                               7              3.660862   \n",
       "                                               8              3.738043   \n",
       "                                               9              3.781991   \n",
       "                                               10             3.904510   \n",
       "                                               11             3.934208   \n",
       "                                               12             4.031569   \n",
       "                                               13             4.088117   \n",
       "                                               14             4.137114   \n",
       "                                               15             4.204283   \n",
       "                                               16             4.339396   \n",
       "                                               17             4.494002   \n",
       "                                               18             4.458937   \n",
       "                                               19             4.505385   \n",
       "                                               20             4.564402   \n",
       "\n",
       "                                                      training_loss  duration  \n",
       "lr    Number of layers Nodes per layer Dropout Epoch                           \n",
       "0.001 1                1000            0       1           4.603593       107  \n",
       "                                               2           3.419888       109  \n",
       "                                               3           2.659173       109  \n",
       "                                               4           2.129618       107  \n",
       "                                               5           1.722824       108  \n",
       "                                               6           1.418396       107  \n",
       "                                               7           1.181855       107  \n",
       "                                               8           1.000694       108  \n",
       "                                               9           0.853623       108  \n",
       "                                               10          0.743285       108  \n",
       "                                               11          0.638958       107  \n",
       "                                               12          0.571090       107  \n",
       "                                               13          0.504048       107  \n",
       "                                               14          0.443666       109  \n",
       "                                               15          0.395206       107  \n",
       "                                               16          0.360476       107  \n",
       "                                               17          0.330983       108  \n",
       "                                               18          0.308775       108  \n",
       "                                               19          0.275873       109  \n",
       "                                               20          0.257876       107  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b048150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008877721650614907"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0.629122\n",
    "n = 11373\n",
    "\n",
    "1.96 * np.sqrt( ((1 - acc) * (acc)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d49296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv(\"../results/LSTM-results_optimal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d2f24ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>Acc@20</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th>1000</th>\n",
       "      <th>0.25</th>\n",
       "      <th>2</th>\n",
       "      <td>0.198109</td>\n",
       "      <td>0.466828</td>\n",
       "      <td>0.602198</td>\n",
       "      <td>0.727808</td>\n",
       "      <td>3.654136</td>\n",
       "      <td>3.856898</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">500</th>\n",
       "      <th>0.00</th>\n",
       "      <th>3</th>\n",
       "      <td>0.197494</td>\n",
       "      <td>0.475357</td>\n",
       "      <td>0.609409</td>\n",
       "      <td>0.738932</td>\n",
       "      <td>3.616603</td>\n",
       "      <td>3.149045</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>2</th>\n",
       "      <td>0.196966</td>\n",
       "      <td>0.475313</td>\n",
       "      <td>0.597978</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>3.702973</td>\n",
       "      <td>4.052021</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <th>0.25</th>\n",
       "      <th>2</th>\n",
       "      <td>0.195164</td>\n",
       "      <td>0.466124</td>\n",
       "      <td>0.594109</td>\n",
       "      <td>0.723719</td>\n",
       "      <td>3.667516</td>\n",
       "      <td>3.616276</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1000</th>\n",
       "      <th>0.00</th>\n",
       "      <th>2</th>\n",
       "      <td>0.192394</td>\n",
       "      <td>0.474390</td>\n",
       "      <td>0.607386</td>\n",
       "      <td>0.729523</td>\n",
       "      <td>3.652411</td>\n",
       "      <td>3.582638</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>3</th>\n",
       "      <td>0.191515</td>\n",
       "      <td>0.461728</td>\n",
       "      <td>0.596219</td>\n",
       "      <td>0.727325</td>\n",
       "      <td>3.707977</td>\n",
       "      <td>3.511576</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>3</th>\n",
       "      <td>0.191515</td>\n",
       "      <td>0.468235</td>\n",
       "      <td>0.604485</td>\n",
       "      <td>0.737657</td>\n",
       "      <td>3.652158</td>\n",
       "      <td>2.721269</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <th>0.25</th>\n",
       "      <th>3</th>\n",
       "      <td>0.191031</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>0.595603</td>\n",
       "      <td>0.723939</td>\n",
       "      <td>3.679106</td>\n",
       "      <td>3.454050</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1500</th>\n",
       "      <th>0.00</th>\n",
       "      <th>2</th>\n",
       "      <td>0.190943</td>\n",
       "      <td>0.462475</td>\n",
       "      <td>0.598417</td>\n",
       "      <td>0.735107</td>\n",
       "      <td>3.669754</td>\n",
       "      <td>3.363616</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>3</th>\n",
       "      <td>0.190767</td>\n",
       "      <td>0.459178</td>\n",
       "      <td>0.591647</td>\n",
       "      <td>0.732073</td>\n",
       "      <td>3.679190</td>\n",
       "      <td>2.887053</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Acc@1     Acc@5  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                       \n",
       "0.001 1                1000            0.25    2      0.198109  0.466828   \n",
       "                       500             0.00    3      0.197494  0.475357   \n",
       "                                       0.25    2      0.196966  0.475313   \n",
       "                       1500            0.25    2      0.195164  0.466124   \n",
       "                       1000            0.00    2      0.192394  0.474390   \n",
       "                                       0.50    3      0.191515  0.461728   \n",
       "                                       0.00    3      0.191515  0.468235   \n",
       "                       500             0.25    3      0.191031  0.461200   \n",
       "                       1500            0.00    2      0.190943  0.462475   \n",
       "                                       0.25    3      0.190767  0.459178   \n",
       "\n",
       "                                                        Acc@10    Acc@20  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch                       \n",
       "0.001 1                1000            0.25    2      0.602198  0.727808   \n",
       "                       500             0.00    3      0.609409  0.738932   \n",
       "                                       0.25    2      0.597978  0.725038   \n",
       "                       1500            0.25    2      0.594109  0.723719   \n",
       "                       1000            0.00    2      0.607386  0.729523   \n",
       "                                       0.50    3      0.596219  0.727325   \n",
       "                                       0.00    3      0.604485  0.737657   \n",
       "                       500             0.25    3      0.595603  0.723939   \n",
       "                       1500            0.00    2      0.598417  0.735107   \n",
       "                                       0.25    3      0.591647  0.732073   \n",
       "\n",
       "                                                      test_loss  \\\n",
       "lr    Number of layers Nodes per layer Dropout Epoch              \n",
       "0.001 1                1000            0.25    2       3.654136   \n",
       "                       500             0.00    3       3.616603   \n",
       "                                       0.25    2       3.702973   \n",
       "                       1500            0.25    2       3.667516   \n",
       "                       1000            0.00    2       3.652411   \n",
       "                                       0.50    3       3.707977   \n",
       "                                       0.00    3       3.652158   \n",
       "                       500             0.25    3       3.679106   \n",
       "                       1500            0.00    2       3.669754   \n",
       "                                       0.25    3       3.679190   \n",
       "\n",
       "                                                      training_loss  duration  \n",
       "lr    Number of layers Nodes per layer Dropout Epoch                           \n",
       "0.001 1                1000            0.25    2           3.856898       122  \n",
       "                       500             0.00    3           3.149045        87  \n",
       "                                       0.25    2           4.052021        87  \n",
       "                       1500            0.25    2           3.616276       170  \n",
       "                       1000            0.00    2           3.582638       121  \n",
       "                                       0.50    3           3.511576       121  \n",
       "                                       0.00    3           2.721269       121  \n",
       "                       500             0.25    3           3.454050        85  \n",
       "                       1500            0.00    2           3.363616       171  \n",
       "                                       0.25    3           2.887053       171  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_results = pd.read_csv(\"../results/LSTM-results.csv\").set_index([\"lr\", \"Number of layers\", \"Nodes per layer\", \"Dropout\", \"Epoch\"])\n",
    "tested_results.sort_values(by=\"Acc@1\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cd41262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.001,\n",
       " 'Number of layers': 1,\n",
       " 'Nodes per layer': 1000,\n",
       " 'Dropout': 0.25,\n",
       " 'Epoch': 2}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_settings = tested_results.sort_values(by=\"Acc@1\", ascending=False).head(1)\n",
    "settings_dict = dict(zip(list(optimal_settings.index.names), list(optimal_settings.index[0])))\n",
    "settings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c9876a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training optimal model.\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 09:15:35\n",
      "Epoch: 1, batch: 2/178, loss: 5.88471\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-b0d2e2fa161e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Store results of current configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-2e0a618f2af5>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=25\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lstm = HCPNN(num_classes=num_classes,\n",
    "             input_size=num_features,\n",
    "             num_layers=int(settings_dict[\"Number of layers\"]),\n",
    "             hidden_size=int(settings_dict[\"Nodes per layer\"]),\n",
    "             dropout_prob=settings_dict[\"Dropout\"],\n",
    "             skills=skills, \n",
    "             certs=certs,\n",
    "             licenses=licenses,\n",
    "             languages=languages,\n",
    "             addresses=addresses,\n",
    "             w2v=w2v,\n",
    "             address_embedding_size=25,\n",
    "             candidate_lengths=candidate_lens,\n",
    "             max_len=max_len)\n",
    "\n",
    "lstm = lstm.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=settings_dict[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "print(f\"Training optimal model.\")\n",
    "\n",
    "trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                        weight_type=3, batch_size=512)\n",
    "\n",
    "# Store results of current configuration\n",
    "outcome = train_loop(lstm, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf53cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "switches = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for c, jobs in career_paths.iteritems():\n",
    "    jobs = jobs[:,-1]\n",
    "    for i in range(len(jobs)):\n",
    "        if i < len(jobs) - 1 and jobs[i] != jobs[i + 1]:\n",
    "            switches[jobs[i]][jobs[i  + 1]] += 1\n",
    "            \n",
    "most_common = {k: nlargest(1, v, key=v.get)[0] for k, v in switches.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a218c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.19140625\n",
      "\n",
      "Previous-job baseline accuracy: 0.0\n",
      "Majority class accuracy: 0.107421875\n",
      "\n",
      "Fraction of previous job predictions: 0.01953125\n",
      "Majority class predictions: 0.087890625\n",
      "Majority switch predictions: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        career, job = career.to(device), job.to(device)\n",
    "        pred, weight = lstm(candidate, career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())        \n",
    "        print()\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        previous_job = torch.Tensor(career_paths.loc[candidate.cpu()].apply(lambda x: x[-2][-1]).values).to(device)\n",
    "        print(\"Previous-job baseline accuracy:\", (job == previous_job).cpu().numpy().mean())\n",
    "        print(\"Majority class accuracy:\", (job == majority_class).cpu().numpy().mean())\n",
    "        print()\n",
    "        \n",
    "        print(\"Fraction of previous job predictions:\", (pred.argmax(1) == previous_job).cpu().numpy().mean())\n",
    "        print(\"Majority class predictions:\", (pred.argmax(1) == majority_class).cpu().numpy().mean())\n",
    "        print(\"Majority switch predictions:\", np.mean([i.item() == most_common[i.item()] for i in pred.argmax(1).cpu().numpy()]))\n",
    "                                                \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "            \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "                \n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "        a = weight.cpu().detach().numpy().mean(axis=0)            \n",
    "        plt.plot(a, label=\"average\")\n",
    "        # plt.plot(weights[0][np.random.choice(range(len(weights[0])))].cpu().detach().numpy(), label=\"random example\")\n",
    "        plt.xlabel(\"Career step\")\n",
    "        plt.ylabel(\"Attention weight\")\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4a40790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = weight.cpu().detach().numpy()\n",
    "\n",
    "for _ in range(20):\n",
    "    c = np.random.randint(0, len(b))\n",
    "    plt.plot(b[c])\n",
    "    plt.xlabel(\"Career step\")\n",
    "    plt.ylabel(\"Attention weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7f1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
