{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2655cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/jacobgil/pytorch-grad-cam.git \"pillow<7\" ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d71dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.10.1)\n",
      "Collecting torch\n",
      "  Using cached torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: grad-cam in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.3.9)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (8.4.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (0.11.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (4.61.1)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (4.5.1.48)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (1.19.5)\n",
      "Requirement already satisfied: ttach in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945beb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8c890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c307be50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebce2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930e08de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af22a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1790f0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1607511",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc74b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f92d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7787d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f4c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f2549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f41804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()\n",
    "df_pred[\"c\"] = df_pred[\"candidate_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15cc457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAD-cam requires a single input into forward(), so we need to include candidate in there as well\n",
    "df_pred = df_pred[[\"candidate_id\", \"c\", \"time_spent\", \"isco_functie_niveau\", \"education\", \"company_name\", \"function_id\", \"isco_code4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48bf211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>c</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id      c  time_spent  isco_functie_niveau  education  \\\n",
       "0         84556  84556   -0.210459                  2.0        0.0   \n",
       "1         84556  84556   -0.252626                  1.0        0.0   \n",
       "2         84556  84556   -0.085012                  2.0        0.0   \n",
       "3         84556  84556   -0.370694                  1.0        0.0   \n",
       "4         84556  84556   -0.363314                  1.0        0.0   \n",
       "\n",
       "   company_name  function_id  isco_code4  \n",
       "0        324258          936         208  \n",
       "1        324258          809         348  \n",
       "2        329244          936         208  \n",
       "3        368140         1519         344  \n",
       "4        419826         1519         344  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b6c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df_pred[\"isco_code4\"].mode().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b46b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_pred.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bb9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a711ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "739f4640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aac8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146249ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:49<00:00, 9541.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ab8f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1fd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b56d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[84556.0, -0.21045870102048395, 2.0, 0.0, 324...\n",
       "84612    [[84612.0, -0.3685852264755267, 1.0, 0.0, 2017...\n",
       "84731    [[84731.0, -0.35066422025728855, 1.0, 0.0, 353...\n",
       "85437    [[85437.0, 0.3313881928721292, 1.0, 2.0, 5500....\n",
       "85888    [[85888.0, -0.2895219637480053, 2.0, 3.0, 4233...\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90382dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "198eac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f005800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b96db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x\n",
    "del career_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90836877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6637c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eeb7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:25000]\n",
    "# y = y[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec24903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "    test, validation = test[:(len(test) // 2)], test[(len(test) // 2):]\n",
    "\n",
    "    train_indices, val_indices, test_indices = idxs[training], idxs[validation], idxs[test]\n",
    "    X_train, X_val, X_test = to_fill[training], to_fill[validation], to_fill[test]\n",
    "    y_train, y_val, y_test = y[training].astype(int), y[validation].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_data = TensorDataset(torch.Tensor(test_indices),\n",
    "                             torch.Tensor(X_test),\n",
    "                             torch.Tensor(y_test).type(torch.LongTensor))\n",
    "\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8107042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XCM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, skills, certs, licenses, \n",
    "                 languages, addresses, w2v, candidate_lengths, max_len, \n",
    "                 F1=64, F2=16, window_size=0.2, skill_embedding_size=50, \n",
    "                 certs_embedding_size=20, license_embedding_size=3, \n",
    "                 language_embedding_size=10, address_embedding_size=25, \n",
    "                 function_embedding_size=50, isco4_embedding_size=25, \n",
    "                 education_embedding_size=3, isco_level_embedding_size=3, \n",
    "                 company_embedding_size=50, w2v_embedding_size=300):\n",
    "        \n",
    "        super(XCM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size + w2v_embedding_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        self.skill_embedding_size = skill_embedding_size\n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        self.certs_embedding_size = certs_embedding_size\n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        self.license_embedding_size = license_embedding_size\n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        self.language_embedding_size = language_embedding_size \n",
    "\n",
    "        self.w2v_embedding_size = w2v_embedding_size\n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        self.address_embedding_size = address_embedding_size\n",
    "        \n",
    "        # Categorical feature embeddings\n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "        \n",
    "        self.function_embedding_size = function_embedding_size\n",
    "        self.isco_code_embedding_size = isco4_embedding_size\n",
    "        self.company_embedding_size = company_embedding_size\n",
    "        self.education_embedding_size = education_embedding_size\n",
    "        self.isco_level_embedding_size = isco_level_embedding_size\n",
    "                \n",
    "        # -6 --> embedded features get replaced\n",
    "        N = self.input_size - 6 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "        \n",
    "        # Actual model\n",
    "        window_size = int(max_len * window_size)\n",
    "        D = N\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(F1)  \n",
    "        self.batchnorm2 = nn.BatchNorm2d(F2)\n",
    "        \n",
    "        self.conv2d_padding = nn.ZeroPad2d((0, 0, window_size // 2, (window_size - 1 ) // 2))\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=F1,\n",
    "                                kernel_size=(window_size, 1),\n",
    "                                stride=(1, 1))\n",
    "        \n",
    "        self._1x1 = nn.Conv2d(in_channels=F1, \n",
    "                              out_channels=1, \n",
    "                              kernel_size=(1, 1), # Maybe (100, 1, 1)?\n",
    "                              stride=1)\n",
    "\n",
    "        # Asymmetric padding to have a consistent shape for even and uneven window_sizes\n",
    "        self.conv1d_padding = nn.ZeroPad2d((0, 0, window_size // 2, (window_size - 1 ) // 2))\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=1,\n",
    "                                out_channels=F1, \n",
    "                                kernel_size=(window_size, D),\n",
    "                                stride=1)\n",
    "                \n",
    "        self._1x1_2 = nn.Conv1d(in_channels=F1, \n",
    "                                out_channels=1, \n",
    "                                kernel_size=(1, 1),\n",
    "                                stride=1)\n",
    "        \n",
    "        self.final_padding = nn.ZeroPad2d(((D + 1) // 2, D // 2, window_size // 2, (window_size - 1 ) // 2))\n",
    "            \n",
    "        self.final_conv1d = nn.Conv1d(in_channels=1,\n",
    "                                      out_channels=F2, \n",
    "                                      kernel_size=(window_size, D + 1),\n",
    "                                      stride=1)\n",
    "        \n",
    "        self.avgpool2d = nn.AvgPool3d(kernel_size=(F2, 1, 1),\n",
    "                                      stride=1)\n",
    "        \n",
    "        self.fc = nn.Linear(max_len * (D + 1), num_classes)\n",
    "                    \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])   \n",
    "                \n",
    "    \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.Tensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration).to(device)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip]).to(device)] * duration, dim=0))\n",
    "                else:\n",
    "                    storage.append(torch.Tensor(cvs[0]))\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * self.w2v_embedding_size).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    "    \n",
    "    def create_tensor(self, x):\n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * (self.skill_embedding_size + self.certs_embedding_size\n",
    "                                            + self.license_embedding_size + self.language_embedding_size\n",
    "                                            + self.address_embedding_size + self.w2v_embedding_size)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        # Extract candidate_ids\n",
    "        candidate = x[:,:,0][:,-1].cpu()\n",
    "        \n",
    "        # Everything else stays in x\n",
    "        x = x[:,:,1:]\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "                \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "        \n",
    "        durations = []\n",
    "        \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "            \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "                                    \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "            durations.append(career_duration)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))                \n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                        \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "         # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "        \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)     \n",
    "                                    \n",
    "        return x, durations\n",
    " \n",
    "    def forward(self, x):                       \n",
    "        # Reshape to allow conv2D\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = x.transpose(1, 3)\n",
    "        x = x.transpose(2, 3)\n",
    "                \n",
    "        # Top part:\n",
    "        x1 = self.conv2d_padding(x)\n",
    "        x1 = self.conv2d(x1)\n",
    "        x1 = self.batchnorm(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x1 = self._1x1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        # x1 = self.dropout(x1)\n",
    "\n",
    "        # Bottom part: \n",
    "        x = self.conv1d_padding(x)\n",
    "        x2 = self.conv1d(x)\n",
    "        x2 = self.batchnorm(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        x2 = self._1x1_2(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        # x2 = self.dropout(x2)\n",
    "        \n",
    "        # Concatenate                \n",
    "        x = torch.cat([x1, x2], dim=-1)\n",
    "                \n",
    "        # Conv 1D\n",
    "        x = self.final_padding(x)\n",
    "        x = self.final_conv1d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "                                \n",
    "        # Global average pooling\n",
    "        x = self.avgpool2d(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "                    \n",
    "        x = self.fc(x)\n",
    "                \n",
    "        # softmax\n",
    "        out = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d3e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "        train_acc1 = 0\n",
    "        \n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            batch_start = time.time()\n",
    "            \n",
    "            candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            career, _ = model.create_tensor(career)\n",
    "            outputs = model(career)\n",
    "            \n",
    "            train_acc1 += (outputs.argmax(1) == job).type(torch.float).sum().item()\n",
    "                                    \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()       \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            batch_end = time.time()\n",
    "            batch_duration = batch_end - batch_start\n",
    "            epoch_duration = int(batch_duration * (len(trainloader) - i))\n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f, Epoch ETA: %02d:%02d:%02d  \" % (epoch + 1,\n",
    "                                                                                         i + 1,\n",
    "                                                                                         len(trainloader), \n",
    "                                                                                         loss.item(),\n",
    "                                                                                         epoch_duration // 3600,\n",
    "                                                                                         (epoch_duration % 3600) // 60,\n",
    "                                                                                         (epoch_duration % 60)), end=\"\\r\")\n",
    "\n",
    "        training_loss /= len(trainloader)\n",
    "        train_acc1 /= len(trainloader.dataset)\n",
    "                \n",
    "        stats = test_loop(valloader, model, criterion)\n",
    "        \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int((done) // 60)}:{int((done) % 60):02d}\")\n",
    "        \n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"test_loss\"].append(stats[3])\n",
    "        results[\"Acc@1 (test)\"].append(stats[4])\n",
    "        results[\"Acc@5 (test)\"].append(stats[5])\n",
    "        results[\"Acc@10 (test)\"].append(stats[6])\n",
    "        results[\"test_loss (test)\"].append(stats[7])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        results[\"duration\"].append(done)\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/optimal_eCNN.pt\")\n",
    "            highest_performance = stats[0]\n",
    "\n",
    "        scheduler.step()\n",
    "                \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "        plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "        plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Average loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, testloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            \n",
    "            career, _ = model.create_tensor(career)\n",
    "            pred = model(career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    print(f\"\\nVal Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    size_2 = len(testloader.dataset)\n",
    "    num_batches_2 = len(testloader)\n",
    "    test_loss_2, acc1_2, acc5_2, acc10_2 = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in testloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred, weight, _ = model(candidate, career)\n",
    "            \n",
    "            test_loss_2 += criterion(pred, job).mean().item()\n",
    "            acc1_2 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5_2 = []\n",
    "            at10_2 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5_2.append(answer.item() in predictions[:5])\n",
    "                at10_2.append(answer.item() in predictions[:10])\n",
    "            \n",
    "            acc5_2 += np.sum(at5_2)\n",
    "            acc10_2 += np.sum(at10_2)\n",
    "            \n",
    "    test_loss_2 /= num_batches_2\n",
    "    acc1_2 /= size_2\n",
    "    acc5_2 /= size_2\n",
    "    acc10_2 /= size_2\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1_2):>0.2f}%, Acc@5: {100*acc5_2:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10_2:>0.2f}%, Avg loss: {test_loss_2:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, acc1_2, acc5_2, acc10_2, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "459300ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 01:56:35\n",
      "Epoch: 1, batch: 1/711, loss: 5.86775, Epoch ETA: 07:11:40  \r"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-3]\n",
    "window_sizes = [0.4]\n",
    "F1_sizes = [8]\n",
    "F2_sizes = [64]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=250\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for F1 in F1_sizes:\n",
    "            for F2 in F2_sizes:\n",
    "                for window_size in window_sizes:\n",
    "\n",
    "                    cnn = XCM(num_classes=num_classes,\n",
    "                              input_size=num_features,\n",
    "                              F1=F1,\n",
    "                              F2=F2,\n",
    "                              window_size=window_size,\n",
    "                              skills=skills, \n",
    "                              certs=certs,\n",
    "                              licenses=licenses,\n",
    "                              languages=languages,\n",
    "                              addresses=addresses,\n",
    "                              w2v=w2v,\n",
    "                              skill_embedding_size=skill_embedding_size,\n",
    "                              address_embedding_size=address_embedding_size,\n",
    "                              function_embedding_size=function_embedding_size,\n",
    "                              isco4_embedding_size=isco4_embedding_size,\n",
    "                              company_embedding_size=company_embedding_size,\n",
    "                              candidate_lengths=candidate_lens,\n",
    "                              w2v_embedding_size=w2v_embedding_size,\n",
    "                              max_len=max_len)\n",
    "\n",
    "                    cnn = cnn.to(device)\n",
    "\n",
    "                    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "                    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "                                        \n",
    "                    trainloader, valloader, testloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                                        weight_type=3, batch_size=128)\n",
    "\n",
    "                    # Store results of current configuration\n",
    "                    outcome = train_loop(cnn, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                    outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                    outcome[\"F1 size\"] = [F1] * num_epochs\n",
    "                    outcome[\"F2 size\"] = [F2] * num_epochs\n",
    "                    outcome[\"Window size\"] = [window_size] * num_epochs\n",
    "\n",
    "                    full_results.append(outcome)\n",
    "\n",
    "                    current += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce747d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['lr', 'F1 size', 'F2 size', 'Window size', 'Epoch'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5490a380071a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmerge_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F1 size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F2 size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Window size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['lr', 'F1 size', 'F2 size', 'Window size', 'Epoch'] are in the columns\""
     ]
    }
   ],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"F1 size\", \"F2 size\", \"Window size\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6491fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-675a0c330fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"
     ]
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ac7859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "skill_embedding_size = 15\n",
    "certs_embedding_size = 20\n",
    "license_embedding_size = 5\n",
    "language_embedding_size = 5\n",
    "address_embedding_size = 10\n",
    "function_embedding_size = 40\n",
    "isco4_embedding_size = 35\n",
    "education_embedding_size = 5\n",
    "isco_level_embedding_size = 5\n",
    "company_embedding_size = 30\n",
    "w2v_embedding_size = 30\n",
    "\n",
    "cnn = XCM(num_classes=num_classes,\n",
    "          input_size=num_features,\n",
    "          F1=16,\n",
    "          F2=256,\n",
    "          window_size=0.8,\n",
    "          skills=skills, \n",
    "          certs=certs,\n",
    "          licenses=licenses,\n",
    "          languages=languages,\n",
    "          addresses=addresses,\n",
    "          w2v=w2v,\n",
    "          skill_embedding_size=skill_embedding_size,\n",
    "          address_embedding_size=address_embedding_size,\n",
    "          function_embedding_size=function_embedding_size,\n",
    "          isco4_embedding_size=isco4_embedding_size,\n",
    "          company_embedding_size=company_embedding_size,\n",
    "          candidate_lengths=candidate_lens,\n",
    "          w2v_embedding_size=w2v_embedding_size,\n",
    "          max_len=max_len)\n",
    "\n",
    "cnn.load_state_dict(torch.load(\"../models/eCNN_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "915d1d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XCM(\n",
       "  (skill_embedding): Linear(in_features=317, out_features=15, bias=False)\n",
       "  (certs_embedding): Linear(in_features=98, out_features=20, bias=False)\n",
       "  (license_embedding): Linear(in_features=8, out_features=3, bias=False)\n",
       "  (language_embedding): Linear(in_features=23, out_features=10, bias=False)\n",
       "  (w2v_embedding): Linear(in_features=300, out_features=30, bias=False)\n",
       "  (address_embedding): Embedding(4768, 10)\n",
       "  (function_embedding): Embedding(2992, 40)\n",
       "  (isco_code_embedding): Embedding(355, 35)\n",
       "  (company_embedding): Embedding(441153, 30)\n",
       "  (education_embedding): Embedding(6, 3)\n",
       "  (isco_level_embedding): Embedding(5, 3)\n",
       "  (relu): ReLU()\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d): Conv2d(1, 16, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
       "  (_1x1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1d_padding): ZeroPad2d(padding=(0, 0, 10, 9), value=0.0)\n",
       "  (conv1d): Conv1d(1, 16, kernel_size=(20, 200), stride=(1,))\n",
       "  (_1x1_2): Conv1d(16, 1, kernel_size=(1, 1), stride=(1,))\n",
       "  (final_conv1d): Conv1d(1, 256, kernel_size=(20, 201), stride=(1,), padding=same)\n",
       "  (avgpool2d): AvgPool2d(kernel_size=(25, 201), stride=1, padding=0)\n",
       "  (fc): Linear(in_features=256, out_features=355, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2968ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                        weight_type=3, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d4e87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.1484375\n",
      "\n",
      "Majority class accuracy: 0.1484375\n",
      "Majority class predictions: 0.03125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "        \n",
    "        career, duration = cnn.create_tensor(career)\n",
    "        pred = cnn(career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())    \n",
    "        print()\n",
    "\n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        print(\"Majority class accuracy:\", (job == majority_class).cpu().numpy().mean())        \n",
    "        print(\"Majority class predictions:\", (pred.argmax(1) == majority_class).cpu().numpy().mean())\n",
    "        \n",
    "        plt.show()        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26e2a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "del skills\n",
    "del certs\n",
    "del w2v\n",
    "del languages\n",
    "del to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9a4cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, isco_level, source, education, company_name, function_id, isco_code, w2v_list, skill_list, certs_list, license_list, langs_list, address_emb\n",
    "feature_names = [\"Time spent\", \"isco level\", \"education\", \"company name\", \"function\", \"isco code\",\n",
    "                 \"cv\", \"skills\", \"certificates\", \"licenses\", \"languages\", \"location\"]\n",
    "\n",
    "# skill_embedding_size=50, certs_embedding_size=20,\n",
    "# license_embedding_size=3, language_embedding_size=10,\n",
    "# address_embedding_size=25, function_embedding_size=50, \n",
    "# isco4_embedding_size=25, education_embedding_size=3, \n",
    "# isco_level_embedding_size=3, company_embedding_size=50\n",
    "source_embedding_size = 1\n",
    "# w2v_embedding_size = 300\n",
    "\n",
    "embedding_sizes= [0, 1, isco_level_embedding_size, education_embedding_size, company_embedding_size, \n",
    "                  function_embedding_size, isco4_embedding_size, w2v_embedding_size, skill_embedding_size, \n",
    "                  certs_embedding_size, license_embedding_size, language_embedding_size, address_embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbbed59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "035f45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_layers(output, embedding_sizes, axis=\"features\"):\n",
    "    \"\"\"order: start=0, reg_features, isco_level_embedding_size, source_embedding_size, \n",
    "              education_embedding_size, company_embedding_size, function_embedding_size, \n",
    "              isco4_embedding_size, w2v_embedding_size, skill_embedding_size, \n",
    "              certs_embedding_size, license_embedding_size, language_embedding_size, \n",
    "              address_embedding_size\"\"\"\n",
    "        \n",
    "    if axis == \"features\":\n",
    "        output = output.T\n",
    "        idxs = np.cumsum(embedding_sizes)\n",
    "        result = np.stack([output[idxs[i]:idxs[i+1]].mean(axis=0) for i in range(len(idxs) - 1)])\n",
    "    elif axis == \"time\":\n",
    "        result = output.sum(axis=1)\n",
    "        # result = np.stack([result] * (len(embedding_sizes) - 1))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8981025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradcam(model, feature_layer, time_layer, valloader, full_batch=True, group=None, min_len=4, max_len=10):\n",
    "    \n",
    "    # model.softmax = Identity()\n",
    "\n",
    "    # Initialize gradcam\n",
    "    cam = GradCAM(model=model, target_layers=[feature_layer], use_cuda=True)\n",
    "    cam2 = GradCAM(model=model, target_layers=[time_layer], use_cuda=True)\n",
    "            \n",
    "    if group == \"Finance\":\n",
    "        allowed = {i - 1 for i in {5, 20, 70, 71, 72, 73, 74, 75, 142, 143, 146, 195}}\n",
    "    elif group == \"Healthcare\":\n",
    "        allowed = {i - 1 for i in{16, 17, 48, 49, 50, 51, 52, 53, 54, 55, \n",
    "                                  56, 57, 58, 59, 60, 127, 128, 129, 130,\n",
    "                                  131, 132, 133, 134, 135, 136, 137, 138,\n",
    "                                  140, 141, 128, 234, 235, 236}}\n",
    "    elif group == \"Customer_support\":\n",
    "        allowed = {i - 1 for i in {152, 183, 185, 186, 187, 188, 189, 190, 191, 192}}\n",
    "    else:\n",
    "        allowed = set(range(0, 355))\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        # Create batch\n",
    "        c, i, jobs = next(iter(valloader))\n",
    "\n",
    "        # Convert batch to tensor\n",
    "        i, duration = cnn.create_tensor(i.to(device))\n",
    "\n",
    "        for j in range(len(i)):\n",
    "            if jobs[j].item() in allowed:\n",
    "                curr = i[j]\n",
    "                dur = duration[j]\n",
    "                candidate = c[j]\n",
    "                curr_class = jobs[j].item()\n",
    "\n",
    "                if min_len < dur < max_len:\n",
    "                    curr = curr.unsqueeze(0)\n",
    "\n",
    "                    cam_result = cam(input_tensor=curr, targets=[ClassifierOutputTarget(curr_class)])[0]\n",
    "                    cam_result2 = cam2(input_tensor=curr, targets=[ClassifierOutputTarget(curr_class)])[0]\n",
    "                    values = merge_layers(curr[0].cpu().detach(), embedding_sizes)\n",
    "\n",
    "                    # Values, gradcam on features, gradcam on time steps, career_duration\n",
    "                    return values, cam_result, cam_result2, dur, candidate, curr_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b23ddbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_gradients(model, feature_layer, time_layer, valloader, lang=\"en\", group=None):\n",
    "    \n",
    "    if lang != \"en\":        \n",
    "        feature_names = [\"Dagen gewerkt\", \"Werkniveau\", \"Opleidingsniveau\", \"Bedrijf\", \"Functie\", \"Isco code\",\n",
    "                         \"CV\", \"Vaardigheden\", \"Certificaten\", \"Rijbewijzen\", \"Talen\", \"Postcode\"]\n",
    "    \n",
    "    good = False\n",
    "    \n",
    "    while not good:\n",
    "        values, cam, cam2, career_duration, candidate, curr_class = apply_gradcam(model, feature_layer, time_layer, valloader, group=group)\n",
    "\n",
    "        print(f\"Current group: {group}\\nCurren candidate: {int(candidate.item())}\\nClass: {curr_class + 1}\")\n",
    "\n",
    "        to_plot = merge_layers(cam, embedding_sizes, axis=\"features\")\n",
    "        time = merge_layers(cam2, embedding_sizes, axis=\"time\")\n",
    "\n",
    "        to_plot = to_plot.T[-career_duration:].T\n",
    "        time = time.T[-career_duration:].T\n",
    "\n",
    "        values = merge_layers(values.T, embedding_sizes)\n",
    "\n",
    "        # Sum each feature over the time dimension and normalize    \n",
    "        feature_weight = to_plot.T.sum(axis=0)    \n",
    "\n",
    "        feature_weight /= feature_weight.sum()\n",
    "\n",
    "        # Normalized feature attention \n",
    "        series = pd.Series(feature_weight, index=feature_names).sort_values(ascending=False)    \n",
    "\n",
    "        # Create grid\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        grid = plt.GridSpec(2, 2, wspace=0.35, hspace=0.5)\n",
    "        grid.update(top=0.9)\n",
    "\n",
    "        ax1 = plt.subplot(grid[0, 0])\n",
    "        ax2 = plt.subplot(grid[0, 1])\n",
    "        ax3 = plt.subplot(grid[1, :])\n",
    "        # ax4 = plt.subplot(grid[2, :2])\n",
    "\n",
    "        if lang == \"en\":\n",
    "            fig.suptitle(\"Attention types\")\n",
    "        else:\n",
    "            fig.suptitle(\"Soorten aandacht\")\n",
    "\n",
    "        # Plot total attention for each feature\n",
    "        sns.barplot(x=series.values * 100, y=series.index, ax=ax1)\n",
    "        # ax1.set_xticklabels(labels=series.values, rotation=90)\n",
    "        if lang == \"en\":\n",
    "            ax1.set_xlabel(\"Gradient\")\n",
    "            ax1.set_title(\"Attention per feature\")\n",
    "        else:\n",
    "            ax1.set_xlabel(\"Aandacht\")\n",
    "            ax1.set_title(\"Aandacht per eigenschap\")\n",
    "            ax1.xaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "            ax1.grid(axis='x')\n",
    "            ax1.set_axisbelow(True)\n",
    "\n",
    "        series2 = pd.Series(dict(zip(range(1, career_duration + 1), time / time.sum())))\n",
    "\n",
    "        sns.barplot(x=series2.index, y=series2.values  * 100, ax=ax2)\n",
    "        if lang == \"en\":\n",
    "            ax2.set_title(\"Attention per time step\")\n",
    "            ax2.set_ylabel(\"Attention score\")\n",
    "            ax2.set_xlabel(\"Time step\")\n",
    "        else:\n",
    "            ax2.set_title(\"Aandacht per baan nummer\")\n",
    "            ax2.set_ylabel(\"Aandacht\")\n",
    "            ax2.set_xlabel(\"Baan nummer\")\n",
    "            ax2.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "            ax2.grid(axis='y')\n",
    "            ax2.set_axisbelow(True)\n",
    "\n",
    "        cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n",
    "\n",
    "        # Normalize gradients\n",
    "        # to_plot *= (values.sum(axis=0) != 0)\n",
    "        to_plot /= to_plot.max() \n",
    "        to_plot = scipy.special.softmax(to_plot, axis=0) * 100\n",
    "        to_plot = pd.DataFrame(to_plot)\n",
    "\n",
    "        to_plot.index = feature_names\n",
    "        to_plot.columns = range(1, career_duration + 1)\n",
    "\n",
    "        to_plot = to_plot.loc[series.index]\n",
    "\n",
    "        if lang == \"en\":\n",
    "            sns.heatmap(to_plot, cmap=cmap, xticklabels=to_plot.columns, yticklabels=to_plot.index, \n",
    "                        cbar_kws={'label': 'Gradient'}, linewidths=0.1, ax=ax3)\n",
    "\n",
    "            ax3.set_title(\"Spatiotemporal attention\")\n",
    "            ax3.set_xlabel(\"Time step\")\n",
    "        else:\n",
    "            sns.heatmap(to_plot, cmap=cmap, xticklabels=to_plot.columns, yticklabels=to_plot.index, \n",
    "                        cbar_kws={'label': 'Aandacht', 'format': '%.0f%%'}, linewidths=0.1, ax=ax3)\n",
    "\n",
    "            ax3.set_title(\"Aandacht per baan, per eigenschap\")\n",
    "            ax3.set_xlabel(\"Baan nummer\")\n",
    "            \n",
    "        plt.show()\n",
    "            \n",
    "        agreed = input(\"Good enough (y/n)? \")\n",
    "        good = agreed == \"y\"\n",
    "\n",
    "    if lang == \"en\":\n",
    "        fig.savefig(f\"Visualisations/{group}/eCNN_c{int(candidate.item())}_p{curr_class + 1}.pdf\", bbox_inches='tight');\n",
    "    else:\n",
    "        fig.savefig(f\"Visualisations/{group}/eCNN_c{int(candidate.item())}_p{curr_class + 1}.png\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "012fbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b592a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gradients(cnn, cnn.conv2d, cnn.conv1d, valloader, lang=\"nl\", group=\"Customer_support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b8669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
