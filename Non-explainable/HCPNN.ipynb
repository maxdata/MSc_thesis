{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa101870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2dc0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4734642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1540040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c04fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46f3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc8ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f63508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>job_order</th>\n",
       "      <th>time_between</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>3</td>\n",
       "      <td>1155</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>4</td>\n",
       "      <td>203</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  job_order  time_between  time_spent  isco_functie_niveau  \\\n",
       "0         84556          0            37         156                  2.0   \n",
       "1         84556          1            23         116                  1.0   \n",
       "2         84556          2            23         275                  2.0   \n",
       "3         84556          3          1155           4                  1.0   \n",
       "4         84556          4           203          11                  1.0   \n",
       "\n",
       "   education  function_id  isco_code4  \n",
       "0        0.0        937.0       207.0  \n",
       "1        0.0        811.0       347.0  \n",
       "2        0.0        937.0       207.0  \n",
       "3        0.0       1521.0       343.0  \n",
       "4        0.0       1521.0       343.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f38a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efbd227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecbad980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465468/465468 [00:44<00:00, 10522.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe1de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are longer than 100 jobs or only 1 job\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens <= 101) & (career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b21bf9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[0.0, 37.0, 156.0, 2.0, 0.0, 937.0, 207.0], [...\n",
       "84612    [[0.0, 2537.0, 6.0, 1.0, 0.0, 1521.0, 343.0], ...\n",
       "84731    [[0.0, 46.0, 23.0, 1.0, 0.0, 1521.0, 343.0], [...\n",
       "85437    [[0.0, 747.0, 670.0, 1.0, 2.0, 1521.0, 343.0],...\n",
       "85627    [[0.0, 140.0, 4627.0, 3.0, 0.0, 1922.0, 155.0]...\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec8837a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "candidate_lens = defaultdict(int)\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, 6]\n",
    "    \n",
    "    if not np.isnan(label):\n",
    "        candidate_lens[idx] = len(career) - 1\n",
    "        \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1aed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23c402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c65667",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85dbd12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f94379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265309, 265309)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71030b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:75000]\n",
    "# y = y[:75000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133efab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "split = 0.8\n",
    "random.seed(42)\n",
    "\n",
    "training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "\n",
    "train_indices, val_indices = idxs[training], idxs[test]\n",
    "X_train, X_val = to_fill[training], to_fill[test]\n",
    "y_train, y_val = y[training].astype(int), y[test].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27f20d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train) + 1\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[y_train]\n",
    "sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "# Create dataloaders\n",
    "train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                           torch.Tensor(X_train), \n",
    "                           torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=512, sampler=sampler)\n",
    "\n",
    "val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                         torch.Tensor(X_val),\n",
    "                         torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "valloader = DataLoader(val_data, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b697892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, skills, certs, w2v, \n",
    "                 candidate_lengths, max_len, static_embedding_size, position_embedding_size):\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size + 300\n",
    "        self.hidden_size = hidden_size\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        self.LSTMs = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            input_size = self.input_size if i == 0 else hidden_size\n",
    "            self.LSTMs.append(nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                                      num_layers=1, batch_first=True))\n",
    "        \n",
    "        # Final fully-connected layer takes the LSTM output, as well as the static embeddings\n",
    "        self.fc = nn.Linear(hidden_size + static_embedding_size, num_classes)\n",
    "        \n",
    "        # Static embeddings: skills, certificates TODO: languages, location, etc.\n",
    "        self.static_embedding = nn.Linear(317 + 98, static_embedding_size, bias=False)\n",
    "        self.static_embedding.weight.data = torch.randn_like(self.static_embedding.weight) \n",
    "        \n",
    "        # Position embeddings: regular features for each job\n",
    "        self.position_embedding = nn.Linear(self.input_size, position_embedding_size, bias=False)\n",
    "        self.position_embedding.weight.data = torch.randn_like(self.position_embedding.weight) \n",
    "\n",
    "        # Skill lookup\n",
    "        self.skill_keys = set(skills.keys())\n",
    "        self.skills = np.vectorize(skills.get)\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs_keys = set(certs.keys())\n",
    "        self.certs = np.vectorize(certs.get)\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len\n",
    "                \n",
    "    def static_lookup(self, candidate):\n",
    "        \"\"\"Looks up a candidate's static features (skills, certificates)\"\"\"\n",
    "         # Look up skills            \n",
    "        if candidate.item() in self.skill_keys:\n",
    "            skill_list = torch.Tensor(self.skills(candidate.item())).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            skill_list = torch.Tensor([0] * 317).type(torch.LongTensor).to(device)\n",
    "\n",
    "        # Look up certificates\n",
    "        if candidate.item() in self.certs_keys:\n",
    "            certs_list = torch.Tensor(self.certs(candidate.item())).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            certs_list = torch.Tensor([0] * 98).type(torch.LongTensor).to(device)\n",
    "            \n",
    "        return skill_list, certs_list\n",
    "    \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.Tensor(cvs[0]).type(torch.LongTensor).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "                if durations[-1] == -1: # Sometimes contains -1 --> last location > (career duration)?\n",
    "                    durations.pop()\n",
    "                    durations[-1] -= 1\n",
    "                    # In case the last one should be ignored completely\n",
    "                    if durations[-1] == 0:\n",
    "                        durations.pop()\n",
    "\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.Tensor(cvs[0]).type(torch.LongTensor).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.Tensor([0] * 300).type(torch.LongTensor).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    "\n",
    "    def forward(self, candidate, x):       \n",
    "        outputs = []\n",
    "        \n",
    "        # Default width of a row (filled with 0s)\n",
    "        cv_width = torch.Tensor([0] * 300).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_cvs = []\n",
    "        candidate_static = []\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for c in candidate:\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]            \n",
    "            \n",
    "            # Get skills and certificates\n",
    "            skill_list, certs_list = self.static_lookup(c)\n",
    "            \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([cv_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.Tensor([]).type(torch.LongTensor).to(device)\n",
    "                \n",
    "            # Combine and embed\n",
    "            static_features = torch.cat([skill_list, certs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            static_features = self.static_embedding(static_features)\n",
    "            \n",
    "            # Broadcast CV to the correct length\n",
    "            cv_features = torch.cat([zeros, w2v_list], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_cvs.append(cv_features)\n",
    "            candidate_static.append(static_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_cvs)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, additional_features], dim=2)\n",
    "        \n",
    "        # Forward pass\n",
    "        for i in range(self.num_layers):\n",
    "            # Last hidden state, all hidden states, all cell states\n",
    "            output, (h_n, c_n) = self.LSTMs[i](x)\n",
    "            outputs.append(output)\n",
    "            x = output\n",
    "            \n",
    "        h_out = h_n.view(-1, self.hidden_size)\n",
    "        \n",
    "        static = torch.stack((candidate_static)).type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # combine with embedding\n",
    "        x = torch.cat([h_out, static], dim=1)\n",
    "        \n",
    "        # TODO: attention ???        \n",
    "\n",
    "        # Fully-connected\n",
    "        out = self.fc(x)\n",
    "\n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aae8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            \n",
    "            candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(candidate, career)\n",
    "\n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "        \n",
    "        stats = test_loop(valloader, model, criterion)\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"Acc@20\"].append(stats[3])\n",
    "        results[\"test_loss\"].append(stats[4])\n",
    "        \n",
    "        scheduler.step()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "            pred = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            at20 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "                at20.append(answer.item() in predictions[:20])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            acc20 += np.sum(at20)\n",
    "            \n",
    "    # print(\"\\nValidation:\", Counter(np.array(pred.argmax(1).cpu())))\n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    acc20 /= size\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}%, Acc@20: {100*acc20:>0.2f}% Avg loss: {test_loss:>8f}\\n\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "120b1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805be189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 0/64\n",
      "- Learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " LSTM(\n",
      "  (softmax): LogSoftmax()\n",
      "  (LSTMs): ModuleList(\n",
      "    (0): LSTM(307, 500, batch_first=True)\n",
      "    (1): LSTM(500, 500, batch_first=True)\n",
      "    (2): LSTM(500, 500, batch_first=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=510, out_features=354, bias=True)\n",
      "  (static_embedding): Linear(in_features=415, out_features=10, bias=False)\n",
      "  (position_embedding): Linear(in_features=307, out_features=10, bias=False)\n",
      ") \n",
      "\n",
      "Epoch: 1, batch: 415/415, loss: 2.89608\n",
      "Test Error:\n",
      "Acc@1: 10.28%, Acc@5: 30.67%, Acc@10: 41.20%, Acc@20: 54.39% Avg loss: 4.354008\n",
      "\n",
      "Epoch: 2, batch: 415/415, loss: 2.04026\n",
      "Test Error:\n",
      "Acc@1: 15.07%, Acc@5: 37.69%, Acc@10: 48.98%, Acc@20: 62.42% Avg loss: 4.015932\n",
      "\n",
      "Epoch: 3, batch: 415/415, loss: 1.49272\n",
      "Test Error:\n",
      "Acc@1: 17.83%, Acc@5: 42.22%, Acc@10: 53.82%, Acc@20: 66.80% Avg loss: 3.813528\n",
      "\n",
      "Epoch: 4, batch: 415/415, loss: 1.52903\n",
      "Test Error:\n",
      "Acc@1: 21.16%, Acc@5: 45.71%, Acc@10: 56.52%, Acc@20: 68.62% Avg loss: 3.697063\n",
      "\n",
      "Epoch: 5, batch: 415/415, loss: 1.63709\n",
      "Test Error:\n",
      "Acc@1: 21.67%, Acc@5: 46.53%, Acc@10: 57.53%, Acc@20: 69.61% Avg loss: 3.648775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "try:            \n",
    "    for learning_rate in [1e-1, 1e-2, 1e-3, 1e-4][2:]:\n",
    "        for num_layers in [3, 5, 10]:\n",
    "            for hidden_size in [500, 500][1:]:\n",
    "\n",
    "                lstm = LSTM(num_classes=num_classes,\n",
    "                            input_size=num_features,\n",
    "                            num_layers=num_layers,\n",
    "                            hidden_size=hidden_size,\n",
    "                            skills=skills, \n",
    "                            certs=certs,\n",
    "                            w2v=w2v,\n",
    "                            static_embedding_size=10,\n",
    "                            position_embedding_size=10,\n",
    "                            candidate_lengths=candidate_lens,\n",
    "                            max_len=max_len)\n",
    "\n",
    "                lstm = lstm.to(device)\n",
    "\n",
    "                optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "                print(f\"Current iteration {current}/{4**3}\\n- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", lstm, \"\\n\")\n",
    "\n",
    "                # Store results of current configuration\n",
    "                outcome = train_loop(lstm, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                outcome[\"Number of layers\"] = [num_layers] * num_epochs\n",
    "                outcome[\"Nodes per layer\"] = [hidden_size] * num_epochs\n",
    "\n",
    "                full_results.append(outcome)\n",
    "\n",
    "                current += 1\n",
    "            break\n",
    "\n",
    "        # We ignore LR for now\n",
    "        break\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ff2f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Number of layers\", \"Nodes per layer\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80066ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>Acc@20</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">500</th>\n",
       "      <th>1</th>\n",
       "      <td>0.102823</td>\n",
       "      <td>0.306717</td>\n",
       "      <td>0.411952</td>\n",
       "      <td>0.543949</td>\n",
       "      <td>4.354008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150673</td>\n",
       "      <td>0.376899</td>\n",
       "      <td>0.489804</td>\n",
       "      <td>0.624157</td>\n",
       "      <td>4.015932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178301</td>\n",
       "      <td>0.422185</td>\n",
       "      <td>0.538201</td>\n",
       "      <td>0.667992</td>\n",
       "      <td>3.813528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.457050</td>\n",
       "      <td>0.565244</td>\n",
       "      <td>0.686216</td>\n",
       "      <td>3.697063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216652</td>\n",
       "      <td>0.465286</td>\n",
       "      <td>0.575270</td>\n",
       "      <td>0.696148</td>\n",
       "      <td>3.648775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Acc@1     Acc@5    Acc@10  \\\n",
       "lr    Number of layers Nodes per layer Epoch                                 \n",
       "0.001 3                500             1      0.102823  0.306717  0.411952   \n",
       "                                       2      0.150673  0.376899  0.489804   \n",
       "                                       3      0.178301  0.422185  0.538201   \n",
       "                                       4      0.211602  0.457050  0.565244   \n",
       "                                       5      0.216652  0.465286  0.575270   \n",
       "\n",
       "                                                Acc@20  test_loss  \n",
       "lr    Number of layers Nodes per layer Epoch                       \n",
       "0.001 3                500             1      0.543949   4.354008  \n",
       "                                       2      0.624157   4.015932  \n",
       "                                       3      0.667992   3.813528  \n",
       "                                       4      0.686216   3.697063  \n",
       "                                       5      0.696148   3.648775  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36aeb202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.212890625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "        pred = lstm(candidate, career)\n",
    "        \n",
    "        print((pred.argmax(1) == job).type(torch.float).mean().item())        \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321269ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(2, 4)\n",
    "inpt = torch.Tensor([[1, 1, 1],\n",
    "                     [0, 1, 0]]).type(torch.LongTensor)\n",
    "\n",
    "emb(inpt).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030111ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
