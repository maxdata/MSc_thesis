{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68635bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4bf3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611734d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd54043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7335bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3806d550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5dcd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c31297b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501f39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           90\n",
       "84612           48\n",
       "84731         3766\n",
       "85437         3812\n",
       "85627         1556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08d3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035a6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a1a002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc8bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d92e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>job_order</th>\n",
       "      <th>time_between</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>source</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.292887</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306568</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.306568</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799670</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.130664</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  job_order  time_between  time_spent  isco_functie_niveau  \\\n",
       "0         84556          0     -0.292887   -0.210459                  2.0   \n",
       "1         84556          1     -0.306568   -0.252626                  1.0   \n",
       "2         84556          2     -0.306568   -0.085012                  2.0   \n",
       "3         84556          3      0.799670   -0.370694                  1.0   \n",
       "4         84556          4     -0.130664   -0.363314                  1.0   \n",
       "\n",
       "   source  education  company_name  function_id  isco_code4  \n",
       "0       0        0.0        324258          936         208  \n",
       "1       0        0.0        324258          809         348  \n",
       "2       0        0.0        329244          936         208  \n",
       "3       0        0.0        368140         1519         344  \n",
       "4       0        0.0        419826         1519         344  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a3c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ec4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec01d83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f57014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61df45bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469568/469568 [00:45<00:00, 10366.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099edc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ef1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e678292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[0.0, -0.292886688151019, -0.2104587010204839...\n",
       "84612    [[0.0, 2.150219165944193, -0.3685852264755267,...\n",
       "84731    [[0.0, -0.28409150707627623, -0.35066422025728...\n",
       "85437    [[0.0, 0.4009553744120213, 0.3313881928721292,...\n",
       "85888    [[0.0, -0.23816111701928622, -0.28952196374800...\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f03b9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9892b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8246c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c3dcd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2eafafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf90bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f85e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:75000]\n",
    "# y = y[:75000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6beb4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "\n",
    "    train_indices, val_indices = idxs[training], idxs[test]\n",
    "    X_train, X_val = to_fill[training], to_fill[test]\n",
    "    y_train, y_val = y[training].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6593309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, \n",
    "                 num_layers, skills, certs, licenses, languages, \n",
    "                 addresses, w2v, candidate_lengths, max_len, \n",
    "                 skill_embedding_size=50, certs_embedding_size=20,\n",
    "                 license_embedding_size=3, language_embedding_size=10,\n",
    "                 address_embedding_size=25, function_embedding_size=50, \n",
    "                 isco4_embedding_size=25, education_embedding_size=3, \n",
    "                 isco_level_embedding_size=3, company_embedding_size=50):\n",
    "        \n",
    "        super(CNN_LSTM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size + 300\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4757, address_embedding_size)       \n",
    "        \n",
    "        # Categorical feature embeddings isco_functie_niveau\tsource\teducation\tcompany_name\tfunction_id\tisco_code4\n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.source_embedding = nn.Embedding(2, 1)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "                \n",
    "        # -6 --> embedded features get replaced\n",
    "        N = self.input_size - 5 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "        \n",
    "        kernel_size = 2\n",
    "        \n",
    "        self.conv_padding = nn.ZeroPad2d((0, 0, kernel_size // 2, (kernel_size - 1 ) // 2))\n",
    "\n",
    "        \n",
    "        self.conv32 = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=32,\n",
    "                                kernel_size=kernel_size, \n",
    "                                stride=1)\n",
    "        \n",
    "        self.conv64 = nn.Conv2d(in_channels=32, \n",
    "                                out_channels=64,\n",
    "                                kernel_size=kernel_size, \n",
    "                                stride=1)\n",
    "        \n",
    "        self.maxpooling = nn.MaxPool3d(kernel_size=(64, 2, 1))\n",
    "            \n",
    "        self.lstm = nn.LSTM(input_size=N,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "            \n",
    "        # Final fully-connected layer takes the LSTM output, as well as the static embeddings\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])  \n",
    "                \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:\n",
    "                    # 0, 10, 20, 30, 40, 50\n",
    "                    # duration = 50\n",
    "                    # ---> 0, 5, 15, 25\n",
    "                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * 300).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    " \n",
    "    def forward(self, candidate, x):               \n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * 408).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "        \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "                        \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "            \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                   \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, source, education, company_name, function_id, isco_code = [x[:,:,-6],\n",
    "                                                                               x[:,:,-5],\n",
    "                                                                               x[:,:,-4],\n",
    "                                                                               x[:,:,-3],\n",
    "                                                                               x[:,:,-2],\n",
    "                                                                               x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-6].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        source_smoothing = (source != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "        \n",
    "        isco_level, source, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                                self.source_embedding(source.type(torch.LongTensor).to(device)) * source_smoothing,\n",
    "                                                                                self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                                self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                                self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                                self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, source, education, company_name, function_id, isco_code, additional_features], dim=2)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv_padding(x)\n",
    "                        \n",
    "        # Forward pass\n",
    "        x = self.conv32(x)\n",
    "        \n",
    "        x = self.conv_padding(x)\n",
    "        x = self.conv64(x)\n",
    "        \n",
    "        # Apply maxpooling\n",
    "        x = self.maxpooling(x)\n",
    "                \n",
    "        # Get rid of extra dimension\n",
    "        x = x.squeeze(1)\n",
    "                        \n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        \n",
    "        x = h_n.view(-1, self.hidden_size)    \n",
    "        \n",
    "        # Fully-connected\n",
    "        out = self.fc(x)\n",
    "    \n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73a3ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "\n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            \n",
    "            career, job = career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(candidate, career)\n",
    "                        \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "               \n",
    "        training_loss /= len(trainloader)\n",
    "                \n",
    "        stats = test_loop(valloader, model, criterion)\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"Acc@20\"].append(stats[3])\n",
    "        results[\"test_loss\"].append(stats[4])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch duration: {int((time.time() - start) // 60)}:{int((time.time() - start) % 60):02d}\\n\")\n",
    "        \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "        plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "        plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Average loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            at20 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "                at20.append(answer.item() in predictions[:20])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            acc20 += np.sum(at20)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    acc20 /= size\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}%, Acc@20: {100*acc20:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45169c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "615ec8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 0/6\n",
      "- Initial learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " CNN_LSTM(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=50, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=20, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=3, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=10, bias=False)\n",
      "  (address_embedding): Embedding(4757, 25)\n",
      "  (function_embedding): Embedding(2992, 50)\n",
      "  (isco_code_embedding): Embedding(355, 25)\n",
      "  (company_embedding): Embedding(441153, 50)\n",
      "  (source_embedding): Embedding(2, 1)\n",
      "  (education_embedding): Embedding(6, 3)\n",
      "  (isco_level_embedding): Embedding(5, 3)\n",
      "  (conv_padding): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "  (conv32): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv64): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (maxpooling): MaxPool3d(kernel_size=(64, 2, 1), stride=(64, 2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm): LSTM(543, 1000, batch_first=True)\n",
      "  (fc): Linear(in_features=1000, out_features=355, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ") \n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 15:53:59\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.65 GiB (GPU 0; 11.17 GiB total capacity; 9.40 GiB already allocated; 1.47 GiB free; 9.42 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b6eea5589557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Store results of current configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0moutcome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0moutcome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Number of layers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-3676de341071>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcareer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# obtain the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-444e3f035d7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, candidate, x)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# Apply maxpooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.65 GiB (GPU 0; 11.17 GiB total capacity; 9.40 GiB already allocated; 1.47 GiB free; 9.42 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4][2:]\n",
    "num_layers_values = [1, 5, 10]\n",
    "hidden_sizes = [500, 1000][1:]\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for num_layers in num_layers_values:\n",
    "            for hidden_size in hidden_sizes:\n",
    "\n",
    "                lstm = CNN_LSTM(num_classes=num_classes,\n",
    "                                input_size=num_features,\n",
    "                                num_layers=num_layers,\n",
    "                                hidden_size=hidden_size,\n",
    "                                skills=skills, \n",
    "                                certs=certs,\n",
    "                                licenses=licenses,\n",
    "                                languages=languages,\n",
    "                                addresses=addresses,\n",
    "                                w2v=w2v,\n",
    "                                address_embedding_size=25,\n",
    "                                candidate_lengths=candidate_lens,\n",
    "                                max_len=max_len)\n",
    "\n",
    "                lstm = lstm.to(device)\n",
    "\n",
    "                optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "                print(f\"Current iteration {current}/{len(learning_rates) * len(num_layers_values) * len(hidden_sizes)}\")\n",
    "                print(f\"- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", lstm, \"\\n\")\n",
    "                \n",
    "                trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                        weight_type=3, batch_size=512)\n",
    "\n",
    "                # Store results of current configuration\n",
    "                outcome = train_loop(lstm, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                outcome[\"Number of layers\"] = [num_layers] * num_epochs\n",
    "                outcome[\"Nodes per layer\"] = [hidden_size] * num_epochs\n",
    "\n",
    "                full_results.append(outcome)\n",
    "                \n",
    "                with open(\"../results/CNN-LSTM.json\", \"w\") as current_stats:\n",
    "                    json.dump(full_results, current_stats)\n",
    "\n",
    "                current += 1\n",
    "            break\n",
    "\n",
    "        # We ignore LR for now\n",
    "        break\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Number of layers\", \"Nodes per layer\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af35dd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>Acc@20</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>training_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1000</th>\n",
       "      <th>1</th>\n",
       "      <td>0.192906</td>\n",
       "      <td>0.485084</td>\n",
       "      <td>0.606284</td>\n",
       "      <td>0.728051</td>\n",
       "      <td>3.826103</td>\n",
       "      <td>4.988491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213871</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>0.750347</td>\n",
       "      <td>3.629356</td>\n",
       "      <td>4.442084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224920</td>\n",
       "      <td>0.495425</td>\n",
       "      <td>0.623566</td>\n",
       "      <td>0.748279</td>\n",
       "      <td>3.558220</td>\n",
       "      <td>4.029389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228546</td>\n",
       "      <td>0.493130</td>\n",
       "      <td>0.623537</td>\n",
       "      <td>0.751452</td>\n",
       "      <td>3.509397</td>\n",
       "      <td>3.610237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.220330</td>\n",
       "      <td>0.485820</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>3.524175</td>\n",
       "      <td>3.211629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.229255</td>\n",
       "      <td>0.499221</td>\n",
       "      <td>0.630847</td>\n",
       "      <td>0.760036</td>\n",
       "      <td>3.486401</td>\n",
       "      <td>2.882281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228235</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.632575</td>\n",
       "      <td>0.763719</td>\n",
       "      <td>3.479807</td>\n",
       "      <td>2.787859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.230473</td>\n",
       "      <td>0.501969</td>\n",
       "      <td>0.634275</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>3.475665</td>\n",
       "      <td>2.726556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.233816</td>\n",
       "      <td>0.504972</td>\n",
       "      <td>0.633680</td>\n",
       "      <td>0.764371</td>\n",
       "      <td>3.470428</td>\n",
       "      <td>2.662190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.229793</td>\n",
       "      <td>0.504490</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>0.766411</td>\n",
       "      <td>3.471349</td>\n",
       "      <td>2.608609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2500</th>\n",
       "      <th>1</th>\n",
       "      <td>0.197779</td>\n",
       "      <td>0.481967</td>\n",
       "      <td>0.610505</td>\n",
       "      <td>0.735275</td>\n",
       "      <td>3.771620</td>\n",
       "      <td>4.966468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202170</td>\n",
       "      <td>0.478369</td>\n",
       "      <td>0.608069</td>\n",
       "      <td>0.730600</td>\n",
       "      <td>3.661020</td>\n",
       "      <td>4.370299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202142</td>\n",
       "      <td>0.475281</td>\n",
       "      <td>0.604159</td>\n",
       "      <td>0.735700</td>\n",
       "      <td>3.599979</td>\n",
       "      <td>3.816791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200612</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.605122</td>\n",
       "      <td>0.743293</td>\n",
       "      <td>3.619379</td>\n",
       "      <td>3.178057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.191121</td>\n",
       "      <td>0.472703</td>\n",
       "      <td>0.616086</td>\n",
       "      <td>0.754937</td>\n",
       "      <td>3.646664</td>\n",
       "      <td>2.564575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.217809</td>\n",
       "      <td>0.494660</td>\n",
       "      <td>0.633425</td>\n",
       "      <td>0.762161</td>\n",
       "      <td>3.565971</td>\n",
       "      <td>2.073564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.217696</td>\n",
       "      <td>0.499788</td>\n",
       "      <td>0.638949</td>\n",
       "      <td>0.766382</td>\n",
       "      <td>3.566889</td>\n",
       "      <td>1.890495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.219820</td>\n",
       "      <td>0.504179</td>\n",
       "      <td>0.641443</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>3.568731</td>\n",
       "      <td>1.761685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.213616</td>\n",
       "      <td>0.499306</td>\n",
       "      <td>0.637448</td>\n",
       "      <td>0.768337</td>\n",
       "      <td>3.599341</td>\n",
       "      <td>1.657246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.219537</td>\n",
       "      <td>0.506332</td>\n",
       "      <td>0.643652</td>\n",
       "      <td>0.772049</td>\n",
       "      <td>3.592572</td>\n",
       "      <td>1.569376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Acc@1     Acc@5    Acc@10  \\\n",
       "lr    Number of layers Nodes per layer Epoch                                 \n",
       "0.001 1                1000            1      0.192906  0.485084  0.606284   \n",
       "                                       2      0.213871  0.495170  0.620251   \n",
       "                                       3      0.224920  0.495425  0.623566   \n",
       "                                       4      0.228546  0.493130  0.623537   \n",
       "                                       5      0.220330  0.485820  0.621016   \n",
       "                                       6      0.229255  0.499221  0.630847   \n",
       "                                       7      0.228235  0.500581  0.632575   \n",
       "                                       8      0.230473  0.501969  0.634275   \n",
       "                                       9      0.233816  0.504972  0.633680   \n",
       "                                       10     0.229793  0.504490  0.635635   \n",
       "                       2500            1      0.197779  0.481967  0.610505   \n",
       "                                       2      0.202170  0.478369  0.608069   \n",
       "                                       3      0.202142  0.475281  0.604159   \n",
       "                                       4      0.200612  0.465705  0.605122   \n",
       "                                       5      0.191121  0.472703  0.616086   \n",
       "                                       6      0.217809  0.494660  0.633425   \n",
       "                                       7      0.217696  0.499788  0.638949   \n",
       "                                       8      0.219820  0.504179  0.641443   \n",
       "                                       9      0.213616  0.499306  0.637448   \n",
       "                                       10     0.219537  0.506332  0.643652   \n",
       "\n",
       "                                                Acc@20  test_loss  \\\n",
       "lr    Number of layers Nodes per layer Epoch                        \n",
       "0.001 1                1000            1      0.728051   3.826103   \n",
       "                                       2      0.750347   3.629356   \n",
       "                                       3      0.748279   3.558220   \n",
       "                                       4      0.751452   3.509397   \n",
       "                                       5      0.754710   3.524175   \n",
       "                                       6      0.760036   3.486401   \n",
       "                                       7      0.763719   3.479807   \n",
       "                                       8      0.765476   3.475665   \n",
       "                                       9      0.764371   3.470428   \n",
       "                                       10     0.766411   3.471349   \n",
       "                       2500            1      0.735275   3.771620   \n",
       "                                       2      0.730600   3.661020   \n",
       "                                       3      0.735700   3.599979   \n",
       "                                       4      0.743293   3.619379   \n",
       "                                       5      0.754937   3.646664   \n",
       "                                       6      0.762161   3.565971   \n",
       "                                       7      0.766382   3.566889   \n",
       "                                       8      0.769470   3.568731   \n",
       "                                       9      0.768337   3.599341   \n",
       "                                       10     0.772049   3.592572   \n",
       "\n",
       "                                              training_loss  \n",
       "lr    Number of layers Nodes per layer Epoch                 \n",
       "0.001 1                1000            1           4.988491  \n",
       "                                       2           4.442084  \n",
       "                                       3           4.029389  \n",
       "                                       4           3.610237  \n",
       "                                       5           3.211629  \n",
       "                                       6           2.882281  \n",
       "                                       7           2.787859  \n",
       "                                       8           2.726556  \n",
       "                                       9           2.662190  \n",
       "                                       10          2.608609  \n",
       "                       2500            1           4.966468  \n",
       "                                       2           4.370299  \n",
       "                                       3           3.816791  \n",
       "                                       4           3.178057  \n",
       "                                       5           2.564575  \n",
       "                                       6           2.073564  \n",
       "                                       7           1.890495  \n",
       "                                       8           1.761685  \n",
       "                                       9           1.657246  \n",
       "                                       10          1.569376  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a072581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.197265625\n",
      "Previous-job baseline accuracy: 0.0\n",
      "Fraction of previous job predictions: 0.08203125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "        pred = lstm(candidate, career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        previous_job = torch.Tensor(career_paths.loc[candidate.cpu()].apply(lambda x: x[-2][-1]).values).to(device)\n",
    "        print(\"Previous-job baseline accuracy:\", (job == previous_job).cpu().numpy().mean())\n",
    "        print(\"Fraction of previous job predictions:\", (pred.argmax(1) == previous_job).cpu().numpy().mean())\n",
    "                \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        \n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0942848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
