{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cce9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.10.2)\n",
      "Requirement already satisfied: wandb in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.12.17)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.5.12)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: setproctitle in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: pathtools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (8.0.1)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (3.17.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (1.26.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54e2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68bfc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mroanschellingerhout\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b151519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5ab093",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15165ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7272c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a15703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa41c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c0fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b0028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4a36b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1935909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc1ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf8030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f21dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8971abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2dac6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id  time_spent  isco_functie_niveau  education  company_name  \\\n",
       "0         84556   -0.210459                  2.0        0.0        324258   \n",
       "1         84556   -0.252626                  1.0        0.0        324258   \n",
       "2         84556   -0.085012                  2.0        0.0        329244   \n",
       "3         84556   -0.370694                  1.0        0.0        368140   \n",
       "4         84556   -0.363314                  1.0        0.0        419826   \n",
       "\n",
       "   function_id  isco_code4  \n",
       "0          936         208  \n",
       "1          809         348  \n",
       "2          936         208  \n",
       "3         1519         344  \n",
       "4         1519         344  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4dae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5898f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd0df6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37981e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "737a4dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:49<00:00, 9468.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd1c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9571a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ffc23c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[-0.21045870102048395, 2.0, 0.0, 324258.0, 93...\n",
       "84612    [[-0.3685852264755267, 1.0, 0.0, 201740.0, 151...\n",
       "84731    [[-0.35066422025728855, 1.0, 0.0, 353745.0, 15...\n",
       "85437    [[0.3313881928721292, 1.0, 2.0, 5500.0, 1519.0...\n",
       "85888    [[-0.2895219637480053, 2.0, 3.0, 423330.0, 795...\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ebfd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c98df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "049dc650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6fb97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b145ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f26c349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9670935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:75000]\n",
    "# y = y[:75000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa796ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "\n",
    "    train_indices, val_indices = idxs[training], idxs[test]\n",
    "    X_train, X_val = to_fill[training], to_fill[test]\n",
    "    y_train, y_val = y[training].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa6183d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, \n",
    "                 kernel_size, kernel_size2, F1, F2, dropout, \n",
    "                 num_layers, skills, certs, licenses, languages, \n",
    "                 addresses, w2v, candidate_lengths, max_len, \n",
    "                 skill_embedding_size=50, certs_embedding_size=20,\n",
    "                 license_embedding_size=3, language_embedding_size=10,\n",
    "                 address_embedding_size=25, function_embedding_size=50, \n",
    "                 isco4_embedding_size=25, education_embedding_size=3, \n",
    "                 isco_level_embedding_size=3, company_embedding_size=50):\n",
    "        \n",
    "        super(CNN_LSTM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size + 300\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        \n",
    "        # Categorical feature embeddings isco_functie_niveau\tsource\teducation\tcompany_name\tfunction_id\tisco_code4\n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "                \n",
    "        # -5 --> embedded features get replaced\n",
    "        N = self.input_size - 5 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "                \n",
    "        self.conv_padding = nn.ZeroPad2d((0, 0,\n",
    "                                          kernel_size // 2, (kernel_size - 1) // 2))\n",
    "        \n",
    "        self.conv32 = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=F1,\n",
    "                                kernel_size=(kernel_size, 1), \n",
    "                                stride=1)\n",
    "        \n",
    "        self.conv64 = nn.Conv2d(in_channels=F1, \n",
    "                                out_channels=F2,\n",
    "                                kernel_size=(kernel_size, 1), \n",
    "                                stride=1)\n",
    "        \n",
    "        self.avgpooling = nn.AvgPool3d(kernel_size=(F2, 1, kernel_size2))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "            \n",
    "        self.lstm = nn.LSTM(input_size=N // kernel_size2,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "            \n",
    "        # Final fully-connected layer takes the LSTM output, as well as the static embeddings\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])  \n",
    "                \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:\n",
    "                    # 0, 10, 20, 30, 40, 50\n",
    "                    # duration = 50\n",
    "                    # ---> 0, 5, 15, 25\n",
    "                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([torch.Tensor(embed_values[i + to_skip])] * duration, dim=0))\n",
    "                else:\n",
    "                    w2v_list = torch.LongTensor(cvs[0]).to(device)\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * 300).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    " \n",
    "    def forward(self, candidate, x):               \n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * 500).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "        \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "                \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "                        \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "            \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))\n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                   \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "        # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "                \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)\n",
    "        x = x.unsqueeze(1)\n",
    "                                       \n",
    "        # Forward pass\n",
    "        x = self.conv_padding(x)\n",
    "        x = self.conv32(x)\n",
    "        x = self.conv_padding(x)\n",
    "        x = self.conv64(x)\n",
    "                \n",
    "        # Apply maxpooling\n",
    "        x = self.avgpooling(x)\n",
    "                                            \n",
    "        # Get rid of extra dimension\n",
    "        x = x.squeeze(1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "            \n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        \n",
    "        x = h_n.squeeze(0)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully-connected\n",
    "        out = self.fc(x)\n",
    "    \n",
    "        # softmax\n",
    "        out = self.softmax(out)\n",
    "                        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f3142a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "\n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            \n",
    "            career, job = career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(candidate, career)\n",
    "                        \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f\" % (epoch + 1, i + 1, len(trainloader), loss.item()), end=\"\\r\")\n",
    "               \n",
    "        training_loss /= len(trainloader)\n",
    "                \n",
    "        stats = test_loop(valloader, model, criterion)\n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"Acc@20\"].append(stats[3])\n",
    "        results[\"test_loss\"].append(stats[4])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/CNN-LSTM_3.pt\")\n",
    "            highest_performance = stats[0]\n",
    "            \n",
    "        wandb.log({\"test loss\": stats[4],\n",
    "                   \"training loss\": training_loss,\n",
    "                   \"test accuracy\": stats[0] * 100})\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int(done // 60)}:{int(done % 60):02d}\")\n",
    "        \n",
    "        with open(f\"../logs/CNN-LSTM/{datetime.now().strftime('%Y_%d_%m_%H:%M:%S')}.txt\", \"w+\") as f:\n",
    "            f.write(f\"{model}\\n\\nEpoch: {epoch + 1}\\n\\nAcc@1: {stats[0]}\\n\\nDuration: {int(done // 60)}:{int(done % 60):02d}\")\n",
    "        \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "#         plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "#         plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "#         plt.xlabel(\"Epoch\")\n",
    "#         plt.ylabel(\"Average loss\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            career, job = career.to(device), job.to(device)\n",
    "            pred = model(candidate, career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            at20 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "                at20.append(answer.item() in predictions[:20])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            acc20 += np.sum(at20)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    acc20 /= size\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}%, Acc@20: {100*acc20:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c8deba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c4d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 0/36\n",
      "- Initial learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " CNN_LSTM(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=50, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=10, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=15, bias=False)\n",
      "  (address_embedding): Embedding(4768, 25)\n",
      "  (function_embedding): Embedding(2992, 250)\n",
      "  (isco_code_embedding): Embedding(355, 150)\n",
      "  (company_embedding): Embedding(441153, 300)\n",
      "  (education_embedding): Embedding(6, 10)\n",
      "  (isco_level_embedding): Embedding(5, 10)\n",
      "  (conv_padding): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)\n",
      "  (conv32): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv64): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (avgpooling): AvgPool3d(kernel_size=(64, 1, 1), stride=(64, 1, 1), padding=0)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (lstm): LSTM(1221, 1000, batch_first=True)\n",
      "  (fc): Linear(in_features=1000, out_features=355, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1y10q94k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861ef955c274135a45b2d79e2c152c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-vortex-131</strong>: <a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/1y10q94k\" target=\"_blank\">https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/1y10q94k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220608_192110-1y10q94k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1y10q94k). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/Non-explainable/wandb/run-20220608_192252-18fhm7zs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/18fhm7zs\" target=\"_blank\">pleasant-breeze-132</a></strong> to <a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 19:23:03\n",
      "Epoch: 1, batch: 356/356, loss: 2.96665\n",
      "Test Error:\n",
      "Acc@1: 20.88%, Acc@5: 48.35%, Acc@10: 60.92%, Acc@20: 74.09% Avg loss: 3.553981\n",
      "Epoch duration: 6:00\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 19:29:04\n",
      "Epoch: 2, batch: 356/356, loss: 1.55602\n",
      "Test Error:\n",
      "Acc@1: 21.68%, Acc@5: 50.39%, Acc@10: 63.63%, Acc@20: 76.38% Avg loss: 3.512354\n",
      "Epoch duration: 6:00\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 19:35:04\n",
      "Epoch: 3, batch: 356/356, loss: 1.03856\n",
      "Test Error:\n",
      "Acc@1: 22.78%, Acc@5: 51.70%, Acc@10: 65.00%, Acc@20: 77.08% Avg loss: 3.549529\n",
      "Epoch duration: 6:01\n",
      "Current iteration 1/36\n",
      "- Initial learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " CNN_LSTM(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=50, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=10, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=15, bias=False)\n",
      "  (address_embedding): Embedding(4768, 25)\n",
      "  (function_embedding): Embedding(2992, 250)\n",
      "  (isco_code_embedding): Embedding(355, 150)\n",
      "  (company_embedding): Embedding(441153, 300)\n",
      "  (education_embedding): Embedding(6, 10)\n",
      "  (isco_level_embedding): Embedding(5, 10)\n",
      "  (conv_padding): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)\n",
      "  (conv32): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv64): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (avgpooling): AvgPool3d(kernel_size=(64, 1, 1), stride=(64, 1, 1), padding=0)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(1221, 1000, batch_first=True)\n",
      "  (fc): Linear(in_features=1000, out_features=355, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:18fhm7zs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840e332acef741a086978a93b1cb5713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test accuracy</td><td>▁▄█</td></tr><tr><td>test loss</td><td>█▁▇</td></tr><tr><td>training loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test accuracy</td><td>22.77863</td></tr><tr><td>test loss</td><td>3.54953</td></tr><tr><td>training loss</td><td>1.36234</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pleasant-breeze-132</strong>: <a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/18fhm7zs\" target=\"_blank\">https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/18fhm7zs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220608_192252-18fhm7zs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:18fhm7zs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/Non-explainable/wandb/run-20220608_194107-jlaf2vo7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM/runs/jlaf2vo7\" target=\"_blank\">apricot-elevator-133</a></strong> to <a href=\"https://wandb.ai/roanschellingerhout/CNN-LSTM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 19:41:19\n",
      "Epoch: 1, batch: 356/356, loss: 3.31916\n",
      "Test Error:\n",
      "Acc@1: 22.28%, Acc@5: 49.26%, Acc@10: 61.86%, Acc@20: 73.98% Avg loss: 3.562981\n",
      "Epoch duration: 6:02\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 19:47:21\n",
      "Epoch: 2, batch: 68/356, loss: 3.11597\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-2, 1e-3, 1e-4][1:2]\n",
    "hidden_sizes = [1000, 1500]\n",
    "num_layerss = [1]\n",
    "batch_sizes = [128, 256, 512][1:2]\n",
    "kernel_sizes = [1, 2, 4]\n",
    "kernel_sizes2 = [1, 2, 4]\n",
    "F1_sizes = [32, 64, 128][:1]\n",
    "F2_sizes = [64, 128, 256][:1]\n",
    "dropout_probs = [0, 0.25, 0.5][:2]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=300\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            for num_layers in num_layerss:\n",
    "                for hidden_size in hidden_sizes:\n",
    "                    for kernel_size in kernel_sizes:\n",
    "                        for kernel_size2 in kernel_sizes2:\n",
    "                            for F1 in F1_sizes:\n",
    "                                for F2 in F2_sizes:\n",
    "                                    for dropout in dropout_probs:\n",
    "\n",
    "\n",
    "                                        lstm = CNN_LSTM(num_classes=num_classes,\n",
    "                                                        input_size=num_features,\n",
    "                                                        num_layers=num_layers,\n",
    "                                                        hidden_size=hidden_size,\n",
    "                                                        kernel_size=kernel_size,\n",
    "                                                        kernel_size2=kernel_size2,\n",
    "                                                        F1=F1,\n",
    "                                                        F2=F2,\n",
    "                                                        dropout=dropout,\n",
    "                                                        skills=skills, \n",
    "                                                        certs=certs,\n",
    "                                                        licenses=licenses,\n",
    "                                                        languages=languages,\n",
    "                                                        addresses=addresses,\n",
    "                                                        w2v=w2v,\n",
    "                                                        skill_embedding_size=skill_embedding_size,\n",
    "                                                        certs_embedding_size=certs_embedding_size,\n",
    "                                                        license_embedding_size=license_embedding_size,\n",
    "                                                        language_embedding_size=language_embedding_size,\n",
    "                                                        address_embedding_size=address_embedding_size,\n",
    "                                                        function_embedding_size=function_embedding_size,\n",
    "                                                        isco4_embedding_size=isco4_embedding_size,\n",
    "                                                        education_embedding_size=education_embedding_size,\n",
    "                                                        isco_level_embedding_size=isco_level_embedding_size,\n",
    "                                                        company_embedding_size=company_embedding_size,\n",
    "                                                        candidate_lengths=candidate_lens,\n",
    "                                                        max_len=max_len)\n",
    "\n",
    "                                        lstm = lstm.to(device)\n",
    "\n",
    "                                        optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "                                        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "                                        total = len(learning_rates) * len(num_layerss) * len(hidden_sizes) * len(batch_sizes) *\\\n",
    "                                                len(kernel_sizes) * len(kernel_sizes2) * len(F1_sizes) * len(F2_sizes) * len(dropout_probs)\n",
    "\n",
    "                                        print(f\"Current iteration {current}/{total}\")\n",
    "                                        print(f\"- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", lstm, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                                        wandb.init(project=\"CNN-LSTM\", entity=\"roanschellingerhout\", config= {\"learning_rate\": learning_rate,\n",
    "                                                                                                              \"epochs\": 3,\n",
    "                                                                                                              \"batch_size\": batch_size,\n",
    "                                                                                                              \"F1_size\": F1,\n",
    "                                                                                                              \"F2_size\": F2,\n",
    "                                                                                                              \"kernel_size\": kernel_size,\n",
    "                                                                                                              \"kernel_size2\": kernel_size2,\n",
    "                                                                                                              \"hidden_size\": hidden_size,\n",
    "                                                                                                              \"num_layers\":num_layers,\n",
    "                                                                                                              \"dropout\": dropout})\n",
    "\n",
    "                                        trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                                                weight_type=3, batch_size=batch_size)\n",
    "\n",
    "                                        # Store results of current configuration\n",
    "                                        outcome = train_loop(lstm, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                                        outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                                        outcome[\"Batch size\"] = [batch_size] * num_epochs\n",
    "                                        outcome[\"Number of layers\"] = [num_layers] * num_epochs\n",
    "                                        outcome[\"Nodes per layer\"] = [hidden_size] * num_epochs\n",
    "                                        outcome[\"Kernel size\"] = [kernel_size] * num_epochs\n",
    "                                        outcome[\"Kernel size 2\"] = [kernel_size2] * num_epochs\n",
    "                                        outcome[\"F1 size\"] = [F1] * num_epochs\n",
    "                                        outcome[\"F2 size\"] = [F2] * num_epochs\n",
    "                                        outcome[\"Dropout\"] = [dropout] * num_epochs\n",
    "\n",
    "                                        full_results.append(outcome)\n",
    "\n",
    "                                        with open(\"../results/CNN-LSTM.json\", \"w\") as current_stats:\n",
    "                                            json.dump(full_results, current_stats)\n",
    "\n",
    "                                        current += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cc279f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"Batch size\", \"Number of layers\", \"Nodes per layer\", \n",
    "                                               \"Kernel size\", \"F1 size\", \"F2 size\", \"Dropout\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b491bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Acc@1</th>\n",
       "      <th>Acc@5</th>\n",
       "      <th>Acc@10</th>\n",
       "      <th>Acc@20</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>Kernel size 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Nodes per layer</th>\n",
       "      <th>Kernel size</th>\n",
       "      <th>F1 size</th>\n",
       "      <th>F2 size</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">256</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">32</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">64</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00</th>\n",
       "      <th>1</th>\n",
       "      <td>0.208793</td>\n",
       "      <td>0.483491</td>\n",
       "      <td>0.609189</td>\n",
       "      <td>0.740910</td>\n",
       "      <td>3.553981</td>\n",
       "      <td>3.966734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.216751</td>\n",
       "      <td>0.503935</td>\n",
       "      <td>0.636272</td>\n",
       "      <td>0.763772</td>\n",
       "      <td>3.512354</td>\n",
       "      <td>2.061329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.516993</td>\n",
       "      <td>0.649989</td>\n",
       "      <td>0.770763</td>\n",
       "      <td>3.549529</td>\n",
       "      <td>1.362336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.25</th>\n",
       "      <th>1</th>\n",
       "      <td>0.222818</td>\n",
       "      <td>0.492636</td>\n",
       "      <td>0.618641</td>\n",
       "      <td>0.739767</td>\n",
       "      <td>3.562981</td>\n",
       "      <td>4.541784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.201143</td>\n",
       "      <td>0.468587</td>\n",
       "      <td>0.600440</td>\n",
       "      <td>0.732776</td>\n",
       "      <td>3.618069</td>\n",
       "      <td>2.889141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1500</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">32</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">64</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.00</th>\n",
       "      <th>2</th>\n",
       "      <td>0.191954</td>\n",
       "      <td>0.478259</td>\n",
       "      <td>0.622730</td>\n",
       "      <td>0.754495</td>\n",
       "      <td>3.628523</td>\n",
       "      <td>2.205281</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197098</td>\n",
       "      <td>0.488371</td>\n",
       "      <td>0.629457</td>\n",
       "      <td>0.759024</td>\n",
       "      <td>3.673902</td>\n",
       "      <td>1.442868</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.25</th>\n",
       "      <th>1</th>\n",
       "      <td>0.156122</td>\n",
       "      <td>0.429985</td>\n",
       "      <td>0.568213</td>\n",
       "      <td>0.704990</td>\n",
       "      <td>3.823537</td>\n",
       "      <td>4.724857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178061</td>\n",
       "      <td>0.441240</td>\n",
       "      <td>0.579072</td>\n",
       "      <td>0.716509</td>\n",
       "      <td>3.759539</td>\n",
       "      <td>2.970265</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194284</td>\n",
       "      <td>0.459881</td>\n",
       "      <td>0.597450</td>\n",
       "      <td>0.736601</td>\n",
       "      <td>3.747828</td>\n",
       "      <td>2.213553</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                Acc@1  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch             \n",
       "0.001 256        1                1000            1           32      64      0.00    1      0.208793   \n",
       "                                                                                      2      0.216751   \n",
       "                                                                                      3      0.227786   \n",
       "                                                                              0.25    1      0.222818   \n",
       "                                                                                      2      0.201143   \n",
       "...                                                                                               ...   \n",
       "                                  1500            4           32      64      0.00    2      0.191954   \n",
       "                                                                                      3      0.197098   \n",
       "                                                                              0.25    1      0.156122   \n",
       "                                                                                      2      0.178061   \n",
       "                                                                                      3      0.194284   \n",
       "\n",
       "                                                                                                Acc@5  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch             \n",
       "0.001 256        1                1000            1           32      64      0.00    1      0.483491   \n",
       "                                                                                      2      0.503935   \n",
       "                                                                                      3      0.516993   \n",
       "                                                                              0.25    1      0.492636   \n",
       "                                                                                      2      0.468587   \n",
       "...                                                                                               ...   \n",
       "                                  1500            4           32      64      0.00    2      0.478259   \n",
       "                                                                                      3      0.488371   \n",
       "                                                                              0.25    1      0.429985   \n",
       "                                                                                      2      0.441240   \n",
       "                                                                                      3      0.459881   \n",
       "\n",
       "                                                                                               Acc@10  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch             \n",
       "0.001 256        1                1000            1           32      64      0.00    1      0.609189   \n",
       "                                                                                      2      0.636272   \n",
       "                                                                                      3      0.649989   \n",
       "                                                                              0.25    1      0.618641   \n",
       "                                                                                      2      0.600440   \n",
       "...                                                                                               ...   \n",
       "                                  1500            4           32      64      0.00    2      0.622730   \n",
       "                                                                                      3      0.629457   \n",
       "                                                                              0.25    1      0.568213   \n",
       "                                                                                      2      0.579072   \n",
       "                                                                                      3      0.597450   \n",
       "\n",
       "                                                                                               Acc@20  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch             \n",
       "0.001 256        1                1000            1           32      64      0.00    1      0.740910   \n",
       "                                                                                      2      0.763772   \n",
       "                                                                                      3      0.770763   \n",
       "                                                                              0.25    1      0.739767   \n",
       "                                                                                      2      0.732776   \n",
       "...                                                                                               ...   \n",
       "                                  1500            4           32      64      0.00    2      0.754495   \n",
       "                                                                                      3      0.759024   \n",
       "                                                                              0.25    1      0.704990   \n",
       "                                                                                      2      0.716509   \n",
       "                                                                                      3      0.736601   \n",
       "\n",
       "                                                                                             test_loss  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch              \n",
       "0.001 256        1                1000            1           32      64      0.00    1       3.553981   \n",
       "                                                                                      2       3.512354   \n",
       "                                                                                      3       3.549529   \n",
       "                                                                              0.25    1       3.562981   \n",
       "                                                                                      2       3.618069   \n",
       "...                                                                                                ...   \n",
       "                                  1500            4           32      64      0.00    2       3.628523   \n",
       "                                                                                      3       3.673902   \n",
       "                                                                              0.25    1       3.823537   \n",
       "                                                                                      2       3.759539   \n",
       "                                                                                      3       3.747828   \n",
       "\n",
       "                                                                                             training_loss  \\\n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch                  \n",
       "0.001 256        1                1000            1           32      64      0.00    1           3.966734   \n",
       "                                                                                      2           2.061329   \n",
       "                                                                                      3           1.362336   \n",
       "                                                                              0.25    1           4.541784   \n",
       "                                                                                      2           2.889141   \n",
       "...                                                                                                    ...   \n",
       "                                  1500            4           32      64      0.00    2           2.205281   \n",
       "                                                                                      3           1.442868   \n",
       "                                                                              0.25    1           4.724857   \n",
       "                                                                                      2           2.970265   \n",
       "                                                                                      3           2.213553   \n",
       "\n",
       "                                                                                             Kernel size 2  \n",
       "lr    Batch size Number of layers Nodes per layer Kernel size F1 size F2 size Dropout Epoch                 \n",
       "0.001 256        1                1000            1           32      64      0.00    1                  1  \n",
       "                                                                                      2                  1  \n",
       "                                                                                      3                  1  \n",
       "                                                                              0.25    1                  1  \n",
       "                                                                                      2                  1  \n",
       "...                                                                                                    ...  \n",
       "                                  1500            4           32      64      0.00    2                  4  \n",
       "                                                                                      3                  4  \n",
       "                                                                              0.25    1                  4  \n",
       "                                                                                      2                  4  \n",
       "                                                                                      3                  4  \n",
       "\n",
       "[108 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5172f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv(\"../results/CNN-LSTM-results_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e30dd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.4140625\n",
      "Previous-job baseline accuracy: 0.0\n",
      "Fraction of previous job predictions: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        career, job = career.to(device), job.to(device)\n",
    "        pred = lstm(candidate, career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        previous_job = torch.Tensor(career_paths.loc[candidate.cpu()].apply(lambda x: x[-2][-1]).values).to(device)\n",
    "        print(\"Previous-job baseline accuracy:\", (job == previous_job).cpu().numpy().mean())\n",
    "        print(\"Fraction of previous job predictions:\", (pred.argmax(1) == previous_job).cpu().numpy().mean())\n",
    "                \n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        \n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7aea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
