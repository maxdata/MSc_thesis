{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974b7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/jacobgil/pytorch-grad-cam.git \"pillow<7\" ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6332f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.10.1)\n",
      "Collecting torch\n",
      "  Using cached torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: grad-cam in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.3.9)\n",
      "Requirement already satisfied: wandb in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.12.17)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (1.19.5)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (8.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (4.61.1)\n",
      "Requirement already satisfied: ttach in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (0.0.3)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (4.5.1.48)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grad-cam) (0.11.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.5.12)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (8.0.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: setproctitle in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (3.17.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: pathtools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade grad-cam wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824b64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/utils\")\n",
    "path.append(\"/home/ec2-user/SageMaker/data-science-development/config\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe0881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mroanschellingerhout\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ff3566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_1</th>\n",
       "      <th>skill_2</th>\n",
       "      <th>skill_3</th>\n",
       "      <th>skill_5</th>\n",
       "      <th>skill_6</th>\n",
       "      <th>skill_7</th>\n",
       "      <th>skill_8</th>\n",
       "      <th>skill_9</th>\n",
       "      <th>skill_12</th>\n",
       "      <th>skill_13</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_3926</th>\n",
       "      <th>skill_3927</th>\n",
       "      <th>skill_3928</th>\n",
       "      <th>skill_3929</th>\n",
       "      <th>skill_3930</th>\n",
       "      <th>skill_3931</th>\n",
       "      <th>skill_3932</th>\n",
       "      <th>skill_3933</th>\n",
       "      <th>skill_3934</th>\n",
       "      <th>skill_3935</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_1  skill_2  skill_3  skill_5  skill_6  skill_7  skill_8  \\\n",
       "candidate_id                                                                  \n",
       "84267               0        0        0        0        0        0        0   \n",
       "84349               1        0        0        0        0        0        0   \n",
       "84381               0        0        0        0        0        0        0   \n",
       "84386               0        0        0        0        0        0        0   \n",
       "84432               0        0        0        0        0        0        0   \n",
       "\n",
       "              skill_9  skill_12  skill_13  ...  skill_3926  skill_3927  \\\n",
       "candidate_id                               ...                           \n",
       "84267               0         0         0  ...           0           0   \n",
       "84349               0         0         0  ...           0           0   \n",
       "84381               0         0         0  ...           0           0   \n",
       "84386               0         0         0  ...           0           0   \n",
       "84432               0         0         0  ...           0           0   \n",
       "\n",
       "              skill_3928  skill_3929  skill_3930  skill_3931  skill_3932  \\\n",
       "candidate_id                                                               \n",
       "84267                  0           0           0           0           0   \n",
       "84349                  0           0           0           0           0   \n",
       "84381                  0           0           0           0           0   \n",
       "84386                  0           0           0           0           0   \n",
       "84432                  0           0           0           0           0   \n",
       "\n",
       "              skill_3933  skill_3934  skill_3935  \n",
       "candidate_id                                      \n",
       "84267                  0           0           0  \n",
       "84349                  0           0           0  \n",
       "84381                  0           0           0  \n",
       "84386                  0           0           0  \n",
       "84432                  0           0           0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = pd.read_csv(\"../Data/skills_one-hot.csv\").set_index(\"candidate_id\")\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc7c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(zip(skills.index, skills.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718c3ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W7</th>\n",
       "      <th>W9</th>\n",
       "      <th>WB</th>\n",
       "      <th>WC</th>\n",
       "      <th>WD</th>\n",
       "      <th>WE</th>\n",
       "      <th>WF</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1  10  11  12  13  14  15  16  17  18  ...  W4  W5  W7  W9  WB  \\\n",
       "candidate_id                                         ...                       \n",
       "84603         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "84867         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85035         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85102         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "85214         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "              WC  WD  WE  WF  ZW  \n",
       "candidate_id                      \n",
       "84603          0   0   0   0   0  \n",
       "84867          0   0   0   0   0  \n",
       "85035          0   0   0   0   0  \n",
       "85102          0   0   0   0   0  \n",
       "85214          0   0   0   0   0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certs = pd.read_csv(\"../Data/candidate_certificates_one-hot.csv\").set_index(\"candidate_id\")\n",
    "certs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c9d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "certs = dict(zip(certs.index, certs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3533aff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BE</th>\n",
       "      <th>C</th>\n",
       "      <th>CE</th>\n",
       "      <th>D</th>\n",
       "      <th>DE</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A  B  BE  C  CE  D  DE  G\n",
       "candidate_id                           \n",
       "84556         0  1   0  0   0  0   0  0\n",
       "84612         0  0   0  0   0  0   0  1\n",
       "84731         1  1   0  0   0  0   0  0\n",
       "85437         0  1   0  0   0  0   0  0\n",
       "85627         0  1   1  0   0  0   0  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licenses = pd.read_csv(\"../Data/licenses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "licenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d4f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "licenses = dict(zip(licenses.index, licenses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467824a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3  4  5  6  7  8  9  ...  13  14  15  16  17  18  19  \\\n",
       "candidate_id                                ...                               \n",
       "84267         0  0  1  1  1  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84349         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "84381         0  0  0  1  0  0  0  0  0  1  ...   0   0   0   0   0   0   0   \n",
       "84386         0  0  1  1  0  0  1  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "84432         0  0  0  1  0  0  1  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "              20  21  22  \n",
       "candidate_id              \n",
       "84267          0   0   0  \n",
       "84349          0   0   0  \n",
       "84381          0   0   0  \n",
       "84386          0   0   0  \n",
       "84432          0   0   0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = pd.read_csv(\"../Data/languages_one-hot.csv\").set_index(\"candidate_id\")\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b70b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = dict(zip(languages.index, languages.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46d3657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84556</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84612</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84731</th>\n",
       "      <td>3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85627</th>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "candidate_id      \n",
       "84556           91\n",
       "84612           49\n",
       "84731         3773\n",
       "85437         3819\n",
       "85627         1560"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_csv(\"../Data/addresses_one-hot.csv\").set_index(\"candidate_id\")\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d67705",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = dict(zip(addresses.index, addresses.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be62d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = json.load(open(\"../Data/embeddings.json\"))\n",
    "# Convert to ints\n",
    "w2v = {int(k):{int(k2):v2 for k2, v2 in v.items()} for k, v in w2v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd4e841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../Data/df_pred_ext.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39425276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.drop([\"time_between\", \"job_order\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d746a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"time_between\"] = (df_pred[\"time_between\"] - df_pred[\"time_between\"].mean()) / df_pred[\"time_between\"].std()\n",
    "df_pred[\"time_spent\"] = (df_pred[\"time_spent\"] - df_pred[\"time_spent\"].mean()) / df_pred[\"time_spent\"].std()\n",
    "df_pred[\"c\"] = df_pred[\"candidate_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33537e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAD-cam requires a single input into forward(), so we need to include candidate in there as well\n",
    "df_pred = df_pred[[\"candidate_id\", \"c\", \"time_spent\", \"isco_functie_niveau\", \"education\", \"company_name\", \"function_id\", \"isco_code4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "801e6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>c</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>isco_functie_niveau</th>\n",
       "      <th>education</th>\n",
       "      <th>company_name</th>\n",
       "      <th>function_id</th>\n",
       "      <th>isco_code4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.252626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324258</td>\n",
       "      <td>809</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329244</td>\n",
       "      <td>936</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.370694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368140</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84556</td>\n",
       "      <td>84556</td>\n",
       "      <td>-0.363314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419826</td>\n",
       "      <td>1519</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate_id      c  time_spent  isco_functie_niveau  education  \\\n",
       "0         84556  84556   -0.210459                  2.0        0.0   \n",
       "1         84556  84556   -0.252626                  1.0        0.0   \n",
       "2         84556  84556   -0.085012                  2.0        0.0   \n",
       "3         84556  84556   -0.370694                  1.0        0.0   \n",
       "4         84556  84556   -0.363314                  1.0        0.0   \n",
       "\n",
       "   company_name  function_id  isco_code4  \n",
       "0        324258          936         208  \n",
       "1        324258          809         348  \n",
       "2        329244          936         208  \n",
       "3        368140         1519         344  \n",
       "4        419826         1519         344  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2804718",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df_pred[\"isco_code4\"].mode().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b07a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_pred.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8d32c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = df_pred.groupby(\"candidate_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b12dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_lens = career_paths.apply(lambda x: len(x) - 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a70e0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df_pred[\"isco_code4\"].unique())\n",
    "num_features = len(career_paths.mean().columns)\n",
    "num_classes, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a949f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_career_duration = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e2141f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469568/469568 [00:48<00:00, 9611.89it/s] \n"
     ]
    }
   ],
   "source": [
    "# Convert to 2d-arrays, grabbing the last 25 jobs of each candidate and getting rid of candidate_ids as values\n",
    "career_paths = career_paths.progress_apply(lambda x: x.values[-(maximum_career_duration + 1):,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b59cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop careers that are only 1 job long\n",
    "career_lens = career_paths.apply(len)\n",
    "career_paths = career_paths.loc[(career_lens > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f027587",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths = career_paths.loc[career_paths.apply(lambda x: x[-1][-1] != x[-2][-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1c4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id\n",
       "84556    [[84556.0, -0.21045870102048395, 2.0, 0.0, 324...\n",
       "84612    [[84612.0, -0.3685852264755267, 1.0, 0.0, 2017...\n",
       "84731    [[84731.0, -0.35066422025728855, 1.0, 0.0, 353...\n",
       "85437    [[85437.0, 0.3313881928721292, 1.0, 2.0, 5500....\n",
       "85888    [[85888.0, -0.2895219637480053, 2.0, 3.0, 4233...\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98aaf47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# max_skills = len([col for col in df_pred if \"skill_\" in col])\n",
    "\n",
    "for idx, career in zip(career_paths.index, career_paths.values):\n",
    "    label = career[-1, -1]\n",
    "    \n",
    "    if not np.isnan(label):       \n",
    "        idxs.append(idx)\n",
    "        x.append(career[:-1].reshape(len(career) - 1, num_features))\n",
    "        y.append(label)\n",
    "\n",
    "idxs = np.array(idxs)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e7487cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fill = np.zeros([len(x), len(max(x, key = lambda x: len(x))), num_features])\n",
    "\n",
    "for i,j in enumerate(x):\n",
    "    if len(j):\n",
    "        to_fill[i][-len(j):] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ded87d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(x, key = lambda x: len(x)))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89d1bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_pred\n",
    "del x\n",
    "del career_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f165b689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "865a4067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113724, 113724)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_fill), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3b57297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fill = to_fill[:25000]\n",
    "# y = y[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae841359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(to_fill, idxs, y, split_size=0.8, weight_type=3, batch_size=512):\n",
    "\n",
    "    # Train test split\n",
    "    split = split_size\n",
    "\n",
    "    training = np.array(random.sample(range(len(to_fill)), int(split * len(to_fill))))\n",
    "    test = np.array(list(set(range(len(to_fill))) - set(training)))\n",
    "\n",
    "    train_indices, val_indices = idxs[training], idxs[test]\n",
    "    X_train, X_val = to_fill[training], to_fill[test]\n",
    "    y_train, y_val = y[training].astype(int), y[test].astype(int)\n",
    "\n",
    "    # Class weights\n",
    "    counts = (np.bincount(y_train) + 1)\n",
    "    \n",
    "    if weight_type == 1:\n",
    "        labels_weights = 1. / counts\n",
    "    elif weight_type == 2:\n",
    "        labels_weights = 1. / np.sqrt(counts)\n",
    "    elif weight_type == 3:\n",
    "        labels_weights = 2. / (0.5 * np.sqrt(counts))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    weights = labels_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data = TensorDataset(torch.Tensor(train_indices), \n",
    "                               torch.Tensor(X_train), \n",
    "                               torch.Tensor(y_train).type(torch.LongTensor))\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    val_data = TensorDataset(torch.Tensor(val_indices),\n",
    "                             torch.Tensor(X_val),\n",
    "                             torch.Tensor(y_val).type(torch.LongTensor))\n",
    "\n",
    "    valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d7a0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XCM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, skills, certs, licenses, \n",
    "                 languages, addresses, w2v, candidate_lengths, max_len, \n",
    "                 F1=64, F2=16, window_size=0.2, skill_embedding_size=50, \n",
    "                 certs_embedding_size=20, license_embedding_size=3, \n",
    "                 language_embedding_size=10, address_embedding_size=25, \n",
    "                 function_embedding_size=50, isco4_embedding_size=25, \n",
    "                 education_embedding_size=3, isco_level_embedding_size=3, \n",
    "                 company_embedding_size=50, w2v_embedding_size=300):\n",
    "        \n",
    "        super(XCM, self).__init__()\n",
    "              \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size + w2v_embedding_size\n",
    "        \n",
    "        # Static embeddings: skills, certificates, licenses, languages\n",
    "        self.skill_embedding = nn.Linear(317, skill_embedding_size, bias=False)\n",
    "        self.skill_embedding.weight.data = torch.randn_like(self.skill_embedding.weight) \n",
    "        self.skill_embedding_size = skill_embedding_size\n",
    "        \n",
    "        self.certs_embedding = nn.Linear(98, certs_embedding_size, bias=False)\n",
    "        self.certs_embedding.weight.data = torch.randn_like(self.certs_embedding.weight) \n",
    "        self.certs_embedding_size = certs_embedding_size\n",
    "        \n",
    "        self.license_embedding = nn.Linear(8, license_embedding_size, bias=False)\n",
    "        self.license_embedding.weight.data = torch.randn_like(self.license_embedding.weight) \n",
    "        self.license_embedding_size = license_embedding_size\n",
    "        \n",
    "        self.language_embedding = nn.Linear(23, language_embedding_size, bias=False)\n",
    "        self.language_embedding.weight.data = torch.randn_like(self.language_embedding.weight) \n",
    "        self.language_embedding_size = language_embedding_size \n",
    "        \n",
    "        self.w2v_embedding = nn.Linear(300, w2v_embedding_size, bias=False)\n",
    "        self.w2v_embedding.weight.data = torch.randn_like(self.w2v_embedding.weight) \n",
    "        self.w2v_embedding_size = w2v_embedding_size\n",
    "        \n",
    "        # Address embedding\n",
    "        self.address_embedding = nn.Embedding(4768, address_embedding_size)       \n",
    "        self.address_embedding_size = address_embedding_size\n",
    "        \n",
    "        # Categorical feature embeddings\n",
    "        self.function_embedding = nn.Embedding(2992, function_embedding_size)\n",
    "        self.isco_code_embedding = nn.Embedding(num_classes, isco4_embedding_size)\n",
    "        self.company_embedding = nn.Embedding(441153, company_embedding_size)\n",
    "        self.education_embedding = nn.Embedding(6, education_embedding_size)\n",
    "        self.isco_level_embedding = nn.Embedding(5, isco_level_embedding_size)\n",
    "        \n",
    "        self.function_embedding_size = function_embedding_size\n",
    "        self.isco_code_embedding_size = isco4_embedding_size\n",
    "        self.company_embedding_size = company_embedding_size\n",
    "        self.education_embedding_size = education_embedding_size\n",
    "        self.isco_level_embedding_size = isco_level_embedding_size\n",
    "                \n",
    "        # -6 --> embedded features get replaced\n",
    "        N = self.input_size - 6 + skill_embedding_size + certs_embedding_size + \\\n",
    "            license_embedding_size + language_embedding_size + address_embedding_size + \\\n",
    "            function_embedding_size + isco4_embedding_size + company_embedding_size + \\\n",
    "            education_embedding_size + isco_level_embedding_size\n",
    "        \n",
    "        # Actual model\n",
    "        window_size = int(max_len * window_size)\n",
    "        D = N\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(F1)  \n",
    "        self.batchnorm2 = nn.BatchNorm2d(F2)\n",
    "        self.conv2d = nn.Conv2d(in_channels=1,\n",
    "                                out_channels=F1,\n",
    "                                kernel_size=(window_size, 1),\n",
    "                                stride=(1, 1),\n",
    "                                padding=\"same\")\n",
    "        \n",
    "        self._1x1 = nn.Conv2d(in_channels=F1, \n",
    "                              out_channels=1, \n",
    "                              kernel_size=(1, 1), # Maybe (100, 1, 1)?\n",
    "                              stride=1)\n",
    "\n",
    "        # Asymmetric padding to have a consistent shape for even and uneven window_sizes\n",
    "        self.conv1d_padding = nn.ZeroPad2d((0, 0, window_size // 2, (window_size - 1 ) // 2))\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=1,\n",
    "                                out_channels=F1, \n",
    "                                kernel_size=(window_size, D),\n",
    "                                stride=1)\n",
    "                \n",
    "        self._1x1_2 = nn.Conv1d(in_channels=F1, \n",
    "                                out_channels=1, \n",
    "                                kernel_size=(1, 1),\n",
    "                                stride=1)\n",
    "            \n",
    "        self.final_conv1d = nn.Conv1d(in_channels=1,\n",
    "                                      out_channels=F2, \n",
    "                                      kernel_size=(window_size, D + 1),\n",
    "                                      stride=1,\n",
    "                                      padding=\"same\")\n",
    "        \n",
    "        self.avgpool2d = nn.AvgPool3d(kernel_size=(F2, 1, 1),\n",
    "                                      stride=1)\n",
    "        \n",
    "        self.fc = nn.Linear(max_len * (D + 1), num_classes)\n",
    "                    \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Skill lookup\n",
    "        self.skills = skills\n",
    "        \n",
    "        # Certificate lookup\n",
    "        self.certs = certs\n",
    "        \n",
    "        # License lookup\n",
    "        self.licenses = licenses\n",
    "        \n",
    "        # Language lookup\n",
    "        self.langs = languages\n",
    "        \n",
    "        # Address lookup\n",
    "        self.adds = addresses\n",
    "        \n",
    "        # w2v lookup\n",
    "        self.w2v_keys = set(w2v.keys())\n",
    "        self.w2v = w2v\n",
    "        \n",
    "        # Career durations\n",
    "        self.candidate_lengths = candidate_lengths\n",
    "        self.max_len = max_len      \n",
    "        \n",
    "        def get_from_dict(x, cdict, N):\n",
    "            return cdict.get(x, np.zeros((N,)))\n",
    "\n",
    "        self.retrieve_static = np.vectorize(get_from_dict, otypes=[np.ndarray])   \n",
    "                \n",
    "    \n",
    "    def w2v_lookup(self, candidate, career_duration):\n",
    "        \"\"\"Finds a candidate's CVs and converts them to a tensor of length career_duration\"\"\"\n",
    "            \n",
    "        actual_career_duration = career_duration\n",
    "        career_duration = min(career_duration, max_len)\n",
    "            \n",
    "        # Look for cvs\n",
    "        if candidate.item() in self.w2v_keys:\n",
    "            cvs = self.w2v[candidate.item()]\n",
    "                \n",
    "            storage = []\n",
    "\n",
    "             # If a candidate only has one CV, proceed as normal\n",
    "            if len(cvs.keys()) == 1:\n",
    "                w2v_list = self.w2v_embedding(torch.Tensor(cvs[0]).to(device))\n",
    "                w2v_list = torch.stack([w2v_list] * career_duration).to(device)\n",
    "            else: # Otherwise, stack them accordingly\n",
    "                ks = np.array(list(cvs.keys()))\n",
    "                \n",
    "                to_skip = 0\n",
    "                                \n",
    "                # Make sure to use candidates' most recent max_len cvs\n",
    "                if actual_career_duration > self.max_len:                                        \n",
    "                    # Update to only include most recent max_len\n",
    "                    ks -= max_len\n",
    "                    \n",
    "                    # Drop everything older than max_len time steps\n",
    "                    ks_2 = np.array([ks[i] for i in range(len(ks)) if i < len(ks) and (i + 1 >= len(ks) or ks[i + 1] > 0)])\n",
    "                    \n",
    "                    # Store how many we need to skip while indexing\n",
    "                    to_skip = len(ks) - len(ks_2)\n",
    "                    \n",
    "                    # Update ks\n",
    "                    ks = ks_2\n",
    "                    ks[0] = 0\n",
    "                    \n",
    "                # Due to clipping, some careers are longer than max_len\n",
    "                ks = np.array([k for k in ks if k <= min(self.max_len, career_duration)])\n",
    "\n",
    "                # Find how many time steps (rows) each CV lasted\n",
    "                durations = [ks[i+1] - ks[i]\n",
    "                             if i < (len(ks) - 1) \n",
    "                             else career_duration - ks[i]\n",
    "                             for i in range(len(ks))]\n",
    "\n",
    "                embed_values = list(cvs.values())\n",
    "\n",
    "                # When the CV got updated on the last timestep, aka our test value\n",
    "                # Remove it from the list of durations, as it should be ignored\n",
    "                if durations[-1] == 0: \n",
    "                    durations.pop()\n",
    "\n",
    "                # Create Tensor(s)\n",
    "                if durations:\n",
    "                    for i, duration in enumerate(durations):\n",
    "                        # Figure out negative duration cause\n",
    "                        storage.append(torch.stack([self.w2v_embedding(torch.Tensor(embed_values[i + to_skip]).to(device))] * duration, dim=0))\n",
    "                else:\n",
    "                    storage.append(self.w2v_embedding(torch.Tensor(cvs[0])))\n",
    "\n",
    "                # Combine stored tensors into a single tensor\n",
    "                w2v_list = torch.cat((storage)).type(torch.LongTensor).to(device)\n",
    "        else:\n",
    "            w2v_list = torch.LongTensor([0] * self.w2v_embedding_size).to(device)\n",
    "            w2v_list = torch.stack([w2v_list] * career_duration)\n",
    "\n",
    "        return w2v_list\n",
    "    \n",
    "    def create_tensor(self, x):\n",
    "        # Default width of a row (filled with 0s)\n",
    "        feature_width = torch.Tensor([0] * (self.skill_embedding_size + self.certs_embedding_size\n",
    "                                            + self.license_embedding_size + self.language_embedding_size\n",
    "                                            + self.address_embedding_size + self.w2v_embedding_size)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        candidate_features = []\n",
    "        \n",
    "        # Extract candidate_ids\n",
    "        candidate = x[:,:,0][:,-1].cpu()\n",
    "        \n",
    "        # Everything else stays in x\n",
    "        x = x[:,:,1:]\n",
    "        \n",
    "        skill_list = self.retrieve_static(candidate, self.skills, 317)\n",
    "        skill_list = torch.LongTensor(np.stack(skill_list)).to(device)\n",
    "        \n",
    "        certs_list = self.retrieve_static(candidate, self.certs, 98)\n",
    "        certs_list = torch.LongTensor(np.stack(certs_list)).to(device)\n",
    "        \n",
    "        license_list = self.retrieve_static(candidate, self.licenses, 8)\n",
    "        license_list = torch.LongTensor(np.stack(license_list)).to(device)\n",
    "        \n",
    "        langs_list = self.retrieve_static(candidate, self.langs, 23)\n",
    "        langs_list = torch.LongTensor(np.stack(langs_list)).to(device)\n",
    "            \n",
    "        address = self.retrieve_static(candidate, self.adds, 1)\n",
    "        address = torch.LongTensor(np.stack(address)).to(device)\n",
    "        \n",
    "        # Embed every static feature\n",
    "        skill_list, certs_list, license_list, langs_list = [self.skill_embedding(skill_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.certs_embedding(certs_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.license_embedding(license_list.type(torch.FloatTensor).to(device)),\n",
    "                                                            self.language_embedding(langs_list.type(torch.FloatTensor).to(device))]\n",
    "                \n",
    "        # Combine and embed\n",
    "        batch_features = torch.cat([skill_list, certs_list, \n",
    "                                    license_list, langs_list], dim=-1).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        batch_addresses = self.address_embedding(address)[:,0,:]\n",
    "        \n",
    "        durations = []\n",
    "        \n",
    "        # For each candidate in the current batch\n",
    "        for i, c in enumerate(candidate):\n",
    "            # Get career duration\n",
    "            career_duration = self.candidate_lengths[c.item()]\n",
    "            \n",
    "            # Get CV embeddings\n",
    "            w2v_list = self.w2v_lookup(c, career_duration)\n",
    "                                    \n",
    "            # Reset to max_len\n",
    "            career_duration = min(career_duration, max_len)\n",
    "            durations.append(career_duration)\n",
    "\n",
    "            # Only create zeros if needed (e.g. less than max_len career duration)\n",
    "            if (self.max_len - career_duration) > 0:\n",
    "                zeros = torch.stack([feature_width] * (self.max_len - career_duration))                \n",
    "            else: # Reset zeros to prevent shape mismatch\n",
    "                zeros = torch.LongTensor([]).to(device)\n",
    "                        \n",
    "            # Broadcast and add static features\n",
    "            static_features = torch.stack([batch_features[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            address_emb = torch.stack([batch_addresses[i]] * career_duration).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            # Combine w2v, static features, and address\n",
    "            full_features = torch.cat([w2v_list, static_features, address_emb], dim=1)\n",
    "                                    \n",
    "            # Broadcast CV, static, and address to the correct length\n",
    "            full_features = torch.cat([zeros, full_features], dim=0)\n",
    "                    \n",
    "            # Store result\n",
    "            candidate_features.append(full_features)\n",
    "                                \n",
    "         # Convert list of tensors to actual tensor\n",
    "        additional_features = torch.stack((candidate_features)).type(torch.FloatTensor).to(device)\n",
    "                \n",
    "        # isco_functie_niveau, education, function_id, isco_code4\n",
    "        isco_level, education, company_name, function_id, isco_code = [x[:,:,-5],\n",
    "                                                                       x[:,:,-4],\n",
    "                                                                       x[:,:,-3],\n",
    "                                                                       x[:,:,-2],\n",
    "                                                                       x[:,:,-1]]\n",
    "        \n",
    "        x = x[:,:,:-5].to(device)\n",
    "        \n",
    "        isco_level_smoothing = (isco_level != 0).unsqueeze(-1)\n",
    "        education_smoothing = (education != 0).unsqueeze(-1)\n",
    "        company_name_smoothing = (company_name != 0).unsqueeze(-1)\n",
    "        function_id_smoothing = (function_id != 0).unsqueeze(-1)\n",
    "        isco_code_smoothing = (isco_code != 0).unsqueeze(-1)\n",
    "        \n",
    "        isco_level, education, company_name, function_id, isco_code  = [self.isco_level_embedding(isco_level.type(torch.LongTensor).to(device)) * isco_level_smoothing,\n",
    "                                                                        self.education_embedding(education.type(torch.LongTensor).to(device)) * education_smoothing,\n",
    "                                                                        self.company_embedding(company_name.type(torch.LongTensor).to(device)) * company_name_smoothing,\n",
    "                                                                        self.function_embedding(function_id.type(torch.LongTensor).to(device)) * function_id_smoothing,\n",
    "                                                                        self.isco_code_embedding(isco_code.type(torch.LongTensor).to(device)) * isco_code_smoothing]   \n",
    "                \n",
    "        # Add features\n",
    "        x = torch.cat([x, isco_level, education, company_name, function_id, isco_code, additional_features], dim=2)     \n",
    "                                    \n",
    "        return x, durations\n",
    " \n",
    "    def forward(self, x):                       \n",
    "        # Reshape to allow conv2D\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = x.transpose(1, 3)\n",
    "        x = x.transpose(2, 3)\n",
    "                \n",
    "        # Top part:\n",
    "        x1 = self.conv2d(x)\n",
    "        x1 = self.batchnorm(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x1 = self._1x1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        # x1 = self.dropout(x1)\n",
    "\n",
    "        # Bottom part: \n",
    "        x = self.conv1d_padding(x)\n",
    "        x2 = self.conv1d(x)\n",
    "        x2 = self.batchnorm(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        x2 = self._1x1_2(x2)\n",
    "        x2 = self.relu2(x2)\n",
    "        # x2 = self.dropout(x2)\n",
    "        \n",
    "        # Concatenate                \n",
    "        x = torch.cat([x1, x2], dim=-1)\n",
    "                \n",
    "        # Conv 1D\n",
    "        x = self.final_conv1d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "                                \n",
    "        # Global average pooling\n",
    "        x = self.avgpool2d(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "                    \n",
    "        x = self.fc(x)\n",
    "                \n",
    "        # softmax\n",
    "        out = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bed3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, trainloader, valloader, optimizer, scheduler, criterion, num_epochs):\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    passed = [0]\n",
    "    training_losses = [6]\n",
    "    test_losses = [6]\n",
    "    accuracy = [0]\n",
    "    \n",
    "    highest_performance = 0\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch starting at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        training_loss = 0\n",
    "        train_acc1 = 0\n",
    "        \n",
    "        for i, (candidate, career, job) in enumerate(trainloader):\n",
    "            batch_start = time.time()\n",
    "            \n",
    "            candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            career, _ = model.create_tensor(career)\n",
    "            outputs = model(career)\n",
    "            \n",
    "            train_acc1 += (outputs.argmax(1) == job).type(torch.float).sum().item()\n",
    "                                    \n",
    "            # obtain the loss function\n",
    "            loss = criterion(outputs, job)\n",
    "            loss = loss.mean()       \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            batch_end = time.time()\n",
    "            batch_duration = batch_end - batch_start\n",
    "            epoch_duration = int(batch_duration * (len(trainloader) - i))\n",
    "            print(\"Epoch: %d, batch: %d/%d, loss: %1.5f, Epoch ETA: %02d:%02d  \" % (epoch + 1,\n",
    "                                                                                i + 1,\n",
    "                                                                                len(trainloader), \n",
    "                                                                                loss.item(),\n",
    "                                                                                epoch_duration // 60,\n",
    "                                                                                (epoch_duration % 60)), end=\"\\r\")\n",
    "               \n",
    "        training_loss /= len(trainloader)\n",
    "        train_acc1 /= len(trainloader.dataset)\n",
    "                \n",
    "        stats = test_loop(valloader, model, criterion)\n",
    "        \n",
    "        done = int(time.time() - start)        \n",
    "        print(f\"Epoch duration: {int((done) // 60)}:{int((done) % 60):02d}\")\n",
    "        \n",
    "        with open(f\"../logs/eCNN/{datetime.now().strftime('%Y_%d_%m_%H:%M:%S')}.txt\", \"w+\") as f:\n",
    "            f.write(f\"{model}\\n\\nEpoch: {epoch + 1}\\n\\nAcc@1: {stats[0]}\\n\\nDuration: {int(done // 60)}:{int(done % 60):02d}\")\n",
    "        \n",
    "        results[\"Epoch\"].append(epoch + 1)\n",
    "        results[\"Acc@1\"].append(stats[0])\n",
    "        results[\"Acc@5\"].append(stats[1])\n",
    "        results[\"Acc@10\"].append(stats[2])\n",
    "        results[\"Acc@20\"].append(stats[3])\n",
    "        results[\"test_loss\"].append(stats[4])\n",
    "        results[\"training_loss\"].append(training_loss)\n",
    "        results[\"duration\"].append(done)\n",
    "        \n",
    "        wandb.log({\"test loss\": stats[4],\n",
    "                   \"training loss\": training_loss,\n",
    "                   \"test accuracy\": stats[0] * 100,\n",
    "                   \"training accuracy\": train_acc1 * 100})\n",
    "        \n",
    "        if stats[0] > highest_performance:\n",
    "            torch.save(model.state_dict(), \"../models/eCNN_1.pt\")\n",
    "            highest_performance = stats[0]\n",
    "        \n",
    "\n",
    "        scheduler.step()\n",
    "                \n",
    "        passed.append(epoch + 1)\n",
    "        training_losses.append(training_loss)\n",
    "        test_losses.append(stats[4])\n",
    "        accuracy.append(stats[0])\n",
    "        \n",
    "        plt.plot(passed, training_losses, label=\"Training Loss\")\n",
    "        plt.plot(passed, test_losses, label=\"Test Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Average loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "                \n",
    "    return results\n",
    "        \n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, acc1, acc5, acc10, acc20 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for candidate, career, job in dataloader:\n",
    "            candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "            \n",
    "            career, _ = model.create_tensor(career)\n",
    "            pred = model(career)\n",
    "            \n",
    "            test_loss += criterion(pred, job).mean().item()\n",
    "            acc1 += (pred.argmax(1) == job).type(torch.float).sum().item()\n",
    "            \n",
    "            sorted_preds = torch.argsort(pred, 1, descending=True)\n",
    "            \n",
    "            at5 = []\n",
    "            at10 = []\n",
    "            at20 = []\n",
    "            \n",
    "            for answer, predictions in zip(job, sorted_preds):\n",
    "                at5.append(answer.item() in predictions[:5])\n",
    "                at10.append(answer.item() in predictions[:10])\n",
    "                at20.append(answer.item() in predictions[:20])\n",
    "            \n",
    "            acc5 += np.sum(at5)\n",
    "            acc10 += np.sum(at10)\n",
    "            acc20 += np.sum(at20)\n",
    "                    \n",
    "    # print(\"\\nValidation:\", Counter(np.array(pred.argmax(1).cpu())))\n",
    "    test_loss /= num_batches\n",
    "    acc1 /= size\n",
    "    acc5 /= size\n",
    "    acc10 /= size\n",
    "    acc20 /= size\n",
    "    print(f\"\\nTest Error:\")\n",
    "    print(f\"Acc@1: {(100*acc1):>0.2f}%, Acc@5: {100*acc5:>0.2f}%, \" +\\\n",
    "          f\"Acc@10: {100*acc10:>0.2f}%, Acc@20: {100*acc20:>0.2f}% Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    return acc1, acc5, acc10, acc20, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2841122",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5cd3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bf4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 0/1\n",
      "- Initial learning rate: 0.001\n",
      "- Model: \n",
      "\n",
      " XCM(\n",
      "  (skill_embedding): Linear(in_features=317, out_features=100, bias=False)\n",
      "  (certs_embedding): Linear(in_features=98, out_features=20, bias=False)\n",
      "  (license_embedding): Linear(in_features=8, out_features=3, bias=False)\n",
      "  (language_embedding): Linear(in_features=23, out_features=10, bias=False)\n",
      "  (w2v_embedding): Linear(in_features=300, out_features=300, bias=False)\n",
      "  (address_embedding): Embedding(4768, 25)\n",
      "  (function_embedding): Embedding(2992, 250)\n",
      "  (isco_code_embedding): Embedding(355, 150)\n",
      "  (company_embedding): Embedding(441153, 250)\n",
      "  (education_embedding): Embedding(6, 3)\n",
      "  (isco_level_embedding): Embedding(5, 3)\n",
      "  (relu): ReLU()\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (batchnorm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2d): Conv2d(1, 8, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "  (_1x1): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1d_padding): ZeroPad2d(padding=(0, 0, 2, 2), value=0.0)\n",
      "  (conv1d): Conv1d(1, 8, kernel_size=(5, 1115), stride=(1,))\n",
      "  (_1x1_2): Conv1d(8, 1, kernel_size=(1, 1), stride=(1,))\n",
      "  (final_conv1d): Conv1d(1, 32, kernel_size=(5, 1116), stride=(1,), padding=same)\n",
      "  (avgpool2d): AvgPool3d(kernel_size=(32, 1, 1), stride=1, padding=0)\n",
      "  (fc): Linear(in_features=27900, out_features=355, bias=True)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/Explainable/wandb/run-20220607_134845-1bilc818</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/roanschellingerhout/CNN/runs/1bilc818\" target=\"_blank\">mild-cosmos-72</a></strong> to <a href=\"https://wandb.ai/roanschellingerhout/CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Epoch starting at: 13:48:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch: 522/711, loss: 2.70345, Epoch ETA: 41:24   \r"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "current = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "full_results = []\n",
    "\n",
    "learning_rates = [1e-2, 1e-3, 1e-4][1:2]\n",
    "window_sizes = [0.04, 0.08, 0.2, 0.4, 0.6, 0.8, 1.0][-5:-4]\n",
    "F1_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256][3:4]\n",
    "F2_sizes = [1, 16, 32, 64, 128, 256][-4:-3]\n",
    "\n",
    "skill_embedding_size=100\n",
    "certs_embedding_size=50\n",
    "license_embedding_size=10\n",
    "language_embedding_size=15\n",
    "address_embedding_size=25\n",
    "function_embedding_size=250\n",
    "isco4_embedding_size=150\n",
    "education_embedding_size=10\n",
    "isco_level_embedding_size=10\n",
    "company_embedding_size=250\n",
    "w2v_embedding_size = 300\n",
    "\n",
    "try:            \n",
    "    for learning_rate in learning_rates:\n",
    "        for F1 in F1_sizes:\n",
    "            for F2 in F2_sizes:\n",
    "                for window_size in window_sizes:\n",
    "\n",
    "                    cnn = XCM(num_classes=num_classes,\n",
    "                              input_size=num_features,\n",
    "                              F1=F1,\n",
    "                              F2=F2,\n",
    "                              window_size=window_size,\n",
    "                              skills=skills, \n",
    "                              certs=certs,\n",
    "                              licenses=licenses,\n",
    "                              languages=languages,\n",
    "                              addresses=addresses,\n",
    "                              w2v=w2v,\n",
    "                              skill_embedding_size=skill_embedding_size,\n",
    "                              address_embedding_size=address_embedding_size,\n",
    "                              function_embedding_size=function_embedding_size,\n",
    "                              isco4_embedding_size=isco4_embedding_size,\n",
    "                              company_embedding_size=company_embedding_size,\n",
    "                              candidate_lengths=candidate_lens,\n",
    "                              w2v_embedding_size=w2v_embedding_size,\n",
    "                              max_len=max_len)\n",
    "\n",
    "                    cnn = cnn.to(device)\n",
    "\n",
    "                    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "                    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "                    print(f\"Current iteration {current}/{len(learning_rates) * len(window_sizes) * len(F1_sizes) * len(F2_sizes)}\")\n",
    "                    print(f\"- Initial learning rate: {learning_rate}\\n- Model: \\n\\n\", cnn, \"\\n\")\n",
    "                    \n",
    "                    wandb.init(project=\"eCNN\", entity=\"roanschellingerhout\", config= {\"learning_rate\": learning_rate,\n",
    "                                                                                     \"epochs\": 3,\n",
    "                                                                                     \"batch_size\": 128,\n",
    "                                                                                     \"F1_size\": F1,\n",
    "                                                                                     \"F2_size\": F2,\n",
    "                                                                                     \"window_size\": window_size,\n",
    "                                                                                     \"dropout\": 0})\n",
    "                    \n",
    "                    trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                                            weight_type=3, batch_size=128)\n",
    "\n",
    "                    # Store results of current configuration\n",
    "                    outcome = train_loop(cnn, trainloader, valloader, optimizer, scheduler, criterion, num_epochs)\n",
    "                    outcome[\"lr\"] = [learning_rate] * num_epochs\n",
    "                    outcome[\"F1 size\"] = [F1] * num_epochs\n",
    "                    outcome[\"F2 size\"] = [F2] * num_epochs\n",
    "                    outcome[\"Window size\"] = [window_size] * num_epochs\n",
    "\n",
    "                    full_results.append(outcome)\n",
    "\n",
    "                    current += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ac816d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['lr', 'F1 size', 'F2 size', 'Window size', 'Epoch'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5490a380071a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmerge_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F1 size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F2 size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Window size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['lr', 'F1 size', 'F2 size', 'Window size', 'Epoch'] are in the columns\""
     ]
    }
   ],
   "source": [
    "merge_results = defaultdict(list)\n",
    "\n",
    "for res in full_results:\n",
    "    for k, v in res.items():\n",
    "        merge_results[k].extend(v)\n",
    "        \n",
    "total = pd.DataFrame(merge_results).set_index([\"lr\", \"F1 size\", \"F2 size\", \"Window size\", \"Epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d33330",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a020da20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "skill_embedding_size = 15\n",
    "certs_embedding_size = 20\n",
    "license_embedding_size = 5\n",
    "language_embedding_size = 5\n",
    "address_embedding_size = 10\n",
    "function_embedding_size = 40\n",
    "isco4_embedding_size = 35\n",
    "education_embedding_size = 5\n",
    "isco_level_embedding_size = 5\n",
    "company_embedding_size = 30\n",
    "w2v_embedding_size = 30\n",
    "\n",
    "cnn = XCM(num_classes=num_classes,\n",
    "          input_size=num_features,\n",
    "          F1=16,\n",
    "          F2=256,\n",
    "          window_size=0.8,\n",
    "          skills=skills, \n",
    "          certs=certs,\n",
    "          licenses=licenses,\n",
    "          languages=languages,\n",
    "          addresses=addresses,\n",
    "          w2v=w2v,\n",
    "          skill_embedding_size=skill_embedding_size,\n",
    "          address_embedding_size=address_embedding_size,\n",
    "          function_embedding_size=function_embedding_size,\n",
    "          isco4_embedding_size=isco4_embedding_size,\n",
    "          company_embedding_size=company_embedding_size,\n",
    "          candidate_lengths=candidate_lens,\n",
    "          w2v_embedding_size=w2v_embedding_size,\n",
    "          max_len=max_len)\n",
    "\n",
    "cnn.load_state_dict(torch.load(\"../models/eCNN_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "485785aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XCM(\n",
       "  (skill_embedding): Linear(in_features=317, out_features=15, bias=False)\n",
       "  (certs_embedding): Linear(in_features=98, out_features=20, bias=False)\n",
       "  (license_embedding): Linear(in_features=8, out_features=3, bias=False)\n",
       "  (language_embedding): Linear(in_features=23, out_features=10, bias=False)\n",
       "  (w2v_embedding): Linear(in_features=300, out_features=30, bias=False)\n",
       "  (address_embedding): Embedding(4768, 10)\n",
       "  (function_embedding): Embedding(2992, 40)\n",
       "  (isco_code_embedding): Embedding(355, 35)\n",
       "  (company_embedding): Embedding(441153, 30)\n",
       "  (education_embedding): Embedding(6, 3)\n",
       "  (isco_level_embedding): Embedding(5, 3)\n",
       "  (relu): ReLU()\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d): Conv2d(1, 16, kernel_size=(20, 1), stride=(1, 1), padding=same)\n",
       "  (_1x1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1d_padding): ZeroPad2d(padding=(0, 0, 10, 9), value=0.0)\n",
       "  (conv1d): Conv1d(1, 16, kernel_size=(20, 200), stride=(1,))\n",
       "  (_1x1_2): Conv1d(16, 1, kernel_size=(1, 1), stride=(1,))\n",
       "  (final_conv1d): Conv1d(1, 256, kernel_size=(20, 201), stride=(1,), padding=same)\n",
       "  (avgpool2d): AvgPool2d(kernel_size=(25, 201), stride=1, padding=0)\n",
       "  (fc): Linear(in_features=256, out_features=355, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bac65983",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = create_loaders(to_fill, idxs, y, split_size=0.8, \n",
    "                                        weight_type=3, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab334db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.404296875\n",
      "\n",
      "Majority class accuracy: 0.130859375\n",
      "Majority class predictions: 0.09375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for candidate, career, job in valloader:\n",
    "        candidate, career, job = candidate.to(device), career.to(device), job.to(device)\n",
    "        \n",
    "        career, duration = cnn.create_tensor(career)\n",
    "        pred = cnn(career)\n",
    "        \n",
    "        print(\"Batch accuracy:\", (pred.argmax(1) == job).type(torch.float).mean().item())    \n",
    "        print()\n",
    "\n",
    "        a = pd.Series(Counter(job.tolist()))\n",
    "        a.sort_index().plot(kind=\"area\", label=\"Ground truth\")\n",
    "        \n",
    "        b = pd.Series(Counter(pred.argmax(1).tolist()))\n",
    "        b.sort_index().plot(kind=\"area\", label=\"predicted\")\n",
    "        plt.xlabel(\"isco_code4\")\n",
    "        plt.ylabel(\"number of occurences\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Check how often the model predicted the previous job + compare to baseline performance\n",
    "        print(\"Majority class accuracy:\", (job == majority_class).cpu().numpy().mean())        \n",
    "        print(\"Majority class predictions:\", (pred.argmax(1) == majority_class).cpu().numpy().mean())\n",
    "        \n",
    "        plt.show()        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbba63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del skills\n",
    "del certs\n",
    "del w2v\n",
    "del languages\n",
    "del to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64c5ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, isco_level, source, education, company_name, function_id, isco_code, w2v_list, skill_list, certs_list, license_list, langs_list, address_emb\n",
    "feature_names = [\"Time spent\", \"isco level\", \"education\", \"company name\", \"function\", \"isco code\",\n",
    "                 \"cv\", \"skills\", \"certificates\", \"licenses\", \"languages\", \"location\"]\n",
    "\n",
    "# skill_embedding_size=50, certs_embedding_size=20,\n",
    "# license_embedding_size=3, language_embedding_size=10,\n",
    "# address_embedding_size=25, function_embedding_size=50, \n",
    "# isco4_embedding_size=25, education_embedding_size=3, \n",
    "# isco_level_embedding_size=3, company_embedding_size=50\n",
    "source_embedding_size = 1\n",
    "# w2v_embedding_size = 300\n",
    "\n",
    "embedding_sizes= [0, 1, isco_level_embedding_size, education_embedding_size, company_embedding_size, \n",
    "                  function_embedding_size, isco4_embedding_size, w2v_embedding_size, skill_embedding_size, \n",
    "                  certs_embedding_size, license_embedding_size, language_embedding_size, address_embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c5c84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21d85691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_layers(output, embedding_sizes, axis=\"features\"):\n",
    "    \"\"\"order: start=0, reg_features, isco_level_embedding_size, source_embedding_size, \n",
    "              education_embedding_size, company_embedding_size, function_embedding_size, \n",
    "              isco4_embedding_size, w2v_embedding_size, skill_embedding_size, \n",
    "              certs_embedding_size, license_embedding_size, language_embedding_size, \n",
    "              address_embedding_size\"\"\"\n",
    "        \n",
    "    if axis == \"features\":\n",
    "        output = output.T\n",
    "        idxs = np.cumsum(embedding_sizes)\n",
    "        result = np.stack([output[idxs[i]:idxs[i+1]].mean(axis=0) for i in range(len(idxs) - 1)])\n",
    "    elif axis == \"time\":\n",
    "        result = output.sum(axis=1)\n",
    "        # result = np.stack([result] * (len(embedding_sizes) - 1))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a800ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradcam(model, feature_layer, time_layer, valloader, full_batch=True, group=None, min_len=4, max_len=10):\n",
    "    \n",
    "    # model.softmax = Identity()\n",
    "\n",
    "    # Initialize gradcam\n",
    "    cam = GradCAM(model=model, target_layers=[feature_layer], use_cuda=True)\n",
    "    cam2 = GradCAM(model=model, target_layers=[time_layer], use_cuda=True)\n",
    "            \n",
    "    if group == \"Finance\":\n",
    "        allowed = {i - 1 for i in {5, 20, 70, 71, 72, 73, 74, 75, 142, 143, 146, 195}}\n",
    "    elif group == \"Healthcare\":\n",
    "        allowed = {i - 1 for i in{16, 17, 48, 49, 50, 51, 52, 53, 54, 55, \n",
    "                                  56, 57, 58, 59, 60, 127, 128, 129, 130,\n",
    "                                  131, 132, 133, 134, 135, 136, 137, 138,\n",
    "                                  140, 141, 128, 234, 235, 236}}\n",
    "    elif group == \"Customer_support\":\n",
    "        allowed = {i - 1 for i in {152, 183, 185, 186, 187, 188, 189, 190, 191, 192}}\n",
    "    else:\n",
    "        allowed = set(range(0, 355))\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        # Create batch\n",
    "        c, i, jobs = next(iter(valloader))\n",
    "\n",
    "        # Convert batch to tensor\n",
    "        i, duration = cnn.create_tensor(i.to(device))\n",
    "\n",
    "        for j in range(len(i)):\n",
    "            if jobs[j].item() in allowed:\n",
    "                curr = i[j]\n",
    "                dur = duration[j]\n",
    "                candidate = c[j]\n",
    "                curr_class = jobs[j].item()\n",
    "\n",
    "                if min_len < dur < max_len:\n",
    "                    curr = curr.unsqueeze(0)\n",
    "\n",
    "                    cam_result = cam(input_tensor=curr, targets=[ClassifierOutputTarget(curr_class)])[0]\n",
    "                    cam_result2 = cam2(input_tensor=curr, targets=[ClassifierOutputTarget(curr_class)])[0]\n",
    "                    values = merge_layers(curr[0].cpu().detach(), embedding_sizes)\n",
    "\n",
    "                    # Values, gradcam on features, gradcam on time steps, career_duration\n",
    "                    return values, cam_result, cam_result2, dur, candidate, curr_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f45fec9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_gradients(model, feature_layer, time_layer, valloader, lang=\"en\", group=None):\n",
    "    \n",
    "    if lang != \"en\":        \n",
    "        feature_names = [\"Dagen gewerkt\", \"Werkniveau\", \"Opleidingsniveau\", \"Bedrijf\", \"Functie\", \"Isco code\",\n",
    "                         \"CV\", \"Vaardigheden\", \"Certificaten\", \"Rijbewijzen\", \"Talen\", \"Postcode\"]\n",
    "    \n",
    "    good = False\n",
    "    \n",
    "    while not good:\n",
    "        values, cam, cam2, career_duration, candidate, curr_class = apply_gradcam(model, feature_layer, time_layer, valloader, group=group)\n",
    "\n",
    "        print(f\"Current group: {group}\\nCurren candidate: {int(candidate.item())}\\nClass: {curr_class + 1}\")\n",
    "\n",
    "        to_plot = merge_layers(cam, embedding_sizes, axis=\"features\")\n",
    "        time = merge_layers(cam2, embedding_sizes, axis=\"time\")\n",
    "\n",
    "        to_plot = to_plot.T[-career_duration:].T\n",
    "        time = time.T[-career_duration:].T\n",
    "\n",
    "        values = merge_layers(values.T, embedding_sizes)\n",
    "\n",
    "        # Sum each feature over the time dimension and normalize    \n",
    "        feature_weight = to_plot.T.sum(axis=0)    \n",
    "\n",
    "        feature_weight /= feature_weight.sum()\n",
    "\n",
    "        # Normalized feature attention \n",
    "        series = pd.Series(feature_weight, index=feature_names).sort_values(ascending=False)    \n",
    "\n",
    "        # Create grid\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        grid = plt.GridSpec(2, 2, wspace=0.35, hspace=0.5)\n",
    "        grid.update(top=0.9)\n",
    "\n",
    "        ax1 = plt.subplot(grid[0, 0])\n",
    "        ax2 = plt.subplot(grid[0, 1])\n",
    "        ax3 = plt.subplot(grid[1, :])\n",
    "        # ax4 = plt.subplot(grid[2, :2])\n",
    "\n",
    "        if lang == \"en\":\n",
    "            fig.suptitle(\"Attention types\")\n",
    "        else:\n",
    "            fig.suptitle(\"Soorten aandacht\")\n",
    "\n",
    "        # Plot total attention for each feature\n",
    "        sns.barplot(x=series.values * 100, y=series.index, ax=ax1)\n",
    "        # ax1.set_xticklabels(labels=series.values, rotation=90)\n",
    "        if lang == \"en\":\n",
    "            ax1.set_xlabel(\"Gradient\")\n",
    "            ax1.set_title(\"Attention per feature\")\n",
    "        else:\n",
    "            ax1.set_xlabel(\"Aandacht\")\n",
    "            ax1.set_title(\"Aandacht per eigenschap\")\n",
    "            ax1.xaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "            ax1.grid(axis='x')\n",
    "            ax1.set_axisbelow(True)\n",
    "\n",
    "        series2 = pd.Series(dict(zip(range(1, career_duration + 1), time / time.sum())))\n",
    "\n",
    "        sns.barplot(x=series2.index, y=series2.values  * 100, ax=ax2)\n",
    "        if lang == \"en\":\n",
    "            ax2.set_title(\"Attention per time step\")\n",
    "            ax2.set_ylabel(\"Attention score\")\n",
    "            ax2.set_xlabel(\"Time step\")\n",
    "        else:\n",
    "            ax2.set_title(\"Aandacht per baan nummer\")\n",
    "            ax2.set_ylabel(\"Aandacht\")\n",
    "            ax2.set_xlabel(\"Baan nummer\")\n",
    "            ax2.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "            ax2.grid(axis='y')\n",
    "            ax2.set_axisbelow(True)\n",
    "\n",
    "        cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n",
    "\n",
    "        # Normalize gradients\n",
    "        # to_plot *= (values.sum(axis=0) != 0)\n",
    "        to_plot /= to_plot.max() \n",
    "        to_plot = scipy.special.softmax(to_plot, axis=0) * 100\n",
    "        to_plot = pd.DataFrame(to_plot)\n",
    "\n",
    "        to_plot.index = feature_names\n",
    "        to_plot.columns = range(1, career_duration + 1)\n",
    "\n",
    "        to_plot = to_plot.loc[series.index]\n",
    "\n",
    "        if lang == \"en\":\n",
    "            sns.heatmap(to_plot, cmap=cmap, xticklabels=to_plot.columns, yticklabels=to_plot.index, \n",
    "                        cbar_kws={'label': 'Gradient'}, linewidths=0.1, ax=ax3)\n",
    "\n",
    "            ax3.set_title(\"Spatiotemporal attention\")\n",
    "            ax3.set_xlabel(\"Time step\")\n",
    "        else:\n",
    "            sns.heatmap(to_plot, cmap=cmap, xticklabels=to_plot.columns, yticklabels=to_plot.index, \n",
    "                        cbar_kws={'label': 'Aandacht', 'format': '%.0f%%'}, linewidths=0.1, ax=ax3)\n",
    "\n",
    "            ax3.set_title(\"Aandacht per baan, per eigenschap\")\n",
    "            ax3.set_xlabel(\"Baan nummer\")\n",
    "            \n",
    "        plt.show()\n",
    "            \n",
    "        agreed = input(\"Good enough (y/n)? \")\n",
    "        good = agreed == \"y\"\n",
    "\n",
    "    if lang == \"en\":\n",
    "        fig.savefig(f\"Visualisations/{group}/eCNN_c{int(candidate.item())}_p{curr_class + 1}.pdf\", bbox_inches='tight');\n",
    "    else:\n",
    "        fig.savefig(f\"Visualisations/{group}/eCNN_c{int(candidate.item())}_p{curr_class + 1}.png\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ea25f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fa4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gradients(cnn, cnn.conv2d, cnn.conv1d, valloader, lang=\"nl\", group=\"Customer_support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426aabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
